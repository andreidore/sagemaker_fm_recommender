{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import sagemaker.amazon.common as smac\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.serializers import SimpleBaseSerializer,JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "import boto3, csv, io, json\n",
    "import numpy as np\n",
    "from scipy.sparse import lil_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-09-05 21:55:05--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
      "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
      "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4924029 (4.7M) [application/zip]\n",
      "Saving to: ‘ml-100k.zip.1’\n",
      "\n",
      "ml-100k.zip.1       100%[===================>]   4.70M  5.19MB/s    in 0.9s    \n",
      "\n",
      "2021-09-05 21:55:06 (5.19 MB/s) - ‘ml-100k.zip.1’ saved [4924029/4924029]\n",
      "\n",
      "Archive:  ml-100k.zip\n",
      "  inflating: ml-100k/allbut.pl       \n",
      "  inflating: ml-100k/mku.sh          \n",
      "  inflating: ml-100k/README          \n",
      "  inflating: ml-100k/u.data          \n",
      "  inflating: ml-100k/u.genre         \n",
      "  inflating: ml-100k/u.info          \n",
      "  inflating: ml-100k/u.item          \n",
      "  inflating: ml-100k/u.occupation    \n",
      "  inflating: ml-100k/u.user          \n",
      "  inflating: ml-100k/u1.base         \n",
      "  inflating: ml-100k/u1.test         \n",
      "  inflating: ml-100k/u2.base         \n",
      "  inflating: ml-100k/u2.test         \n",
      "  inflating: ml-100k/u3.base         \n",
      "  inflating: ml-100k/u3.test         \n",
      "  inflating: ml-100k/u4.base         \n",
      "  inflating: ml-100k/u4.test         \n",
      "  inflating: ml-100k/u5.base         \n",
      "  inflating: ml-100k/u5.test         \n",
      "  inflating: ml-100k/ua.base         \n",
      "  inflating: ml-100k/ua.test         \n",
      "  inflating: ml-100k/ub.base         \n",
      "  inflating: ml-100k/ub.test         \n"
     ]
    }
   ],
   "source": [
    "!wget http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "!unzip -o ml-100k.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "1\t1\t5\t874965758\n",
      "1\t2\t3\t876893171\n",
      "1\t3\t4\t878542960\n",
      "1\t4\t3\t876893119\n",
      "1\t5\t3\t889751712\n",
      "1\t6\t5\t887431973\n",
      "1\t7\t4\t875071561\n",
      "1\t8\t1\t875072484\n",
      "1\t9\t5\t878543541\n",
      "1\t10\t3\t875693118\n",
      "\n",
      "Testing Data:\n",
      "1\t20\t4\t887431883\n",
      "1\t33\t4\t878542699\n",
      "1\t61\t4\t878542420\n",
      "1\t117\t3\t874965739\n",
      "1\t155\t2\t878542201\n",
      "1\t160\t4\t875072547\n",
      "1\t171\t5\t889751711\n",
      "1\t189\t3\t888732928\n",
      "1\t202\t5\t875072442\n",
      "1\t265\t4\t878542441\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data:\")\n",
    "!head -10 ./ml-100k/ua.base\n",
    "\n",
    "print(\"\\nTesting Data:\")\n",
    "!head -10 ./ml-100k/ua.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "\n",
    "Sagemaker se asteapta ca datele sa vina in urmatorul format:\n",
    "  - O matrice sparse. Nu vom stoca 0\n",
    "  - Variabila target este recomandarea(rating) utilizatorului\n",
    "  - One-hot encoding pentru utilizator $N$\n",
    "  - One-hot encoding pentru produs $M$\n",
    "  \n",
    "  \n",
    "\n",
    "|Rating|User1|User2|...|UserN|Movie1|Movie2|Movie3|...|MovieM|Feature1|Feature2|...|\n",
    "|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
    "|4|1|0|...|0|0|0|0|...|0|20|2.2|...|\n",
    "|5|0|1|...|0|0|0|0|...|0|17|9.1|...|\n",
    "|3|0|0|...|0|1|0|0|...|0|3|11.0|...|\n",
    "|4|0|0|...|0|0|1|0|...|0|15|6.4|...|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(csv_reader):\n",
    "    samples = []\n",
    "    for userId,movieId,rating,timestamp in csv_reader:\n",
    "        samples.append({\n",
    "            'userId': userId,\n",
    "            'movieId': movieId,\n",
    "            'rating': rating,\n",
    "            'timestamp': timestamp\n",
    "        })\n",
    "        \n",
    "    return samples\n",
    "    \n",
    "    \n",
    "def get_maximums(samples):\n",
    "    users = []\n",
    "    movies = []\n",
    "    for sample in samples:\n",
    "        users.append(int(sample['userId']))\n",
    "        movies.append(int(sample['movieId']))\n",
    "\n",
    "    max_user_id = max(users)\n",
    "    max_movie_id = max(movies)\n",
    "    \n",
    "    return max_user_id, max_movie_id\n",
    "\n",
    "\n",
    "def get_matrix_shape(max_user_id, max_movie_id, samples):\n",
    "    total_samples = len(samples)\n",
    "    total_features = max_user_id + max_movie_id\n",
    "\n",
    "    return total_samples, total_features\n",
    "\n",
    "\n",
    "def fill_data(data, labels, samples):\n",
    "    row = 0\n",
    "        \n",
    "    # Build matrix and labels\n",
    "    for sample in samples:\n",
    "\n",
    "        # One hot-encode userId and movieId at row\n",
    "        user_index = int(sample['userId']) - 1\n",
    "        movie_index = 943 + int(sample['movieId']) - 1    #!!\n",
    "\n",
    "        data[row, user_index] = 1\n",
    "        data[row, movie_index] = 1\n",
    "\n",
    "        # Append binary to labels for whether user \"enjoyed\" movie\n",
    "        labels.append(int(sample['rating']))\n",
    "        #if int(sample['rating']) >= 4:\n",
    "        #    labels.append(1)\n",
    "        #else:\n",
    "        #    labels.append(0)\n",
    "\n",
    "        row = row + 1\n",
    "\n",
    "    # Convert labels list to float 32\n",
    "    labels = np.array(labels).astype('float32')\n",
    "    \n",
    "    return data, labels\n",
    "    \n",
    "\n",
    "def load_dataset(training_data_file_path, testing_data_file_path):\n",
    "    # Training Data\n",
    "    with open(training_data_file_path, 'r') as file:\n",
    "        csv_reader = csv.reader(file, delimiter='\\t')\n",
    "        \n",
    "        # Get all training samples in form of [{}, {}, ...]\n",
    "        training_samples = get_samples(csv_reader)\n",
    "        \n",
    "        # Get maximum number of users and movies\n",
    "        max_user_id, max_movie_id = get_maximums(training_samples)\n",
    "        \n",
    "        # Get shape of training matrix\n",
    "        training_matrix_shape = get_matrix_shape(max_user_id, max_movie_id, training_samples)\n",
    "        \n",
    "        # Initialize training data and labels structures\n",
    "        training_data = lil_matrix(training_matrix_shape).astype('float32')\n",
    "        training_labels = []\n",
    "\n",
    "        # Fill training data and labels structures with sample training data \n",
    "        training_data, training_labels = fill_data(training_data, training_labels, training_samples)\n",
    "        \n",
    "    # Testing Data\n",
    "    with open(testing_data_file_path, 'r') as file:\n",
    "        csv_reader = csv.reader(file, delimiter='\\t')\n",
    "        \n",
    "        # Get all testing samples in form of [{}, {}, ...]\n",
    "        testing_samples = get_samples(csv_reader)\n",
    "        \n",
    "        #Get shape of testing matrix\n",
    "        testing_matrix_shape = get_matrix_shape(max_user_id, max_movie_id, testing_samples)\n",
    "        \n",
    "        # Initialize testing data and labels structures\n",
    "        testing_data = lil_matrix(testing_matrix_shape).astype('float32')\n",
    "        testing_labels = []\n",
    "        \n",
    "        # Fill testing data and labels structurs with sample testing data\n",
    "        testing_data, testing_labels = fill_data(testing_data, testing_labels, testing_samples)\n",
    "        \n",
    "    \n",
    "    \n",
    "    return (training_data, training_labels), (testing_data, testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_file_path = './ml-100k/ua.base'\n",
    "testing_data_file_path = './ml-100k/ua.test'\n",
    "\n",
    "(training_data, training_labels), (testing_data, testing_labels) = load_dataset(training_data_file_path, testing_data_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Ratings, Features)\n",
      "(90570, 2625)\n",
      "(90570,)\n",
      "(9430, 2625)\n",
      "(9430,)\n"
     ]
    }
   ],
   "source": [
    "print(\"(Ratings, Features)\")\n",
    "print(training_data.shape)\n",
    "print(training_labels.shape)\n",
    "\n",
    "print(testing_data.shape)\n",
    "print(testing_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1.0\n",
      "  (0, 953)\t1.0\n",
      "  (1, 0)\t1.0\n",
      "  (1, 954)\t1.0\n",
      "  (2, 0)\t1.0\n",
      "  (2, 955)\t1.0\n",
      "  (3, 0)\t1.0\n",
      "  (3, 956)\t1.0\n",
      "  (4, 0)\t1.0\n",
      "  (4, 957)\t1.0\n",
      "[2. 5. 5. 5. 5.]\n",
      "  (0, 1)\t1.0\n",
      "  (0, 955)\t1.0\n",
      "  (1, 1)\t1.0\n",
      "  (1, 992)\t1.0\n",
      "  (2, 1)\t1.0\n",
      "  (2, 1193)\t1.0\n",
      "  (3, 1)\t1.0\n",
      "  (3, 1222)\t1.0\n",
      "  (4, 1)\t1.0\n",
      "  (4, 1223)\t1.0\n",
      "[4. 5. 5. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "print(training_data[10:15])\n",
    "print(training_labels[10:15])\n",
    "\n",
    "print(testing_data[10:15])\n",
    "print(testing_labels[10:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to protobuf and save to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'andrei-work-eu' # Put your bucket\n",
    "prefix = 'temp/movielens'\n",
    "\n",
    "training_data_key = '{}/training-data/training.protobuf'.format(prefix)\n",
    "testing_data_key = '{}/testing-data/testing.protobuf'.format(prefix)\n",
    "\n",
    "output_path = 's3://{}/{}/output'.format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataset_to_protobuf(data, labels, bucket, key):\n",
    "    buf = io.BytesIO()\n",
    "    smac.write_spmatrix_to_sparse_tensor(buf, data, labels)\n",
    "    buf.seek(0)\n",
    "    boto3.resource('s3').Bucket(bucket).Object(key).upload_fileobj(buf)\n",
    "    return 's3://{}/{}'.format(bucket, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data written to: s3://andrei-work-eu/temp/movielens/training-data/training.protobuf\n",
      "Testing data written to: s3://andrei-work-eu/temp/movielens/testing-data/testing.protobuf\n",
      "Output location: s3://andrei-work-eu/temp/movielens/output\n"
     ]
    }
   ],
   "source": [
    "training_data_location = write_dataset_to_protobuf(training_data, training_labels, bucket, training_data_key)\n",
    "testing_data_location = write_dataset_to_protobuf(testing_data, testing_labels, bucket, testing_data_key)\n",
    "\n",
    "print('Training data written to: {}'.format(training_data_location))\n",
    "print('Testing data written to: {}'.format(testing_data_location))\n",
    "print('Output location: {}'.format(output_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User image : 664544806723.dkr.ecr.eu-central-1.amazonaws.com/factorization-machines:1\n",
      "2021-09-05 21:59:52 Starting - Starting the training job...\n",
      "2021-09-05 21:59:54 Starting - Launching requested ML instancesProfilerReport-1630879192: InProgress\n",
      "...\n",
      "2021-09-05 22:00:42 Starting - Preparing the instances for training......\n",
      "2021-09-05 22:01:50 Downloading - Downloading input data...\n",
      "2021-09-05 22:02:23 Training - Downloading the training image...\n",
      "2021-09-05 22:02:43 Training - Training image download completed. Training in progress.\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/jsonref.py:8: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Mapping, MutableMapping, Sequence\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/algorithm/network_builder.py:87: DeprecationWarning: invalid escape sequence \\s\n",
      "  \"\"\"\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/algorithm/network_builder.py:120: DeprecationWarning: invalid escape sequence \\s\n",
      "  \"\"\"\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:40 INFO 140434797135680] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/resources/default-conf.json: {'epochs': 1, 'mini_batch_size': '1000', 'use_bias': 'true', 'use_linear': 'true', 'bias_lr': '0.1', 'linear_lr': '0.001', 'factors_lr': '0.0001', 'bias_wd': '0.01', 'linear_wd': '0.001', 'factors_wd': '0.00001', 'bias_init_method': 'normal', 'bias_init_sigma': '0.01', 'linear_init_method': 'normal', 'linear_init_sigma': '0.01', 'factors_init_method': 'normal', 'factors_init_sigma': '0.001', 'batch_metrics_publish_interval': '500', '_data_format': 'record', '_kvstore': 'auto', '_learning_rate': '1.0', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_optimizer': 'adam', '_tuning_objective_metric': '', '_use_full_symbolic': 'true', '_wd': '1.0'}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:40 INFO 140434797135680] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'feature_dim': '2625', 'predictor_type': 'regressor', 'num_factors': '10', 'epochs': '200', 'mini_batch_size': '1000'}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:40 INFO 140434797135680] Final configuration: {'epochs': '200', 'mini_batch_size': '1000', 'use_bias': 'true', 'use_linear': 'true', 'bias_lr': '0.1', 'linear_lr': '0.001', 'factors_lr': '0.0001', 'bias_wd': '0.01', 'linear_wd': '0.001', 'factors_wd': '0.00001', 'bias_init_method': 'normal', 'bias_init_sigma': '0.01', 'linear_init_method': 'normal', 'linear_init_sigma': '0.01', 'factors_init_method': 'normal', 'factors_init_sigma': '0.001', 'batch_metrics_publish_interval': '500', '_data_format': 'record', '_kvstore': 'auto', '_learning_rate': '1.0', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_optimizer': 'adam', '_tuning_objective_metric': '', '_use_full_symbolic': 'true', '_wd': '1.0', 'feature_dim': '2625', 'predictor_type': 'regressor', 'num_factors': '10'}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:40 WARNING 140434797135680] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:40 INFO 140434797135680] Using default worker.\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:40 INFO 140434797135680] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:40.757] [tensorio] [warning] TensorIO is already initialized; ignoring the initialization routine.\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:40.762] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 9, \"num_examples\": 1, \"num_bytes\": 64000}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:40 INFO 140434797135680] nvidia-smi: took 0.033 seconds to run.\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:40 INFO 140434797135680] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:40 INFO 140434797135680] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:40 INFO 140434797135680] [Sparse network] Building a sparse network.\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:40 INFO 140434797135680] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879360.7527027, \"EndTime\": 1630879360.8005326, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 38.93923759460449, \"count\": 1, \"min\": 38.93923759460449, \"max\": 38.93923759460449}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879360.8007767, \"EndTime\": 1630879360.8008063, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1000.0, \"count\": 1, \"min\": 1000, \"max\": 1000}, \"Total Batches Seen\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Max Records Seen Between Resets\": {\"sum\": 1000.0, \"count\": 1, \"min\": 1000, \"max\": 1000}, \"Max Batches Seen Between Resets\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[22:02:40] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.204642.0/AL2_x86_64/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[34m[22:02:40] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.204642.0/AL2_x86_64/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:40 INFO 140434797135680] #quality_metric: host=algo-1, epoch=0, batch=0 train rmse <loss>=3.799242189034216\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:40 INFO 140434797135680] #quality_metric: host=algo-1, epoch=0, batch=0 train mse <loss>=14.4342412109375\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:40 INFO 140434797135680] #quality_metric: host=algo-1, epoch=0, batch=0 train absolute_loss <loss>=3.592279541015625\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:41.307] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 2, \"duration\": 491, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:41 INFO 140434797135680] #quality_metric: host=algo-1, epoch=0, train rmse <loss>=1.762020084834808\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:41 INFO 140434797135680] #quality_metric: host=algo-1, epoch=0, train mse <loss>=3.104714779361264\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:41 INFO 140434797135680] #quality_metric: host=algo-1, epoch=0, train absolute_loss <loss>=1.391475605388264\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879360.8005996, \"EndTime\": 1630879361.3079796, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 200.0, \"count\": 1, \"min\": 200, \"max\": 200}, \"update.time\": {\"sum\": 506.8798065185547, \"count\": 1, \"min\": 506.8798065185547, \"max\": 506.8798065185547}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:41 INFO 140434797135680] #progress_metric: host=algo-1, completed 0.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879360.8010712, \"EndTime\": 1630879361.3096943, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 91570.0, \"count\": 1, \"min\": 91570, \"max\": 91570}, \"Total Batches Seen\": {\"sum\": 92.0, \"count\": 1, \"min\": 92, \"max\": 92}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:41 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=178015.57352527694 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:41 INFO 140434797135680] #quality_metric: host=algo-1, epoch=1, batch=0 train rmse <loss>=1.2368693152976995\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:41 INFO 140434797135680] #quality_metric: host=algo-1, epoch=1, batch=0 train mse <loss>=1.529845703125\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:41 INFO 140434797135680] #quality_metric: host=algo-1, epoch=1, batch=0 train absolute_loss <loss>=1.0575992431640624\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:41.763] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 4, \"duration\": 451, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:41 INFO 140434797135680] #quality_metric: host=algo-1, epoch=1, train rmse <loss>=1.1412053603249734\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:41 INFO 140434797135680] #quality_metric: host=algo-1, epoch=1, train mse <loss>=1.3023496744344523\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:41 INFO 140434797135680] #quality_metric: host=algo-1, epoch=1, train absolute_loss <loss>=0.9548167436201493\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879361.308086, \"EndTime\": 1630879361.7646568, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 454.24771308898926, \"count\": 1, \"min\": 454.24771308898926, \"max\": 454.24771308898926}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:41 INFO 140434797135680] #progress_metric: host=algo-1, completed 1.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879361.31038, \"EndTime\": 1630879361.7653093, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 182140.0, \"count\": 1, \"min\": 182140, \"max\": 182140}, \"Total Batches Seen\": {\"sum\": 183.0, \"count\": 1, \"min\": 183, \"max\": 183}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:41 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=198915.62134211636 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:41 INFO 140434797135680] #quality_metric: host=algo-1, epoch=2, batch=0 train rmse <loss>=1.227320227734494\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:41 INFO 140434797135680] #quality_metric: host=algo-1, epoch=2, batch=0 train mse <loss>=1.50631494140625\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:41 INFO 140434797135680] #quality_metric: host=algo-1, epoch=2, batch=0 train absolute_loss <loss>=1.04984619140625\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:42.249] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 6, \"duration\": 481, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:42 INFO 140434797135680] #quality_metric: host=algo-1, epoch=2, train rmse <loss>=1.1323779839378962\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:42 INFO 140434797135680] #quality_metric: host=algo-1, epoch=2, train mse <loss>=1.2822798985072545\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:42 INFO 140434797135680] #quality_metric: host=algo-1, epoch=2, train absolute_loss <loss>=0.946013665838556\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879361.764978, \"EndTime\": 1630879362.2502458, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 483.8218688964844, \"count\": 1, \"min\": 483.8218688964844, \"max\": 483.8218688964844}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:42 INFO 140434797135680] #progress_metric: host=algo-1, completed 1.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879361.7663941, \"EndTime\": 1630879362.250614, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 272710.0, \"count\": 1, \"min\": 272710, \"max\": 272710}, \"Total Batches Seen\": {\"sum\": 274.0, \"count\": 1, \"min\": 274, \"max\": 274}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:42 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=186992.1537923101 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:42 INFO 140434797135680] #quality_metric: host=algo-1, epoch=3, batch=0 train rmse <loss>=1.2150723759950475\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:42 INFO 140434797135680] #quality_metric: host=algo-1, epoch=3, batch=0 train mse <loss>=1.47640087890625\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:42 INFO 140434797135680] #quality_metric: host=algo-1, epoch=3, batch=0 train absolute_loss <loss>=1.03799560546875\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:42.742] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 8, \"duration\": 489, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:42 INFO 140434797135680] #quality_metric: host=algo-1, epoch=3, train rmse <loss>=1.12350766242691\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:42 INFO 140434797135680] #quality_metric: host=algo-1, epoch=3, train mse <loss>=1.2622694675319797\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:42 INFO 140434797135680] #quality_metric: host=algo-1, epoch=3, train absolute_loss <loss>=0.9370201395894145\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879362.2503102, \"EndTime\": 1630879362.743933, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 492.5844669342041, \"count\": 1, \"min\": 492.5844669342041, \"max\": 492.5844669342041}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:42 INFO 140434797135680] #progress_metric: host=algo-1, completed 2.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879362.2512624, \"EndTime\": 1630879362.7443402, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 363280.0, \"count\": 1, \"min\": 363280, \"max\": 363280}, \"Total Batches Seen\": {\"sum\": 365.0, \"count\": 1, \"min\": 365, \"max\": 365}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:42 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=183601.50006089793 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:42 INFO 140434797135680] #quality_metric: host=algo-1, epoch=4, batch=0 train rmse <loss>=1.2031140421578912\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:42 INFO 140434797135680] #quality_metric: host=algo-1, epoch=4, batch=0 train mse <loss>=1.4474833984375\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:42 INFO 140434797135680] #quality_metric: host=algo-1, epoch=4, batch=0 train absolute_loss <loss>=1.0260789794921874\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:43.261] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 10, \"duration\": 513, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:43 INFO 140434797135680] #quality_metric: host=algo-1, epoch=4, train rmse <loss>=1.114968552480314\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:43 INFO 140434797135680] #quality_metric: host=algo-1, epoch=4, train mse <loss>=1.2431548730200463\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:43 INFO 140434797135680] #quality_metric: host=algo-1, epoch=4, train absolute_loss <loss>=0.9280598419524811\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879362.7440193, \"EndTime\": 1630879363.2622507, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 516.9551372528076, \"count\": 1, \"min\": 516.9551372528076, \"max\": 516.9551372528076}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:43 INFO 140434797135680] #progress_metric: host=algo-1, completed 2.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879362.7452629, \"EndTime\": 1630879363.262747, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 453850.0, \"count\": 1, \"min\": 453850, \"max\": 453850}, \"Total Batches Seen\": {\"sum\": 456.0, \"count\": 1, \"min\": 456, \"max\": 456}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:43 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=174954.71054587726 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:43 INFO 140434797135680] #quality_metric: host=algo-1, epoch=5, batch=0 train rmse <loss>=1.1918683017968574\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:43 INFO 140434797135680] #quality_metric: host=algo-1, epoch=5, batch=0 train mse <loss>=1.420550048828125\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:43 INFO 140434797135680] #quality_metric: host=algo-1, epoch=5, batch=0 train absolute_loss <loss>=1.0145809936523438\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:43.730] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 12, \"duration\": 464, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:43 INFO 140434797135680] #quality_metric: host=algo-1, epoch=5, train rmse <loss>=1.106943968695093\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:43 INFO 140434797135680] #quality_metric: host=algo-1, epoch=5, train mse <loss>=1.225324949830443\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:43 INFO 140434797135680] #quality_metric: host=algo-1, epoch=5, train absolute_loss <loss>=0.9193318763146033\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879363.2623713, \"EndTime\": 1630879363.7316053, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 467.87333488464355, \"count\": 1, \"min\": 467.87333488464355, \"max\": 467.87333488464355}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:43 INFO 140434797135680] #progress_metric: host=algo-1, completed 3.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879363.2636864, \"EndTime\": 1630879363.7321362, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 544420.0, \"count\": 1, \"min\": 544420, \"max\": 544420}, \"Total Batches Seen\": {\"sum\": 547.0, \"count\": 1, \"min\": 547, \"max\": 547}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 7.0, \"count\": 1, \"min\": 7, \"max\": 7}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:43 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=193223.37088664577 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:43 INFO 140434797135680] #quality_metric: host=algo-1, epoch=6, batch=0 train rmse <loss>=1.1814593998426532\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:43 INFO 140434797135680] #quality_metric: host=algo-1, epoch=6, batch=0 train mse <loss>=1.3958463134765624\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:43 INFO 140434797135680] #quality_metric: host=algo-1, epoch=6, batch=0 train absolute_loss <loss>=1.0036727294921874\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:44.262] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 14, \"duration\": 526, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:44 INFO 140434797135680] #quality_metric: host=algo-1, epoch=6, train rmse <loss>=1.0994977290990642\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:44 INFO 140434797135680] #quality_metric: host=algo-1, epoch=6, train mse <loss>=1.208895256293999\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:44 INFO 140434797135680] #quality_metric: host=algo-1, epoch=6, train absolute_loss <loss>=0.9109447148920415\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879363.731686, \"EndTime\": 1630879364.263378, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 530.2248001098633, \"count\": 1, \"min\": 530.2248001098633, \"max\": 530.2248001098633}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:44 INFO 140434797135680] #progress_metric: host=algo-1, completed 3.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879363.7331238, \"EndTime\": 1630879364.264134, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 634990.0, \"count\": 1, \"min\": 634990, \"max\": 634990}, \"Total Batches Seen\": {\"sum\": 638.0, \"count\": 1, \"min\": 638, \"max\": 638}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 8.0, \"count\": 1, \"min\": 8, \"max\": 8}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:44 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=170413.35055359494 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:44 INFO 140434797135680] #quality_metric: host=algo-1, epoch=7, batch=0 train rmse <loss>=1.171902551759451\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:44 INFO 140434797135680] #quality_metric: host=algo-1, epoch=7, batch=0 train mse <loss>=1.3733555908203126\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:44 INFO 140434797135680] #quality_metric: host=algo-1, epoch=7, batch=0 train absolute_loss <loss>=0.9934150390625\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:44.834] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 16, \"duration\": 567, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:44 INFO 140434797135680] #quality_metric: host=algo-1, epoch=7, train rmse <loss>=1.0926356414814722\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:44 INFO 140434797135680] #quality_metric: host=algo-1, epoch=7, train mse <loss>=1.1938526450356284\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:44 INFO 140434797135680] #quality_metric: host=algo-1, epoch=7, train absolute_loss <loss>=0.902957765684023\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879364.2637208, \"EndTime\": 1630879364.835898, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 570.5645084381104, \"count\": 1, \"min\": 570.5645084381104, \"max\": 570.5645084381104}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:44 INFO 140434797135680] #progress_metric: host=algo-1, completed 4.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879364.2653043, \"EndTime\": 1630879364.8363216, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 725560.0, \"count\": 1, \"min\": 725560, \"max\": 725560}, \"Total Batches Seen\": {\"sum\": 729.0, \"count\": 1, \"min\": 729, \"max\": 729}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:44 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=158553.21074350673 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:44 INFO 140434797135680] #quality_metric: host=algo-1, epoch=8, batch=0 train rmse <loss>=1.1631669688660082\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:44 INFO 140434797135680] #quality_metric: host=algo-1, epoch=8, batch=0 train mse <loss>=1.3529573974609375\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:44 INFO 140434797135680] #quality_metric: host=algo-1, epoch=8, batch=0 train absolute_loss <loss>=0.983822265625\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:45.338] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 18, \"duration\": 499, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:45 INFO 140434797135680] #quality_metric: host=algo-1, epoch=8, train rmse <loss>=1.0863339415030635\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:45 INFO 140434797135680] #quality_metric: host=algo-1, epoch=8, train mse <loss>=1.1801214324615814\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:45 INFO 140434797135680] #quality_metric: host=algo-1, epoch=8, train absolute_loss <loss>=0.8954019393082503\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879364.8360338, \"EndTime\": 1630879365.3396761, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 502.42114067077637, \"count\": 1, \"min\": 502.42114067077637, \"max\": 502.42114067077637}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:45 INFO 140434797135680] #progress_metric: host=algo-1, completed 4.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879364.837222, \"EndTime\": 1630879365.3401926, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 816130.0, \"count\": 1, \"min\": 816130, \"max\": 816130}, \"Total Batches Seen\": {\"sum\": 820.0, \"count\": 1, \"min\": 820, \"max\": 820}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:45 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=179998.63217797154 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:45 INFO 140434797135680] #quality_metric: host=algo-1, epoch=9, batch=0 train rmse <loss>=1.155201593946377\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:45 INFO 140434797135680] #quality_metric: host=algo-1, epoch=9, batch=0 train mse <loss>=1.33449072265625\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:45 INFO 140434797135680] #quality_metric: host=algo-1, epoch=9, batch=0 train absolute_loss <loss>=0.9748866577148437\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:45.917] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 20, \"duration\": 574, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:45 INFO 140434797135680] #quality_metric: host=algo-1, epoch=9, train rmse <loss>=1.0805542388440255\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:45 INFO 140434797135680] #quality_metric: host=algo-1, epoch=9, train mse <loss>=1.1675974630837913\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:45 INFO 140434797135680] #quality_metric: host=algo-1, epoch=9, train absolute_loss <loss>=0.8882990119011848\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879365.3398023, \"EndTime\": 1630879365.918877, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 577.700138092041, \"count\": 1, \"min\": 577.700138092041, \"max\": 577.700138092041}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:45 INFO 140434797135680] #progress_metric: host=algo-1, completed 5.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879365.3411467, \"EndTime\": 1630879365.919363, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 906700.0, \"count\": 1, \"min\": 906700, \"max\": 906700}, \"Total Batches Seen\": {\"sum\": 911.0, \"count\": 1, \"min\": 911, \"max\": 911}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 11.0, \"count\": 1, \"min\": 11, \"max\": 11}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:45 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=156591.36050652948 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:45 INFO 140434797135680] #quality_metric: host=algo-1, epoch=10, batch=0 train rmse <loss>=1.147947280577107\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:45 INFO 140434797135680] #quality_metric: host=algo-1, epoch=10, batch=0 train mse <loss>=1.317782958984375\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:45 INFO 140434797135680] #quality_metric: host=algo-1, epoch=10, batch=0 train absolute_loss <loss>=0.9665895385742187\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:46.459] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 22, \"duration\": 537, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:46 INFO 140434797135680] #quality_metric: host=algo-1, epoch=10, train rmse <loss>=1.0752519668961928\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:46 INFO 140434797135680] #quality_metric: host=algo-1, epoch=10, train mse <loss>=1.1561667923141312\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:46 INFO 140434797135680] #quality_metric: host=algo-1, epoch=10, train absolute_loss <loss>=0.8816728683304\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879365.918977, \"EndTime\": 1630879366.4604938, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 540.1456356048584, \"count\": 1, \"min\": 540.1456356048584, \"max\": 540.1456356048584}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:46 INFO 140434797135680] #progress_metric: host=algo-1, completed 5.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879365.9203186, \"EndTime\": 1630879366.460966, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 997270.0, \"count\": 1, \"min\": 997270, \"max\": 997270}, \"Total Batches Seen\": {\"sum\": 1002.0, \"count\": 1, \"min\": 1002, \"max\": 1002}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 12.0, \"count\": 1, \"min\": 12, \"max\": 12}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:46 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=167468.9888019877 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:46 INFO 140434797135680] #quality_metric: host=algo-1, epoch=11, batch=0 train rmse <loss>=1.1413427750146425\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:46 INFO 140434797135680] #quality_metric: host=algo-1, epoch=11, batch=0 train mse <loss>=1.302663330078125\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:46 INFO 140434797135680] #quality_metric: host=algo-1, epoch=11, batch=0 train absolute_loss <loss>=0.9589058837890625\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:46.963] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 24, \"duration\": 499, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:46 INFO 140434797135680] #quality_metric: host=algo-1, epoch=11, train rmse <loss>=1.070381250862522\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:46 INFO 140434797135680] #quality_metric: host=algo-1, epoch=11, train mse <loss>=1.145716022198017\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:46 INFO 140434797135680] #quality_metric: host=algo-1, epoch=11, train absolute_loss <loss>=0.8755418238377833\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879366.4605932, \"EndTime\": 1630879366.9646287, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 502.63166427612305, \"count\": 1, \"min\": 502.63166427612305, \"max\": 502.63166427612305}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:46 INFO 140434797135680] #progress_metric: host=algo-1, completed 6.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879366.4619648, \"EndTime\": 1630879366.9651582, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1087840.0, \"count\": 1, \"min\": 1087840, \"max\": 1087840}, \"Total Batches Seen\": {\"sum\": 1093.0, \"count\": 1, \"min\": 1093, \"max\": 1093}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 13.0, \"count\": 1, \"min\": 13, \"max\": 13}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:46 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=179913.042519515 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:46 INFO 140434797135680] #quality_metric: host=algo-1, epoch=12, batch=0 train rmse <loss>=1.1353278109344676\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:46 INFO 140434797135680] #quality_metric: host=algo-1, epoch=12, batch=0 train mse <loss>=1.28896923828125\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:46 INFO 140434797135680] #quality_metric: host=algo-1, epoch=12, batch=0 train absolute_loss <loss>=0.9518067626953125\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:47.523] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 26, \"duration\": 555, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:47 INFO 140434797135680] #quality_metric: host=algo-1, epoch=12, train rmse <loss>=1.0658975809417113\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:47 INFO 140434797135680] #quality_metric: host=algo-1, epoch=12, train mse <loss>=1.136137653057392\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:47 INFO 140434797135680] #quality_metric: host=algo-1, epoch=12, train absolute_loss <loss>=0.8699016830947373\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879366.9647553, \"EndTime\": 1630879367.5245008, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 558.3295822143555, \"count\": 1, \"min\": 558.3295822143555, \"max\": 558.3295822143555}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:47 INFO 140434797135680] #progress_metric: host=algo-1, completed 6.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879366.9661417, \"EndTime\": 1630879367.524835, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1178410.0, \"count\": 1, \"min\": 1178410, \"max\": 1178410}, \"Total Batches Seen\": {\"sum\": 1184.0, \"count\": 1, \"min\": 1184, \"max\": 1184}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 14.0, \"count\": 1, \"min\": 14, \"max\": 14}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:47 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=162061.48336395714 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:47 INFO 140434797135680] #quality_metric: host=algo-1, epoch=13, batch=0 train rmse <loss>=1.1298449816754454\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:47 INFO 140434797135680] #quality_metric: host=algo-1, epoch=13, batch=0 train mse <loss>=1.2765496826171876\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:47 INFO 140434797135680] #quality_metric: host=algo-1, epoch=13, batch=0 train absolute_loss <loss>=0.9452608642578125\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:48.026] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 28, \"duration\": 499, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:48 INFO 140434797135680] #quality_metric: host=algo-1, epoch=13, train rmse <loss>=1.061759459578436\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:48 INFO 140434797135680] #quality_metric: host=algo-1, epoch=13, train mse <loss>=1.1273331500042927\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:48 INFO 140434797135680] #quality_metric: host=algo-1, epoch=13, train absolute_loss <loss>=0.8647584463266226\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879367.5246027, \"EndTime\": 1630879368.0282867, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 502.3174285888672, \"count\": 1, \"min\": 502.3174285888672, \"max\": 502.3174285888672}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:48 INFO 140434797135680] #progress_metric: host=algo-1, completed 7.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879367.525884, \"EndTime\": 1630879368.028919, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1268980.0, \"count\": 1, \"min\": 1268980, \"max\": 1268980}, \"Total Batches Seen\": {\"sum\": 1275.0, \"count\": 1, \"min\": 1275, \"max\": 1275}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 15.0, \"count\": 1, \"min\": 15, \"max\": 15}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:48 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=179901.88094725052 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:48 INFO 140434797135680] #quality_metric: host=algo-1, epoch=14, batch=0 train rmse <loss>=1.1248401579155036\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:48 INFO 140434797135680] #quality_metric: host=algo-1, epoch=14, batch=0 train mse <loss>=1.265265380859375\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:48 INFO 140434797135680] #quality_metric: host=algo-1, epoch=14, batch=0 train absolute_loss <loss>=0.939443115234375\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:48.541] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 30, \"duration\": 510, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:48 INFO 140434797135680] #quality_metric: host=algo-1, epoch=14, train rmse <loss>=1.0579288875717416\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:48 INFO 140434797135680] #quality_metric: host=algo-1, epoch=14, train mse <loss>=1.1192135311587825\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:48 INFO 140434797135680] #quality_metric: host=algo-1, epoch=14, train absolute_loss <loss>=0.8600893387008499\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879368.0285923, \"EndTime\": 1630879368.5428953, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 512.8765106201172, \"count\": 1, \"min\": 512.8765106201172, \"max\": 512.8765106201172}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:48 INFO 140434797135680] #progress_metric: host=algo-1, completed 7.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879368.0299916, \"EndTime\": 1630879368.5432937, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1359550.0, \"count\": 1, \"min\": 1359550, \"max\": 1359550}, \"Total Batches Seen\": {\"sum\": 1366.0, \"count\": 1, \"min\": 1366, \"max\": 1366}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:48 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=176376.33388166828 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:48 INFO 140434797135680] #quality_metric: host=algo-1, epoch=15, batch=0 train rmse <loss>=1.1202636299487445\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:48 INFO 140434797135680] #quality_metric: host=algo-1, epoch=15, batch=0 train mse <loss>=1.2549906005859375\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:48 INFO 140434797135680] #quality_metric: host=algo-1, epoch=15, batch=0 train absolute_loss <loss>=0.9342910766601562\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:49.014] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 32, \"duration\": 468, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:49 INFO 140434797135680] #quality_metric: host=algo-1, epoch=15, train rmse <loss>=1.0543718338022308\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:49 INFO 140434797135680] #quality_metric: host=algo-1, epoch=15, train mse <loss>=1.111699963915479\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:49 INFO 140434797135680] #quality_metric: host=algo-1, epoch=15, train absolute_loss <loss>=0.8558577511965574\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879368.5430326, \"EndTime\": 1630879369.0151134, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 470.86143493652344, \"count\": 1, \"min\": 470.86143493652344, \"max\": 470.86143493652344}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:49 INFO 140434797135680] #progress_metric: host=algo-1, completed 8.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879368.5442243, \"EndTime\": 1630879369.0154765, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1450120.0, \"count\": 1, \"min\": 1450120, \"max\": 1450120}, \"Total Batches Seen\": {\"sum\": 1457.0, \"count\": 1, \"min\": 1457, \"max\": 1457}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 17.0, \"count\": 1, \"min\": 17, \"max\": 17}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:49 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=192127.484755103 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:49 INFO 140434797135680] #quality_metric: host=algo-1, epoch=16, batch=0 train rmse <loss>=1.1160696986593737\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:49 INFO 140434797135680] #quality_metric: host=algo-1, epoch=16, batch=0 train mse <loss>=1.245611572265625\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:49 INFO 140434797135680] #quality_metric: host=algo-1, epoch=16, batch=0 train absolute_loss <loss>=0.9296412963867188\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:49.540] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 34, \"duration\": 523, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:49 INFO 140434797135680] #quality_metric: host=algo-1, epoch=16, train rmse <loss>=1.05105802192366\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:49 INFO 140434797135680] #quality_metric: host=algo-1, epoch=16, train mse <loss>=1.1047229654500772\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:49 INFO 140434797135680] #quality_metric: host=algo-1, epoch=16, train absolute_loss <loss>=0.8520099279382727\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879369.0152342, \"EndTime\": 1630879369.5420463, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 525.8865356445312, \"count\": 1, \"min\": 525.8865356445312, \"max\": 525.8865356445312}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:49 INFO 140434797135680] #progress_metric: host=algo-1, completed 8.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879369.0161285, \"EndTime\": 1630879369.5425987, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1540690.0, \"count\": 1, \"min\": 1540690, \"max\": 1540690}, \"Total Batches Seen\": {\"sum\": 1548.0, \"count\": 1, \"min\": 1548, \"max\": 1548}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 18.0, \"count\": 1, \"min\": 18, \"max\": 18}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:49 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=171971.7881569393 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:49 INFO 140434797135680] #quality_metric: host=algo-1, epoch=17, batch=0 train rmse <loss>=1.1122169254501626\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:49 INFO 140434797135680] #quality_metric: host=algo-1, epoch=17, batch=0 train mse <loss>=1.2370264892578124\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:49 INFO 140434797135680] #quality_metric: host=algo-1, epoch=17, batch=0 train absolute_loss <loss>=0.925477294921875\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:50.081] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 36, \"duration\": 536, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:50 INFO 140434797135680] #quality_metric: host=algo-1, epoch=17, train rmse <loss>=1.0479607828676265\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:50 INFO 140434797135680] #quality_metric: host=algo-1, epoch=17, train mse <loss>=1.0982218024285284\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:50 INFO 140434797135680] #quality_metric: host=algo-1, epoch=17, train absolute_loss <loss>=0.8485109521216089\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879369.5421715, \"EndTime\": 1630879370.0825038, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 538.9001369476318, \"count\": 1, \"min\": 538.9001369476318, \"max\": 538.9001369476318}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:50 INFO 140434797135680] #progress_metric: host=algo-1, completed 9.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879369.543576, \"EndTime\": 1630879370.0828414, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1631260.0, \"count\": 1, \"min\": 1631260, \"max\": 1631260}, \"Total Batches Seen\": {\"sum\": 1639.0, \"count\": 1, \"min\": 1639, \"max\": 1639}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 19.0, \"count\": 1, \"min\": 19, \"max\": 19}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:50 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=167902.29957635264 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:50 INFO 140434797135680] #quality_metric: host=algo-1, epoch=18, batch=0 train rmse <loss>=1.1086680736184917\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:50 INFO 140434797135680] #quality_metric: host=algo-1, epoch=18, batch=0 train mse <loss>=1.2291448974609376\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:50 INFO 140434797135680] #quality_metric: host=algo-1, epoch=18, batch=0 train absolute_loss <loss>=0.9217300415039062\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:50.553] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 38, \"duration\": 468, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:50 INFO 140434797135680] #quality_metric: host=algo-1, epoch=18, train rmse <loss>=1.0450567190196864\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:50 INFO 140434797135680] #quality_metric: host=algo-1, epoch=18, train mse <loss>=1.0921435459681919\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:50 INFO 140434797135680] #quality_metric: host=algo-1, epoch=18, train absolute_loss <loss>=0.845324715750558\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879370.082602, \"EndTime\": 1630879370.5547252, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 471.2071418762207, \"count\": 1, \"min\": 471.2071418762207, \"max\": 471.2071418762207}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:50 INFO 140434797135680] #progress_metric: host=algo-1, completed 9.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879370.083491, \"EndTime\": 1630879370.5550911, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1721830.0, \"count\": 1, \"min\": 1721830, \"max\": 1721830}, \"Total Batches Seen\": {\"sum\": 1730.0, \"count\": 1, \"min\": 1730, \"max\": 1730}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 20.0, \"count\": 1, \"min\": 20, \"max\": 20}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:50 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=192002.70167763118 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:50 INFO 140434797135680] #quality_metric: host=algo-1, epoch=19, batch=0 train rmse <loss>=1.1053895731362937\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:50 INFO 140434797135680] #quality_metric: host=algo-1, epoch=19, batch=0 train mse <loss>=1.2218861083984376\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:50 INFO 140434797135680] #quality_metric: host=algo-1, epoch=19, batch=0 train absolute_loss <loss>=0.9182962036132812\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:51.009] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 40, \"duration\": 452, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:51 INFO 140434797135680] #quality_metric: host=algo-1, epoch=19, train rmse <loss>=1.0423253693359167\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:51 INFO 140434797135680] #quality_metric: host=algo-1, epoch=19, train mse <loss>=1.0864421755612552\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:51 INFO 140434797135680] #quality_metric: host=algo-1, epoch=19, train absolute_loss <loss>=0.8424037643264938\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879370.5547898, \"EndTime\": 1630879371.0112472, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 455.4319381713867, \"count\": 1, \"min\": 455.4319381713867, \"max\": 455.4319381713867}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:51 INFO 140434797135680] #progress_metric: host=algo-1, completed 10.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879370.5557714, \"EndTime\": 1630879371.0117664, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1812400.0, \"count\": 1, \"min\": 1812400, \"max\": 1812400}, \"Total Batches Seen\": {\"sum\": 1821.0, \"count\": 1, \"min\": 1821, \"max\": 1821}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 21.0, \"count\": 1, \"min\": 21, \"max\": 21}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:51 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=198507.3276782397 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:51 INFO 140434797135680] #quality_metric: host=algo-1, epoch=20, batch=0 train rmse <loss>=1.102351667671778\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:51 INFO 140434797135680] #quality_metric: host=algo-1, epoch=20, batch=0 train mse <loss>=1.21517919921875\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:51 INFO 140434797135680] #quality_metric: host=algo-1, epoch=20, batch=0 train absolute_loss <loss>=0.915210205078125\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:51.680] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 42, \"duration\": 665, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:51 INFO 140434797135680] #quality_metric: host=algo-1, epoch=20, train rmse <loss>=1.0397489466886065\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:51 INFO 140434797135680] #quality_metric: host=algo-1, epoch=20, train mse <loss>=1.081077872140067\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:51 INFO 140434797135680] #quality_metric: host=algo-1, epoch=20, train absolute_loss <loss>=0.8397085162152301\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879371.0113277, \"EndTime\": 1630879371.6814024, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 668.6608791351318, \"count\": 1, \"min\": 668.6608791351318, \"max\": 668.6608791351318}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:51 INFO 140434797135680] #progress_metric: host=algo-1, completed 10.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879371.0127134, \"EndTime\": 1630879371.6817803, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1902970.0, \"count\": 1, \"min\": 1902970, \"max\": 1902970}, \"Total Batches Seen\": {\"sum\": 1912.0, \"count\": 1, \"min\": 1912, \"max\": 1912}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 22.0, \"count\": 1, \"min\": 22, \"max\": 22}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:51 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=135335.31649411816 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:51 INFO 140434797135680] #quality_metric: host=algo-1, epoch=21, batch=0 train rmse <loss>=1.0995279304873864\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:51 INFO 140434797135680] #quality_metric: host=algo-1, epoch=21, batch=0 train mse <loss>=1.208961669921875\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:51 INFO 140434797135680] #quality_metric: host=algo-1, epoch=21, batch=0 train absolute_loss <loss>=0.9123898315429687\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:52.107] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 44, \"duration\": 423, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:52 INFO 140434797135680] #quality_metric: host=algo-1, epoch=21, train rmse <loss>=1.0373118689226888\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:52 INFO 140434797135680] #quality_metric: host=algo-1, epoch=21, train mse <loss>=1.0760159134078813\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:52 INFO 140434797135680] #quality_metric: host=algo-1, epoch=21, train absolute_loss <loss>=0.8372138470660199\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879371.6815462, \"EndTime\": 1630879372.1080234, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 425.5039691925049, \"count\": 1, \"min\": 425.5039691925049, \"max\": 425.5039691925049}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:52 INFO 140434797135680] #progress_metric: host=algo-1, completed 11.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879371.682436, \"EndTime\": 1630879372.108359, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1993540.0, \"count\": 1, \"min\": 1993540, \"max\": 1993540}, \"Total Batches Seen\": {\"sum\": 2003.0, \"count\": 1, \"min\": 2003, \"max\": 2003}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:52 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=212581.6607842863 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:52 INFO 140434797135680] #quality_metric: host=algo-1, epoch=22, batch=0 train rmse <loss>=1.0968949205812173\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:52 INFO 140434797135680] #quality_metric: host=algo-1, epoch=22, batch=0 train mse <loss>=1.203178466796875\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:52 INFO 140434797135680] #quality_metric: host=algo-1, epoch=22, batch=0 train absolute_loss <loss>=0.9098331909179688\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:52.557] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 46, \"duration\": 447, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:52 INFO 140434797135680] #quality_metric: host=algo-1, epoch=22, train rmse <loss>=1.035000531582798\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:52 INFO 140434797135680] #quality_metric: host=algo-1, epoch=22, train mse <loss>=1.071226100376674\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:52 INFO 140434797135680] #quality_metric: host=algo-1, epoch=22, train absolute_loss <loss>=0.834889867090917\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879372.1080987, \"EndTime\": 1630879372.5584292, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 449.3892192840576, \"count\": 1, \"min\": 449.3892192840576, \"max\": 449.3892192840576}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:52 INFO 140434797135680] #progress_metric: host=algo-1, completed 11.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879372.1090102, \"EndTime\": 1630879372.5587027, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2084110.0, \"count\": 1, \"min\": 2084110, \"max\": 2084110}, \"Total Batches Seen\": {\"sum\": 2094.0, \"count\": 1, \"min\": 2094, \"max\": 2094}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 24.0, \"count\": 1, \"min\": 24, \"max\": 24}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:52 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=201339.61004964614 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:52 INFO 140434797135680] #quality_metric: host=algo-1, epoch=23, batch=0 train rmse <loss>=1.0944319302725045\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:52 INFO 140434797135680] #quality_metric: host=algo-1, epoch=23, batch=0 train mse <loss>=1.19778125\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:52 INFO 140434797135680] #quality_metric: host=algo-1, epoch=23, batch=0 train absolute_loss <loss>=0.9074754638671875\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:53.002] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 48, \"duration\": 441, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:53 INFO 140434797135680] #quality_metric: host=algo-1, epoch=23, train rmse <loss>=1.0328030991367805\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:53 INFO 140434797135680] #quality_metric: host=algo-1, epoch=23, train mse <loss>=1.0666822415865385\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:53 INFO 140434797135680] #quality_metric: host=algo-1, epoch=23, train absolute_loss <loss>=0.8327139966356886\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879372.5585096, \"EndTime\": 1630879373.0035353, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 444.14329528808594, \"count\": 1, \"min\": 444.14329528808594, \"max\": 444.14329528808594}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:53 INFO 140434797135680] #progress_metric: host=algo-1, completed 12.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879372.559364, \"EndTime\": 1630879373.0037825, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2174680.0, \"count\": 1, \"min\": 2174680, \"max\": 2174680}, \"Total Batches Seen\": {\"sum\": 2185.0, \"count\": 1, \"min\": 2185, \"max\": 2185}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 25.0, \"count\": 1, \"min\": 25, \"max\": 25}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:53 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=203726.447715601 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:53 INFO 140434797135680] #quality_metric: host=algo-1, epoch=24, batch=0 train rmse <loss>=1.0921207731762659\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:53 INFO 140434797135680] #quality_metric: host=algo-1, epoch=24, batch=0 train mse <loss>=1.192727783203125\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:53 INFO 140434797135680] #quality_metric: host=algo-1, epoch=24, batch=0 train absolute_loss <loss>=0.905296630859375\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:53.698] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 50, \"duration\": 692, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:53 INFO 140434797135680] #quality_metric: host=algo-1, epoch=24, train rmse <loss>=1.0307091417233865\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:53 INFO 140434797135680] #quality_metric: host=algo-1, epoch=24, train mse <loss>=1.06236133483216\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:53 INFO 140434797135680] #quality_metric: host=algo-1, epoch=24, train absolute_loss <loss>=0.8306669519445399\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879373.0036106, \"EndTime\": 1630879373.699473, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 695.030689239502, \"count\": 1, \"min\": 695.030689239502, \"max\": 695.030689239502}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:53 INFO 140434797135680] #progress_metric: host=algo-1, completed 12.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879373.0044138, \"EndTime\": 1630879373.700049, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2265250.0, \"count\": 1, \"min\": 2265250, \"max\": 2265250}, \"Total Batches Seen\": {\"sum\": 2276.0, \"count\": 1, \"min\": 2276, \"max\": 2276}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 26.0, \"count\": 1, \"min\": 26, \"max\": 26}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:53 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=130175.26639835104 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:53 INFO 140434797135680] #quality_metric: host=algo-1, epoch=25, batch=0 train rmse <loss>=1.0899453357673208\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:53 INFO 140434797135680] #quality_metric: host=algo-1, epoch=25, batch=0 train mse <loss>=1.1879808349609375\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:53 INFO 140434797135680] #quality_metric: host=algo-1, epoch=25, batch=0 train absolute_loss <loss>=0.903294677734375\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:54.180] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 52, \"duration\": 477, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:54 INFO 140434797135680] #quality_metric: host=algo-1, epoch=25, train rmse <loss>=1.0287095106452668\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:54 INFO 140434797135680] #quality_metric: host=algo-1, epoch=25, train mse <loss>=1.0582432572920244\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:54 INFO 140434797135680] #quality_metric: host=algo-1, epoch=25, train absolute_loss <loss>=0.8287372765174279\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879373.6997683, \"EndTime\": 1630879374.1812348, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 480.41272163391113, \"count\": 1, \"min\": 480.41272163391113, \"max\": 480.41272163391113}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:54 INFO 140434797135680] #progress_metric: host=algo-1, completed 13.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879373.700758, \"EndTime\": 1630879374.1816325, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2355820.0, \"count\": 1, \"min\": 2355820, \"max\": 2355820}, \"Total Batches Seen\": {\"sum\": 2367.0, \"count\": 1, \"min\": 2367, \"max\": 2367}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 27.0, \"count\": 1, \"min\": 27, \"max\": 27}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:54 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=188280.867043944 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:54 INFO 140434797135680] #quality_metric: host=algo-1, epoch=26, batch=0 train rmse <loss>=1.0878916769519151\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:54 INFO 140434797135680] #quality_metric: host=algo-1, epoch=26, batch=0 train mse <loss>=1.18350830078125\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:54 INFO 140434797135680] #quality_metric: host=algo-1, epoch=26, batch=0 train absolute_loss <loss>=0.9014607543945312\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:54.623] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 54, \"duration\": 439, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:54 INFO 140434797135680] #quality_metric: host=algo-1, epoch=26, train rmse <loss>=1.0267961097945604\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:54 INFO 140434797135680] #quality_metric: host=algo-1, epoch=26, train mse <loss>=1.0543102510892428\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:54 INFO 140434797135680] #quality_metric: host=algo-1, epoch=26, train absolute_loss <loss>=0.826911638532366\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879374.18131, \"EndTime\": 1630879374.6241493, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 441.7285919189453, \"count\": 1, \"min\": 441.7285919189453, \"max\": 441.7285919189453}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:54 INFO 140434797135680] #progress_metric: host=algo-1, completed 13.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879374.1823921, \"EndTime\": 1630879374.624416, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2446390.0, \"count\": 1, \"min\": 2446390, \"max\": 2446390}, \"Total Batches Seen\": {\"sum\": 2458.0, \"count\": 1, \"min\": 2458, \"max\": 2458}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 28.0, \"count\": 1, \"min\": 28, \"max\": 28}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:54 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=204811.3288810317 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:54 INFO 140434797135680] #quality_metric: host=algo-1, epoch=27, batch=0 train rmse <loss>=1.0859472796322227\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:54 INFO 140434797135680] #quality_metric: host=algo-1, epoch=27, batch=0 train mse <loss>=1.179281494140625\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:54 INFO 140434797135680] #quality_metric: host=algo-1, epoch=27, batch=0 train absolute_loss <loss>=0.899763427734375\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:55.183] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 56, \"duration\": 557, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:55 INFO 140434797135680] #quality_metric: host=algo-1, epoch=27, train rmse <loss>=1.0249618250788404\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:55 INFO 140434797135680] #quality_metric: host=algo-1, epoch=27, train mse <loss>=1.0505467428689474\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:55 INFO 140434797135680] #quality_metric: host=algo-1, epoch=27, train absolute_loss <loss>=0.8251770549396892\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879374.624233, \"EndTime\": 1630879375.1852424, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 560.1046085357666, \"count\": 1, \"min\": 560.1046085357666, \"max\": 560.1046085357666}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:55 INFO 140434797135680] #progress_metric: host=algo-1, completed 14.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879374.6251097, \"EndTime\": 1630879375.1858153, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2536960.0, \"count\": 1, \"min\": 2536960, \"max\": 2536960}, \"Total Batches Seen\": {\"sum\": 2549.0, \"count\": 1, \"min\": 2549, \"max\": 2549}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 29.0, \"count\": 1, \"min\": 29, \"max\": 29}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:55 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=161488.97814820686 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:55 INFO 140434797135680] #quality_metric: host=algo-1, epoch=28, batch=0 train rmse <loss>=1.0841013028152051\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:55 INFO 140434797135680] #quality_metric: host=algo-1, epoch=28, batch=0 train mse <loss>=1.175275634765625\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:55 INFO 140434797135680] #quality_metric: host=algo-1, epoch=28, batch=0 train absolute_loss <loss>=0.8981934204101563\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:55.708] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 58, \"duration\": 519, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:55 INFO 140434797135680] #quality_metric: host=algo-1, epoch=28, train rmse <loss>=1.0232002663661992\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:55 INFO 140434797135680] #quality_metric: host=algo-1, epoch=28, train mse <loss>=1.0469387850918612\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:55 INFO 140434797135680] #quality_metric: host=algo-1, epoch=28, train absolute_loss <loss>=0.8235225689227764\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879375.185325, \"EndTime\": 1630879375.70922, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 522.3538875579834, \"count\": 1, \"min\": 522.3538875579834, \"max\": 522.3538875579834}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:55 INFO 140434797135680] #progress_metric: host=algo-1, completed 14.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879375.1868415, \"EndTime\": 1630879375.7096024, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2627530.0, \"count\": 1, \"min\": 2627530, \"max\": 2627530}, \"Total Batches Seen\": {\"sum\": 2640.0, \"count\": 1, \"min\": 2640, \"max\": 2640}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 30.0, \"count\": 1, \"min\": 30, \"max\": 30}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:55 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=173213.31876050727 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:55 INFO 140434797135680] #quality_metric: host=algo-1, epoch=29, batch=0 train rmse <loss>=1.082344212411479\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:55 INFO 140434797135680] #quality_metric: host=algo-1, epoch=29, batch=0 train mse <loss>=1.171468994140625\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:55 INFO 140434797135680] #quality_metric: host=algo-1, epoch=29, batch=0 train absolute_loss <loss>=0.8967451171875\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:56.145] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 60, \"duration\": 434, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:56 INFO 140434797135680] #quality_metric: host=algo-1, epoch=29, train rmse <loss>=1.0215057416595315\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:56 INFO 140434797135680] #quality_metric: host=algo-1, epoch=29, train mse <loss>=1.0434739802433894\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:56 INFO 140434797135680] #quality_metric: host=algo-1, epoch=29, train absolute_loss <loss>=0.8219425283578726\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879375.709283, \"EndTime\": 1630879376.1468806, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 436.5971088409424, \"count\": 1, \"min\": 436.5971088409424, \"max\": 436.5971088409424}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:56 INFO 140434797135680] #progress_metric: host=algo-1, completed 15.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879375.710255, \"EndTime\": 1630879376.147259, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2718100.0, \"count\": 1, \"min\": 2718100, \"max\": 2718100}, \"Total Batches Seen\": {\"sum\": 2731.0, \"count\": 1, \"min\": 2731, \"max\": 2731}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 31.0, \"count\": 1, \"min\": 31, \"max\": 31}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:56 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=207197.12693368766 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:56 INFO 140434797135680] #quality_metric: host=algo-1, epoch=30, batch=0 train rmse <loss>=1.0806676312802541\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:56 INFO 140434797135680] #quality_metric: host=algo-1, epoch=30, batch=0 train mse <loss>=1.167842529296875\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:56 INFO 140434797135680] #quality_metric: host=algo-1, epoch=30, batch=0 train absolute_loss <loss>=0.8953781127929688\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:56.606] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 62, \"duration\": 456, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:56 INFO 140434797135680] #quality_metric: host=algo-1, epoch=30, train rmse <loss>=1.0198731933888816\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:56 INFO 140434797135680] #quality_metric: host=algo-1, epoch=30, train mse <loss>=1.040141330593235\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:56 INFO 140434797135680] #quality_metric: host=algo-1, epoch=30, train absolute_loss <loss>=0.8204280831473214\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879376.1469479, \"EndTime\": 1630879376.6070669, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 459.09881591796875, \"count\": 1, \"min\": 459.09881591796875, \"max\": 459.09881591796875}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:56 INFO 140434797135680] #progress_metric: host=algo-1, completed 15.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879376.1479397, \"EndTime\": 1630879376.6074288, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 30, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2808670.0, \"count\": 1, \"min\": 2808670, \"max\": 2808670}, \"Total Batches Seen\": {\"sum\": 2822.0, \"count\": 1, \"min\": 2822, \"max\": 2822}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 32.0, \"count\": 1, \"min\": 32, \"max\": 32}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:56 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=197049.69334935828 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:56 INFO 140434797135680] #quality_metric: host=algo-1, epoch=31, batch=0 train rmse <loss>=1.0790642421431056\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:56 INFO 140434797135680] #quality_metric: host=algo-1, epoch=31, batch=0 train mse <loss>=1.164379638671875\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:56 INFO 140434797135680] #quality_metric: host=algo-1, epoch=31, batch=0 train absolute_loss <loss>=0.8940814819335937\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:57.033] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 64, \"duration\": 423, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:57 INFO 140434797135680] #quality_metric: host=algo-1, epoch=31, train rmse <loss>=1.0182980402677306\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:57 INFO 140434797135680] #quality_metric: host=algo-1, epoch=31, train mse <loss>=1.036930898813101\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:57 INFO 140434797135680] #quality_metric: host=algo-1, epoch=31, train absolute_loss <loss>=0.8189733376974588\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879376.607184, \"EndTime\": 1630879377.0339985, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 425.86350440979004, \"count\": 1, \"min\": 425.86350440979004, \"max\": 425.86350440979004}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:57 INFO 140434797135680] #progress_metric: host=algo-1, completed 16.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879376.6081, \"EndTime\": 1630879377.0343335, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 31, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2899240.0, \"count\": 1, \"min\": 2899240, \"max\": 2899240}, \"Total Batches Seen\": {\"sum\": 2913.0, \"count\": 1, \"min\": 2913, \"max\": 2913}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 33.0, \"count\": 1, \"min\": 33, \"max\": 33}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:57 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=212422.9654142738 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:57 INFO 140434797135680] #quality_metric: host=algo-1, epoch=32, batch=0 train rmse <loss>=1.0775275745094068\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:57 INFO 140434797135680] #quality_metric: host=algo-1, epoch=32, batch=0 train mse <loss>=1.161065673828125\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:57 INFO 140434797135680] #quality_metric: host=algo-1, epoch=32, batch=0 train absolute_loss <loss>=0.8928479614257813\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:57.486] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 66, \"duration\": 450, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:57 INFO 140434797135680] #quality_metric: host=algo-1, epoch=32, train rmse <loss>=1.0167761693043298\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:57 INFO 140434797135680] #quality_metric: host=algo-1, epoch=32, train mse <loss>=1.0338337784651872\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:57 INFO 140434797135680] #quality_metric: host=algo-1, epoch=32, train absolute_loss <loss>=0.817573962536487\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879377.0340748, \"EndTime\": 1630879377.4875782, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 452.5461196899414, \"count\": 1, \"min\": 452.5461196899414, \"max\": 452.5461196899414}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:57 INFO 140434797135680] #progress_metric: host=algo-1, completed 16.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879377.0350046, \"EndTime\": 1630879377.4879441, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 32, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2989810.0, \"count\": 1, \"min\": 2989810, \"max\": 2989810}, \"Total Batches Seen\": {\"sum\": 3004.0, \"count\": 1, \"min\": 3004, \"max\": 3004}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 34.0, \"count\": 1, \"min\": 34, \"max\": 34}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:57 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=199896.92179943906 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:57 INFO 140434797135680] #quality_metric: host=algo-1, epoch=33, batch=0 train rmse <loss>=1.0760520719386388\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:57 INFO 140434797135680] #quality_metric: host=algo-1, epoch=33, batch=0 train mse <loss>=1.1578880615234375\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:57 INFO 140434797135680] #quality_metric: host=algo-1, epoch=33, batch=0 train absolute_loss <loss>=0.8916749877929687\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:57.914] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 68, \"duration\": 424, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:57 INFO 140434797135680] #quality_metric: host=algo-1, epoch=33, train rmse <loss>=1.0153038647249208\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:57 INFO 140434797135680] #quality_metric: host=algo-1, epoch=33, train mse <loss>=1.0308419377253606\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:57 INFO 140434797135680] #quality_metric: host=algo-1, epoch=33, train absolute_loss <loss>=0.8162263773823832\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879377.4876976, \"EndTime\": 1630879377.9156375, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 427.0038604736328, \"count\": 1, \"min\": 427.0038604736328, \"max\": 427.0038604736328}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:57 INFO 140434797135680] #progress_metric: host=algo-1, completed 17.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879377.4886065, \"EndTime\": 1630879377.9160032, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 33, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3080380.0, \"count\": 1, \"min\": 3080380, \"max\": 3080380}, \"Total Batches Seen\": {\"sum\": 3095.0, \"count\": 1, \"min\": 3095, \"max\": 3095}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 35.0, \"count\": 1, \"min\": 35, \"max\": 35}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:57 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=211842.1588957921 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:57 INFO 140434797135680] #quality_metric: host=algo-1, epoch=34, batch=0 train rmse <loss>=1.0746328179240456\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:57 INFO 140434797135680] #quality_metric: host=algo-1, epoch=34, batch=0 train mse <loss>=1.154835693359375\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:57 INFO 140434797135680] #quality_metric: host=algo-1, epoch=34, batch=0 train absolute_loss <loss>=0.8905785522460937\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:58.372] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 70, \"duration\": 454, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:58 INFO 140434797135680] #quality_metric: host=algo-1, epoch=34, train rmse <loss>=1.0138777774547303\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:58 INFO 140434797135680] #quality_metric: host=algo-1, epoch=34, train mse <loss>=1.0279481476165435\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:58 INFO 140434797135680] #quality_metric: host=algo-1, epoch=34, train absolute_loss <loss>=0.8149244867681147\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879377.9157302, \"EndTime\": 1630879378.373295, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 456.5145969390869, \"count\": 1, \"min\": 456.5145969390869, \"max\": 456.5145969390869}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:58 INFO 140434797135680] #progress_metric: host=algo-1, completed 17.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879377.9167576, \"EndTime\": 1630879378.3736653, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 34, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3170950.0, \"count\": 1, \"min\": 3170950, \"max\": 3170950}, \"Total Batches Seen\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 36.0, \"count\": 1, \"min\": 36, \"max\": 36}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:58 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=198170.3597893921 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:58 INFO 140434797135680] #quality_metric: host=algo-1, epoch=35, batch=0 train rmse <loss>=1.0732654292581238\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:58 INFO 140434797135680] #quality_metric: host=algo-1, epoch=35, batch=0 train mse <loss>=1.151898681640625\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:58 INFO 140434797135680] #quality_metric: host=algo-1, epoch=35, batch=0 train absolute_loss <loss>=0.88955517578125\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:58.823] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 72, \"duration\": 447, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:58 INFO 140434797135680] #quality_metric: host=algo-1, epoch=35, train rmse <loss>=1.012494846900679\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:58 INFO 140434797135680] #quality_metric: host=algo-1, epoch=35, train mse <loss>=1.0251458150004293\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:58 INFO 140434797135680] #quality_metric: host=algo-1, epoch=35, train absolute_loss <loss>=0.81366357757233\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879378.3733578, \"EndTime\": 1630879378.8244019, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 450.06346702575684, \"count\": 1, \"min\": 450.06346702575684, \"max\": 450.06346702575684}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:58 INFO 140434797135680] #progress_metric: host=algo-1, completed 18.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879378.3743105, \"EndTime\": 1630879378.824824, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 35, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3261520.0, \"count\": 1, \"min\": 3261520, \"max\": 3261520}, \"Total Batches Seen\": {\"sum\": 3277.0, \"count\": 1, \"min\": 3277, \"max\": 3277}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 37.0, \"count\": 1, \"min\": 37, \"max\": 37}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:58 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=200965.6393392669 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:58 INFO 140434797135680] #quality_metric: host=algo-1, epoch=36, batch=0 train rmse <loss>=1.0719461756616444\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:58 INFO 140434797135680] #quality_metric: host=algo-1, epoch=36, batch=0 train mse <loss>=1.149068603515625\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:58 INFO 140434797135680] #quality_metric: host=algo-1, epoch=36, batch=0 train absolute_loss <loss>=0.8885792846679688\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:59.271] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 74, \"duration\": 444, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:59 INFO 140434797135680] #quality_metric: host=algo-1, epoch=36, train rmse <loss>=1.0111523394985433\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:59 INFO 140434797135680] #quality_metric: host=algo-1, epoch=36, train mse <loss>=1.0224290536733773\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:59 INFO 140434797135680] #quality_metric: host=algo-1, epoch=36, train absolute_loss <loss>=0.8124422204992273\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879378.824484, \"EndTime\": 1630879379.2724872, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 446.7933177947998, \"count\": 1, \"min\": 446.7933177947998, \"max\": 446.7933177947998}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:59 INFO 140434797135680] #progress_metric: host=algo-1, completed 18.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879378.8256679, \"EndTime\": 1630879379.2727056, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 36, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3352090.0, \"count\": 1, \"min\": 3352090, \"max\": 3352090}, \"Total Batches Seen\": {\"sum\": 3368.0, \"count\": 1, \"min\": 3368, \"max\": 3368}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 38.0, \"count\": 1, \"min\": 38, \"max\": 38}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:59 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=202543.11195377124 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:59 INFO 140434797135680] #quality_metric: host=algo-1, epoch=37, batch=0 train rmse <loss>=1.0706717006743944\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:59 INFO 140434797135680] #quality_metric: host=algo-1, epoch=37, batch=0 train mse <loss>=1.146337890625\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:59 INFO 140434797135680] #quality_metric: host=algo-1, epoch=37, batch=0 train absolute_loss <loss>=0.8876399536132813\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:02:59.729] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 76, \"duration\": 454, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:59 INFO 140434797135680] #quality_metric: host=algo-1, epoch=37, train rmse <loss>=1.0098477155998016\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:59 INFO 140434797135680] #quality_metric: host=algo-1, epoch=37, train mse <loss>=1.0197924087021377\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:59 INFO 140434797135680] #quality_metric: host=algo-1, epoch=37, train absolute_loss <loss>=0.8112574965927627\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879379.2725563, \"EndTime\": 1630879379.7302706, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 456.87150955200195, \"count\": 1, \"min\": 456.87150955200195, \"max\": 456.87150955200195}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:59 INFO 140434797135680] #progress_metric: host=algo-1, completed 19.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879379.27337, \"EndTime\": 1630879379.7306666, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 37, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3442660.0, \"count\": 1, \"min\": 3442660, \"max\": 3442660}, \"Total Batches Seen\": {\"sum\": 3459.0, \"count\": 1, \"min\": 3459, \"max\": 3459}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 39.0, \"count\": 1, \"min\": 39, \"max\": 39}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:59 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=197999.72442104286 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:59 INFO 140434797135680] #quality_metric: host=algo-1, epoch=38, batch=0 train rmse <loss>=1.0694390824969298\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:59 INFO 140434797135680] #quality_metric: host=algo-1, epoch=38, batch=0 train mse <loss>=1.143699951171875\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:02:59 INFO 140434797135680] #quality_metric: host=algo-1, epoch=38, batch=0 train absolute_loss <loss>=0.886734130859375\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:00.281] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 78, \"duration\": 548, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:00 INFO 140434797135680] #quality_metric: host=algo-1, epoch=38, train rmse <loss>=1.0085786809613904\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:00 INFO 140434797135680] #quality_metric: host=algo-1, epoch=38, train mse <loss>=1.017230955689818\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:00 INFO 140434797135680] #quality_metric: host=algo-1, epoch=38, train absolute_loss <loss>=0.8101090195205185\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879379.730345, \"EndTime\": 1630879380.2828493, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 551.3916015625, \"count\": 1, \"min\": 551.3916015625, \"max\": 551.3916015625}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:00 INFO 140434797135680] #progress_metric: host=algo-1, completed 19.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879379.731386, \"EndTime\": 1630879380.2832813, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 38, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3533230.0, \"count\": 1, \"min\": 3533230, \"max\": 3533230}, \"Total Batches Seen\": {\"sum\": 3550.0, \"count\": 1, \"min\": 3550, \"max\": 3550}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 40.0, \"count\": 1, \"min\": 40, \"max\": 40}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:00 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=164051.48606216177 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:00 INFO 140434797135680] #quality_metric: host=algo-1, epoch=39, batch=0 train rmse <loss>=1.0682457806383148\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:00 INFO 140434797135680] #quality_metric: host=algo-1, epoch=39, batch=0 train mse <loss>=1.1411490478515625\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:00 INFO 140434797135680] #quality_metric: host=algo-1, epoch=39, batch=0 train absolute_loss <loss>=0.8858675537109375\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:00.860] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 80, \"duration\": 574, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:00 INFO 140434797135680] #quality_metric: host=algo-1, epoch=39, train rmse <loss>=1.0073431771894363\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:00 INFO 140434797135680] #quality_metric: host=algo-1, epoch=39, train mse <loss>=1.0147402766301081\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:00 INFO 140434797135680] #quality_metric: host=algo-1, epoch=39, train absolute_loss <loss>=0.8089926395625858\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879380.282933, \"EndTime\": 1630879380.8617558, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 577.4729251861572, \"count\": 1, \"min\": 577.4729251861572, \"max\": 577.4729251861572}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:00 INFO 140434797135680] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879380.284187, \"EndTime\": 1630879380.862138, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 39, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3623800.0, \"count\": 1, \"min\": 3623800, \"max\": 3623800}, \"Total Batches Seen\": {\"sum\": 3641.0, \"count\": 1, \"min\": 3641, \"max\": 3641}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 41.0, \"count\": 1, \"min\": 41, \"max\": 41}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:00 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=156667.694934463 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:00 INFO 140434797135680] #quality_metric: host=algo-1, epoch=40, batch=0 train rmse <loss>=1.067089353100292\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:00 INFO 140434797135680] #quality_metric: host=algo-1, epoch=40, batch=0 train mse <loss>=1.1386796875\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:00 INFO 140434797135680] #quality_metric: host=algo-1, epoch=40, batch=0 train absolute_loss <loss>=0.8850537719726562\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:01.409] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 82, \"duration\": 545, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:01 INFO 140434797135680] #quality_metric: host=algo-1, epoch=40, train rmse <loss>=1.0061392709434194\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:01 INFO 140434797135680] #quality_metric: host=algo-1, epoch=40, train mse <loss>=1.0123162325345554\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:01 INFO 140434797135680] #quality_metric: host=algo-1, epoch=40, train absolute_loss <loss>=0.80790626341432\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879380.8618202, \"EndTime\": 1630879381.4104774, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 547.5919246673584, \"count\": 1, \"min\": 547.5919246673584, \"max\": 547.5919246673584}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:01 INFO 140434797135680] #progress_metric: host=algo-1, completed 20.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879380.862804, \"EndTime\": 1630879381.4110632, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 40, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3714370.0, \"count\": 1, \"min\": 3714370, \"max\": 3714370}, \"Total Batches Seen\": {\"sum\": 3732.0, \"count\": 1, \"min\": 3732, \"max\": 3732}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 42.0, \"count\": 1, \"min\": 42, \"max\": 42}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:01 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=165150.5387939186 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:01 INFO 140434797135680] #quality_metric: host=algo-1, epoch=41, batch=0 train rmse <loss>=1.0659679158662563\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:01 INFO 140434797135680] #quality_metric: host=algo-1, epoch=41, batch=0 train mse <loss>=1.13628759765625\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:01 INFO 140434797135680] #quality_metric: host=algo-1, epoch=41, batch=0 train absolute_loss <loss>=0.8842950439453126\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:02.159] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 84, \"duration\": 744, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:02 INFO 140434797135680] #quality_metric: host=algo-1, epoch=41, train rmse <loss>=1.0049652357545111\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:02 INFO 140434797135680] #quality_metric: host=algo-1, epoch=41, train mse <loss>=1.0099551250751202\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:02 INFO 140434797135680] #quality_metric: host=algo-1, epoch=41, train absolute_loss <loss>=0.8068459070226648\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879381.4105675, \"EndTime\": 1630879382.1599674, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 747.8249073028564, \"count\": 1, \"min\": 747.8249073028564, \"max\": 747.8249073028564}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:02 INFO 140434797135680] #progress_metric: host=algo-1, completed 21.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879381.4120913, \"EndTime\": 1630879382.1603644, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 41, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3804940.0, \"count\": 1, \"min\": 3804940, \"max\": 3804940}, \"Total Batches Seen\": {\"sum\": 3823.0, \"count\": 1, \"min\": 3823, \"max\": 3823}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:02 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=121010.92897087001 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:02 INFO 140434797135680] #quality_metric: host=algo-1, epoch=42, batch=0 train rmse <loss>=1.0648795160904647\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:02 INFO 140434797135680] #quality_metric: host=algo-1, epoch=42, batch=0 train mse <loss>=1.1339683837890624\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:02 INFO 140434797135680] #quality_metric: host=algo-1, epoch=42, batch=0 train absolute_loss <loss>=0.883564697265625\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:02.596] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 86, \"duration\": 434, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:02 INFO 140434797135680] #quality_metric: host=algo-1, epoch=42, train rmse <loss>=1.0038194335269748\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:02 INFO 140434797135680] #quality_metric: host=algo-1, epoch=42, train mse <loss>=1.0076534551264165\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:02 INFO 140434797135680] #quality_metric: host=algo-1, epoch=42, train absolute_loss <loss>=0.8058101840176425\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879382.160059, \"EndTime\": 1630879382.5975742, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 436.4619255065918, \"count\": 1, \"min\": 436.4619255065918, \"max\": 436.4619255065918}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:02 INFO 140434797135680] #progress_metric: host=algo-1, completed 21.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879382.1610892, \"EndTime\": 1630879382.597949, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 42, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3895510.0, \"count\": 1, \"min\": 3895510, \"max\": 3895510}, \"Total Batches Seen\": {\"sum\": 3914.0, \"count\": 1, \"min\": 3914, \"max\": 3914}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 44.0, \"count\": 1, \"min\": 44, \"max\": 44}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:02 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=207262.01593155976 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:02 INFO 140434797135680] #quality_metric: host=algo-1, epoch=43, batch=0 train rmse <loss>=1.063822533973154\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:02 INFO 140434797135680] #quality_metric: host=algo-1, epoch=43, batch=0 train mse <loss>=1.1317183837890625\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:02 INFO 140434797135680] #quality_metric: host=algo-1, epoch=43, batch=0 train absolute_loss <loss>=0.8828555297851562\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:03.139] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 88, \"duration\": 539, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:03 INFO 140434797135680] #quality_metric: host=algo-1, epoch=43, train rmse <loss>=1.0027004339278884\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:03 INFO 140434797135680] #quality_metric: host=algo-1, epoch=43, train mse <loss>=1.0054081601991758\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:03 INFO 140434797135680] #quality_metric: host=algo-1, epoch=43, train absolute_loss <loss>=0.8047976563841432\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879382.5976372, \"EndTime\": 1630879383.141597, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 542.9418087005615, \"count\": 1, \"min\": 542.9418087005615, \"max\": 542.9418087005615}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:03 INFO 140434797135680] #progress_metric: host=algo-1, completed 22.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879382.5986266, \"EndTime\": 1630879383.1435127, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 43, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3986080.0, \"count\": 1, \"min\": 3986080, \"max\": 3986080}, \"Total Batches Seen\": {\"sum\": 4005.0, \"count\": 1, \"min\": 4005, \"max\": 4005}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 45.0, \"count\": 1, \"min\": 45, \"max\": 45}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:03 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=166071.14553287035 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:03 INFO 140434797135680] #quality_metric: host=algo-1, epoch=44, batch=0 train rmse <loss>=1.0627954552440935\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:03 INFO 140434797135680] #quality_metric: host=algo-1, epoch=44, batch=0 train mse <loss>=1.1295341796875\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:03 INFO 140434797135680] #quality_metric: host=algo-1, epoch=44, batch=0 train absolute_loss <loss>=0.882166015625\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:03.755] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 90, \"duration\": 608, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:03 INFO 140434797135680] #quality_metric: host=algo-1, epoch=44, train rmse <loss>=1.001606875010755\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:03 INFO 140434797135680] #quality_metric: host=algo-1, epoch=44, train mse <loss>=1.0032163320688101\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:03 INFO 140434797135680] #quality_metric: host=algo-1, epoch=44, train absolute_loss <loss>=0.8038084824111436\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879383.141974, \"EndTime\": 1630879383.7565858, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 611.7374897003174, \"count\": 1, \"min\": 611.7374897003174, \"max\": 611.7374897003174}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:03 INFO 140434797135680] #progress_metric: host=algo-1, completed 22.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879383.1447935, \"EndTime\": 1630879383.7571747, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 44, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4076650.0, \"count\": 1, \"min\": 4076650, \"max\": 4076650}, \"Total Batches Seen\": {\"sum\": 4096.0, \"count\": 1, \"min\": 4096, \"max\": 4096}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 46.0, \"count\": 1, \"min\": 46, \"max\": 46}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:03 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=147842.52415471157 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:03 INFO 140434797135680] #quality_metric: host=algo-1, epoch=45, batch=0 train rmse <loss>=1.061796929608747\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:03 INFO 140434797135680] #quality_metric: host=algo-1, epoch=45, batch=0 train mse <loss>=1.1274127197265624\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:03 INFO 140434797135680] #quality_metric: host=algo-1, epoch=45, batch=0 train absolute_loss <loss>=0.8815128173828125\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:04.332] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 92, \"duration\": 572, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:04 INFO 140434797135680] #quality_metric: host=algo-1, epoch=45, train rmse <loss>=1.0005375132250987\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:04 INFO 140434797135680] #quality_metric: host=algo-1, epoch=45, train mse <loss>=1.0010753153706644\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:04 INFO 140434797135680] #quality_metric: host=algo-1, epoch=45, train absolute_loss <loss>=0.8028415648072631\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879383.7568169, \"EndTime\": 1630879384.3336449, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 575.4287242889404, \"count\": 1, \"min\": 575.4287242889404, \"max\": 575.4287242889404}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:04 INFO 140434797135680] #progress_metric: host=algo-1, completed 23.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879383.7581508, \"EndTime\": 1630879384.334003, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 45, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4167220.0, \"count\": 1, \"min\": 4167220, \"max\": 4167220}, \"Total Batches Seen\": {\"sum\": 4187.0, \"count\": 1, \"min\": 4187, \"max\": 4187}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 47.0, \"count\": 1, \"min\": 47, \"max\": 47}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:04 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=157241.15215272186 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:04 INFO 140434797135680] #quality_metric: host=algo-1, epoch=46, batch=0 train rmse <loss>=1.060825714379635\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:04 INFO 140434797135680] #quality_metric: host=algo-1, epoch=46, batch=0 train mse <loss>=1.1253511962890625\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:04 INFO 140434797135680] #quality_metric: host=algo-1, epoch=46, batch=0 train absolute_loss <loss>=0.880883056640625\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:04.890] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 94, \"duration\": 554, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:04 INFO 140434797135680] #quality_metric: host=algo-1, epoch=46, train rmse <loss>=0.9994911824325999\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:04 INFO 140434797135680] #quality_metric: host=algo-1, epoch=46, train mse <loss>=0.9989826237605168\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:04 INFO 140434797135680] #quality_metric: host=algo-1, epoch=46, train absolute_loss <loss>=0.8018959598750859\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879384.333716, \"EndTime\": 1630879384.8921554, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 557.4414730072021, \"count\": 1, \"min\": 557.4414730072021, \"max\": 557.4414730072021}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:04 INFO 140434797135680] #progress_metric: host=algo-1, completed 23.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879384.334687, \"EndTime\": 1630879384.8928235, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 46, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4257790.0, \"count\": 1, \"min\": 4257790, \"max\": 4257790}, \"Total Batches Seen\": {\"sum\": 4278.0, \"count\": 1, \"min\": 4278, \"max\": 4278}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 48.0, \"count\": 1, \"min\": 48, \"max\": 48}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:04 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=162160.82605616577 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:04 INFO 140434797135680] #quality_metric: host=algo-1, epoch=47, batch=0 train rmse <loss>=1.059880617724527\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:04 INFO 140434797135680] #quality_metric: host=algo-1, epoch=47, batch=0 train mse <loss>=1.123346923828125\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:04 INFO 140434797135680] #quality_metric: host=algo-1, epoch=47, batch=0 train absolute_loss <loss>=0.8802774658203125\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:05.737] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 96, \"duration\": 842, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:05 INFO 140434797135680] #quality_metric: host=algo-1, epoch=47, train rmse <loss>=0.9984668174372475\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:05 INFO 140434797135680] #quality_metric: host=algo-1, epoch=47, train mse <loss>=0.9969359855232658\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:05 INFO 140434797135680] #quality_metric: host=algo-1, epoch=47, train absolute_loss <loss>=0.8009691235888136\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879384.89248, \"EndTime\": 1630879385.738873, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 844.9177742004395, \"count\": 1, \"min\": 844.9177742004395, \"max\": 844.9177742004395}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:05 INFO 140434797135680] #progress_metric: host=algo-1, completed 24.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879384.8939283, \"EndTime\": 1630879385.7398067, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 47, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4348360.0, \"count\": 1, \"min\": 4348360, \"max\": 4348360}, \"Total Batches Seen\": {\"sum\": 4369.0, \"count\": 1, \"min\": 4369, \"max\": 4369}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 49.0, \"count\": 1, \"min\": 49, \"max\": 49}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:05 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=107035.95964013107 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:05 INFO 140434797135680] #quality_metric: host=algo-1, epoch=48, batch=0 train rmse <loss>=1.058960614474312\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:05 INFO 140434797135680] #quality_metric: host=algo-1, epoch=48, batch=0 train mse <loss>=1.1213975830078124\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:05 INFO 140434797135680] #quality_metric: host=algo-1, epoch=48, batch=0 train absolute_loss <loss>=0.8796923217773438\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:06.549] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 98, \"duration\": 806, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:06 INFO 140434797135680] #quality_metric: host=algo-1, epoch=48, train rmse <loss>=0.997463463833269\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:06 INFO 140434797135680] #quality_metric: host=algo-1, epoch=48, train mse <loss>=0.9949333616822631\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:06 INFO 140434797135680] #quality_metric: host=algo-1, epoch=48, train absolute_loss <loss>=0.8000590330689819\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879385.7393749, \"EndTime\": 1630879386.550108, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 809.3521595001221, \"count\": 1, \"min\": 809.3521595001221, \"max\": 809.3521595001221}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:06 INFO 140434797135680] #progress_metric: host=algo-1, completed 24.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879385.740727, \"EndTime\": 1630879386.5505438, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 48, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4438930.0, \"count\": 1, \"min\": 4438930, \"max\": 4438930}, \"Total Batches Seen\": {\"sum\": 4460.0, \"count\": 1, \"min\": 4460, \"max\": 4460}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 50.0, \"count\": 1, \"min\": 50, \"max\": 50}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:06 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=111818.93686708204 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:06 INFO 140434797135680] #quality_metric: host=algo-1, epoch=49, batch=0 train rmse <loss>=1.0580646163736291\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:06 INFO 140434797135680] #quality_metric: host=algo-1, epoch=49, batch=0 train mse <loss>=1.119500732421875\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:06 INFO 140434797135680] #quality_metric: host=algo-1, epoch=49, batch=0 train absolute_loss <loss>=0.8791204223632813\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:07.136] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 100, \"duration\": 583, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:07 INFO 140434797135680] #quality_metric: host=algo-1, epoch=49, train rmse <loss>=0.996480151904382\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:07 INFO 140434797135680] #quality_metric: host=algo-1, epoch=49, train mse <loss>=0.9929726931393802\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:07 INFO 140434797135680] #quality_metric: host=algo-1, epoch=49, train absolute_loss <loss>=0.7991652154608088\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879386.550183, \"EndTime\": 1630879387.1380587, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 586.5015983581543, \"count\": 1, \"min\": 586.5015983581543, \"max\": 586.5015983581543}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:07 INFO 140434797135680] #progress_metric: host=algo-1, completed 25.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879386.5514774, \"EndTime\": 1630879387.1384795, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 49, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4529500.0, \"count\": 1, \"min\": 4529500, \"max\": 4529500}, \"Total Batches Seen\": {\"sum\": 4551.0, \"count\": 1, \"min\": 4551, \"max\": 4551}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 51.0, \"count\": 1, \"min\": 51, \"max\": 51}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:07 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=154226.5182910441 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:07 INFO 140434797135680] #quality_metric: host=algo-1, epoch=50, batch=0 train rmse <loss>=1.0571917029919409\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:07 INFO 140434797135680] #quality_metric: host=algo-1, epoch=50, batch=0 train mse <loss>=1.117654296875\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:07 INFO 140434797135680] #quality_metric: host=algo-1, epoch=50, batch=0 train absolute_loss <loss>=0.878560791015625\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:07.656] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 102, \"duration\": 514, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:07 INFO 140434797135680] #quality_metric: host=algo-1, epoch=50, train rmse <loss>=0.99551606147522\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:07 INFO 140434797135680] #quality_metric: host=algo-1, epoch=50, train mse <loss>=0.991052228655134\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:07 INFO 140434797135680] #quality_metric: host=algo-1, epoch=50, train absolute_loss <loss>=0.7982880745353279\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879387.1381884, \"EndTime\": 1630879387.656967, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 517.4720287322998, \"count\": 1, \"min\": 517.4720287322998, \"max\": 517.4720287322998}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:07 INFO 140434797135680] #progress_metric: host=algo-1, completed 25.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879387.1394641, \"EndTime\": 1630879387.657328, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 50, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4620070.0, \"count\": 1, \"min\": 4620070, \"max\": 4620070}, \"Total Batches Seen\": {\"sum\": 4642.0, \"count\": 1, \"min\": 4642, \"max\": 4642}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 52.0, \"count\": 1, \"min\": 52, \"max\": 52}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:07 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=174839.24047556805 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:07 INFO 140434797135680] #quality_metric: host=algo-1, epoch=51, batch=0 train rmse <loss>=1.056340949301822\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:07 INFO 140434797135680] #quality_metric: host=algo-1, epoch=51, batch=0 train mse <loss>=1.115856201171875\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:07 INFO 140434797135680] #quality_metric: host=algo-1, epoch=51, batch=0 train absolute_loss <loss>=0.8780281372070312\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:08.089] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 104, \"duration\": 430, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:08 INFO 140434797135680] #quality_metric: host=algo-1, epoch=51, train rmse <loss>=0.9945703933325893\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:08 INFO 140434797135680] #quality_metric: host=algo-1, epoch=51, train mse <loss>=0.9891702672937415\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:08 INFO 140434797135680] #quality_metric: host=algo-1, epoch=51, train absolute_loss <loss>=0.7974271682906937\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879387.6570623, \"EndTime\": 1630879388.0912573, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 433.17174911499023, \"count\": 1, \"min\": 433.17174911499023, \"max\": 433.17174911499023}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:08 INFO 140434797135680] #progress_metric: host=algo-1, completed 26.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879387.6580575, \"EndTime\": 1630879388.091963, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 51, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4710640.0, \"count\": 1, \"min\": 4710640, \"max\": 4710640}, \"Total Batches Seen\": {\"sum\": 4733.0, \"count\": 1, \"min\": 4733, \"max\": 4733}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 53.0, \"count\": 1, \"min\": 53, \"max\": 53}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:08 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=208509.99976946763 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:08 INFO 140434797135680] #quality_metric: host=algo-1, epoch=52, batch=0 train rmse <loss>=1.0555114258581892\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:08 INFO 140434797135680] #quality_metric: host=algo-1, epoch=52, batch=0 train mse <loss>=1.1141043701171875\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:08 INFO 140434797135680] #quality_metric: host=algo-1, epoch=52, batch=0 train absolute_loss <loss>=0.87751806640625\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:08.537] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 106, \"duration\": 442, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:08 INFO 140434797135680] #quality_metric: host=algo-1, epoch=52, train rmse <loss>=0.9936423664411033\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:08 INFO 140434797135680] #quality_metric: host=algo-1, epoch=52, train mse <loss>=0.9873251523866758\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:08 INFO 140434797135680] #quality_metric: host=algo-1, epoch=52, train absolute_loss <loss>=0.7965815818702782\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879388.0916183, \"EndTime\": 1630879388.538192, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 444.9114799499512, \"count\": 1, \"min\": 444.9114799499512, \"max\": 444.9114799499512}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:08 INFO 140434797135680] #progress_metric: host=algo-1, completed 26.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879388.0932503, \"EndTime\": 1630879388.538575, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 52, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4801210.0, \"count\": 1, \"min\": 4801210, \"max\": 4801210}, \"Total Batches Seen\": {\"sum\": 4824.0, \"count\": 1, \"min\": 4824, \"max\": 4824}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 54.0, \"count\": 1, \"min\": 54, \"max\": 54}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:08 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=203289.70118598736 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:08 INFO 140434797135680] #quality_metric: host=algo-1, epoch=53, batch=0 train rmse <loss>=1.0547021989716459\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:08 INFO 140434797135680] #quality_metric: host=algo-1, epoch=53, batch=0 train mse <loss>=1.112396728515625\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:08 INFO 140434797135680] #quality_metric: host=algo-1, epoch=53, batch=0 train absolute_loss <loss>=0.8770247802734376\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:08.986] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 108, \"duration\": 445, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:08 INFO 140434797135680] #quality_metric: host=algo-1, epoch=53, train rmse <loss>=0.9927313168132349\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:08 INFO 140434797135680] #quality_metric: host=algo-1, epoch=53, train mse <loss>=0.9855154673817393\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:08 INFO 140434797135680] #quality_metric: host=algo-1, epoch=53, train absolute_loss <loss>=0.795750996013264\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879388.538308, \"EndTime\": 1630879388.987156, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 447.784423828125, \"count\": 1, \"min\": 447.784423828125, \"max\": 447.784423828125}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:08 INFO 140434797135680] #progress_metric: host=algo-1, completed 27.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879388.5393438, \"EndTime\": 1630879388.9874737, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 53, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4891780.0, \"count\": 1, \"min\": 4891780, \"max\": 4891780}, \"Total Batches Seen\": {\"sum\": 4915.0, \"count\": 1, \"min\": 4915, \"max\": 4915}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 55.0, \"count\": 1, \"min\": 55, \"max\": 55}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:08 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=202036.17463228255 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:08 INFO 140434797135680] #quality_metric: host=algo-1, epoch=54, batch=0 train rmse <loss>=1.053912504614502\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:08 INFO 140434797135680] #quality_metric: host=algo-1, epoch=54, batch=0 train mse <loss>=1.1107315673828124\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:08 INFO 140434797135680] #quality_metric: host=algo-1, epoch=54, batch=0 train absolute_loss <loss>=0.8765421752929687\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:09.441] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 110, \"duration\": 451, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:09 INFO 140434797135680] #quality_metric: host=algo-1, epoch=54, train rmse <loss>=0.9918365368907973\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:09 INFO 140434797135680] #quality_metric: host=algo-1, epoch=54, train mse <loss>=0.9837397159115299\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:09 INFO 140434797135680] #quality_metric: host=algo-1, epoch=54, train absolute_loss <loss>=0.794934344951923\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879388.9872344, \"EndTime\": 1630879389.4418857, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 453.6459445953369, \"count\": 1, \"min\": 453.6459445953369, \"max\": 453.6459445953369}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:09 INFO 140434797135680] #progress_metric: host=algo-1, completed 27.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879388.9881933, \"EndTime\": 1630879389.442251, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 54, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4982350.0, \"count\": 1, \"min\": 4982350, \"max\": 4982350}, \"Total Batches Seen\": {\"sum\": 5006.0, \"count\": 1, \"min\": 5006, \"max\": 5006}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 56.0, \"count\": 1, \"min\": 56, \"max\": 56}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:09 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=199389.10318547563 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:09 INFO 140434797135680] #quality_metric: host=algo-1, epoch=55, batch=0 train rmse <loss>=1.0531414014857823\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:09 INFO 140434797135680] #quality_metric: host=algo-1, epoch=55, batch=0 train mse <loss>=1.1091068115234375\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:09 INFO 140434797135680] #quality_metric: host=algo-1, epoch=55, batch=0 train absolute_loss <loss>=0.87608154296875\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:09.897] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 112, \"duration\": 452, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:09 INFO 140434797135680] #quality_metric: host=algo-1, epoch=55, train rmse <loss>=0.9909574399344395\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:09 INFO 140434797135680] #quality_metric: host=algo-1, epoch=55, train mse <loss>=0.9819966477614183\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:09 INFO 140434797135680] #quality_metric: host=algo-1, epoch=55, train absolute_loss <loss>=0.7941313094254379\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879389.4419775, \"EndTime\": 1630879389.8981984, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 455.1806449890137, \"count\": 1, \"min\": 455.1806449890137, \"max\": 455.1806449890137}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:09 INFO 140434797135680] #progress_metric: host=algo-1, completed 28.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879389.4429908, \"EndTime\": 1630879389.898516, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 55, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5072920.0, \"count\": 1, \"min\": 5072920, \"max\": 5072920}, \"Total Batches Seen\": {\"sum\": 5097.0, \"count\": 1, \"min\": 5097, \"max\": 5097}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 57.0, \"count\": 1, \"min\": 57, \"max\": 57}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:09 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=198761.6905606041 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:09 INFO 140434797135680] #quality_metric: host=algo-1, epoch=56, batch=0 train rmse <loss>=1.0523880025031167\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:09 INFO 140434797135680] #quality_metric: host=algo-1, epoch=56, batch=0 train mse <loss>=1.1075205078125\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:09 INFO 140434797135680] #quality_metric: host=algo-1, epoch=56, batch=0 train absolute_loss <loss>=0.8756298828125\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:10.325] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 114, \"duration\": 424, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:10 INFO 140434797135680] #quality_metric: host=algo-1, epoch=56, train rmse <loss>=0.9900933875820356\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:10 INFO 140434797135680] #quality_metric: host=algo-1, epoch=56, train mse <loss>=0.980284916133671\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:10 INFO 140434797135680] #quality_metric: host=algo-1, epoch=56, train absolute_loss <loss>=0.7933412415221497\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879389.8982973, \"EndTime\": 1630879390.3260958, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 426.80931091308594, \"count\": 1, \"min\": 426.80931091308594, \"max\": 426.80931091308594}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:10 INFO 140434797135680] #progress_metric: host=algo-1, completed 28.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879389.8992596, \"EndTime\": 1630879390.3264623, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 56, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5163490.0, \"count\": 1, \"min\": 5163490, \"max\": 5163490}, \"Total Batches Seen\": {\"sum\": 5188.0, \"count\": 1, \"min\": 5188, \"max\": 5188}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 58.0, \"count\": 1, \"min\": 58, \"max\": 58}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:10 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=211922.0486271692 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:10 INFO 140434797135680] #quality_metric: host=algo-1, epoch=57, batch=0 train rmse <loss>=1.0516515912296893\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:10 INFO 140434797135680] #quality_metric: host=algo-1, epoch=57, batch=0 train mse <loss>=1.1059710693359375\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:10 INFO 140434797135680] #quality_metric: host=algo-1, epoch=57, batch=0 train absolute_loss <loss>=0.8751919555664063\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:10.783] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 116, \"duration\": 454, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:10 INFO 140434797135680] #quality_metric: host=algo-1, epoch=57, train rmse <loss>=0.9892438883748678\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:10 INFO 140434797135680] #quality_metric: host=algo-1, epoch=57, train mse <loss>=0.9786034706870278\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:10 INFO 140434797135680] #quality_metric: host=algo-1, epoch=57, train absolute_loss <loss>=0.7925640641097184\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879390.3262155, \"EndTime\": 1630879390.7845254, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 457.3063850402832, \"count\": 1, \"min\": 457.3063850402832, \"max\": 457.3063850402832}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:10 INFO 140434797135680] #progress_metric: host=algo-1, completed 29.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879390.327189, \"EndTime\": 1630879390.7851562, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 57, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5254060.0, \"count\": 1, \"min\": 5254060, \"max\": 5254060}, \"Total Batches Seen\": {\"sum\": 5279.0, \"count\": 1, \"min\": 5279, \"max\": 5279}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 59.0, \"count\": 1, \"min\": 59, \"max\": 59}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:10 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=197614.91393450086 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:10 INFO 140434797135680] #quality_metric: host=algo-1, epoch=58, batch=0 train rmse <loss>=1.0509312160643234\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:10 INFO 140434797135680] #quality_metric: host=algo-1, epoch=58, batch=0 train mse <loss>=1.1044564208984375\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:10 INFO 140434797135680] #quality_metric: host=algo-1, epoch=58, batch=0 train absolute_loss <loss>=0.8747866821289062\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:11.233] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 118, \"duration\": 444, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:11 INFO 140434797135680] #quality_metric: host=algo-1, epoch=58, train rmse <loss>=0.9884083552021035\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:11 INFO 140434797135680] #quality_metric: host=algo-1, epoch=58, train mse <loss>=0.9769510766333276\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:11 INFO 140434797135680] #quality_metric: host=algo-1, epoch=58, train absolute_loss <loss>=0.7917988448929001\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879390.7847984, \"EndTime\": 1630879391.233777, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 447.462797164917, \"count\": 1, \"min\": 447.462797164917, \"max\": 447.462797164917}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:11 INFO 140434797135680] #progress_metric: host=algo-1, completed 29.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879390.7862847, \"EndTime\": 1630879391.2340484, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 58, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5344630.0, \"count\": 1, \"min\": 5344630, \"max\": 5344630}, \"Total Batches Seen\": {\"sum\": 5370.0, \"count\": 1, \"min\": 5370, \"max\": 5370}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 60.0, \"count\": 1, \"min\": 60, \"max\": 60}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:11 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=202207.38298017305 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:11 INFO 140434797135680] #quality_metric: host=algo-1, epoch=59, batch=0 train rmse <loss>=1.0502260963790726\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:11 INFO 140434797135680] #quality_metric: host=algo-1, epoch=59, batch=0 train mse <loss>=1.102974853515625\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:11 INFO 140434797135680] #quality_metric: host=algo-1, epoch=59, batch=0 train absolute_loss <loss>=0.8743853759765625\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:11.795] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 120, \"duration\": 559, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:11 INFO 140434797135680] #quality_metric: host=algo-1, epoch=59, train rmse <loss>=0.987586306001345\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:11 INFO 140434797135680] #quality_metric: host=algo-1, epoch=59, train mse <loss>=0.9753267118013822\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:11 INFO 140434797135680] #quality_metric: host=algo-1, epoch=59, train absolute_loss <loss>=0.7910454919836023\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879391.2338588, \"EndTime\": 1630879391.7965133, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 561.7923736572266, \"count\": 1, \"min\": 561.7923736572266, \"max\": 561.7923736572266}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:11 INFO 140434797135680] #progress_metric: host=algo-1, completed 30.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879391.2346928, \"EndTime\": 1630879391.7968602, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 59, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5435200.0, \"count\": 1, \"min\": 5435200, \"max\": 5435200}, \"Total Batches Seen\": {\"sum\": 5461.0, \"count\": 1, \"min\": 5461, \"max\": 5461}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 61.0, \"count\": 1, \"min\": 61, \"max\": 61}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:11 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=161061.2565282537 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:11 INFO 140434797135680] #quality_metric: host=algo-1, epoch=60, batch=0 train rmse <loss>=1.0495354487596524\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:11 INFO 140434797135680] #quality_metric: host=algo-1, epoch=60, batch=0 train mse <loss>=1.101524658203125\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:11 INFO 140434797135680] #quality_metric: host=algo-1, epoch=60, batch=0 train absolute_loss <loss>=0.8739860229492188\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:12.235] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 122, \"duration\": 436, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:12 INFO 140434797135680] #quality_metric: host=algo-1, epoch=60, train rmse <loss>=0.9867772847453632\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:12 INFO 140434797135680] #quality_metric: host=algo-1, epoch=60, train mse <loss>=0.9737294096894317\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:12 INFO 140434797135680] #quality_metric: host=algo-1, epoch=60, train absolute_loss <loss>=0.7903039758703211\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879391.7966318, \"EndTime\": 1630879392.2366936, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 438.4903907775879, \"count\": 1, \"min\": 438.4903907775879, \"max\": 438.4903907775879}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:12 INFO 140434797135680] #progress_metric: host=algo-1, completed 30.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879391.7981768, \"EndTime\": 1630879392.2370532, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 60, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5525770.0, \"count\": 1, \"min\": 5525770, \"max\": 5525770}, \"Total Batches Seen\": {\"sum\": 5552.0, \"count\": 1, \"min\": 5552, \"max\": 5552}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 62.0, \"count\": 1, \"min\": 62, \"max\": 62}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:12 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=206300.32262689367 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:12 INFO 140434797135680] #quality_metric: host=algo-1, epoch=61, batch=0 train rmse <loss>=1.048858428915099\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:12 INFO 140434797135680] #quality_metric: host=algo-1, epoch=61, batch=0 train mse <loss>=1.10010400390625\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:12 INFO 140434797135680] #quality_metric: host=algo-1, epoch=61, batch=0 train absolute_loss <loss>=0.8735877075195313\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:12.672] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 124, \"duration\": 432, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:12 INFO 140434797135680] #quality_metric: host=algo-1, epoch=61, train rmse <loss>=0.9859807942669957\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:12 INFO 140434797135680] #quality_metric: host=algo-1, epoch=61, train mse <loss>=0.9721581266633756\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:12 INFO 140434797135680] #quality_metric: host=algo-1, epoch=61, train absolute_loss <loss>=0.789572996705443\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879392.236791, \"EndTime\": 1630879392.673394, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 435.53876876831055, \"count\": 1, \"min\": 435.53876876831055, \"max\": 435.53876876831055}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:12 INFO 140434797135680] #progress_metric: host=algo-1, completed 31.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879392.2378163, \"EndTime\": 1630879392.6737347, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 61, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5616340.0, \"count\": 1, \"min\": 5616340, \"max\": 5616340}, \"Total Batches Seen\": {\"sum\": 5643.0, \"count\": 1, \"min\": 5643, \"max\": 5643}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 63.0, \"count\": 1, \"min\": 63, \"max\": 63}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:12 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=207698.41332014572 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:12 INFO 140434797135680] #quality_metric: host=algo-1, epoch=62, batch=0 train rmse <loss>=1.0481943062767216\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:12 INFO 140434797135680] #quality_metric: host=algo-1, epoch=62, batch=0 train mse <loss>=1.0987113037109375\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:12 INFO 140434797135680] #quality_metric: host=algo-1, epoch=62, batch=0 train absolute_loss <loss>=0.873189697265625\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:13.124] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 126, \"duration\": 448, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:13 INFO 140434797135680] #quality_metric: host=algo-1, epoch=62, train rmse <loss>=0.9851964377598159\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:13 INFO 140434797135680] #quality_metric: host=algo-1, epoch=62, train mse <loss>=0.9706120209746308\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:13 INFO 140434797135680] #quality_metric: host=algo-1, epoch=62, train absolute_loss <loss>=0.7888518656636332\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879392.6734707, \"EndTime\": 1630879393.1254303, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 450.9315490722656, \"count\": 1, \"min\": 450.9315490722656, \"max\": 450.9315490722656}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:13 INFO 140434797135680] #progress_metric: host=algo-1, completed 31.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879392.6744728, \"EndTime\": 1630879393.125682, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 62, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5706910.0, \"count\": 1, \"min\": 5706910, \"max\": 5706910}, \"Total Batches Seen\": {\"sum\": 5734.0, \"count\": 1, \"min\": 5734, \"max\": 5734}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 64.0, \"count\": 1, \"min\": 64, \"max\": 64}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:13 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=200670.8324225413 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:13 INFO 140434797135680] #quality_metric: host=algo-1, epoch=63, batch=0 train rmse <loss>=1.047542231398095\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:13 INFO 140434797135680] #quality_metric: host=algo-1, epoch=63, batch=0 train mse <loss>=1.0973447265625\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:13 INFO 140434797135680] #quality_metric: host=algo-1, epoch=63, batch=0 train absolute_loss <loss>=0.8727933959960937\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:13.554] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 128, \"duration\": 426, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:13 INFO 140434797135680] #quality_metric: host=algo-1, epoch=63, train rmse <loss>=0.9844238088588398\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:13 INFO 140434797135680] #quality_metric: host=algo-1, epoch=63, train mse <loss>=0.9690902354481457\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:13 INFO 140434797135680] #quality_metric: host=algo-1, epoch=63, train absolute_loss <loss>=0.7881412534608946\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879393.1255064, \"EndTime\": 1630879393.555304, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 428.94554138183594, \"count\": 1, \"min\": 428.94554138183594, \"max\": 428.94554138183594}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:13 INFO 140434797135680] #progress_metric: host=algo-1, completed 32.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879393.1263306, \"EndTime\": 1630879393.5555522, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 63, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5797480.0, \"count\": 1, \"min\": 5797480, \"max\": 5797480}, \"Total Batches Seen\": {\"sum\": 5825.0, \"count\": 1, \"min\": 5825, \"max\": 5825}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 65.0, \"count\": 1, \"min\": 65, \"max\": 65}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:13 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=210946.12666381613 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:13 INFO 140434797135680] #quality_metric: host=algo-1, epoch=64, batch=0 train rmse <loss>=1.0469014688818021\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:13 INFO 140434797135680] #quality_metric: host=algo-1, epoch=64, batch=0 train mse <loss>=1.096002685546875\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:13 INFO 140434797135680] #quality_metric: host=algo-1, epoch=64, batch=0 train absolute_loss <loss>=0.8723966064453125\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:14.004] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 130, \"duration\": 447, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:14 INFO 140434797135680] #quality_metric: host=algo-1, epoch=64, train rmse <loss>=0.98366248585591\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:14 INFO 140434797135680] #quality_metric: host=algo-1, epoch=64, train mse <loss>=0.9675918860802284\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:14 INFO 140434797135680] #quality_metric: host=algo-1, epoch=64, train absolute_loss <loss>=0.7874402713985234\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879393.5553784, \"EndTime\": 1630879394.0056956, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 449.4006633758545, \"count\": 1, \"min\": 449.4006633758545, \"max\": 449.4006633758545}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:14 INFO 140434797135680] #progress_metric: host=algo-1, completed 32.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879393.5562587, \"EndTime\": 1630879394.0060606, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 64, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5888050.0, \"count\": 1, \"min\": 5888050, \"max\": 5888050}, \"Total Batches Seen\": {\"sum\": 5916.0, \"count\": 1, \"min\": 5916, \"max\": 5916}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:14 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=201296.61420677463 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:14 INFO 140434797135680] #quality_metric: host=algo-1, epoch=65, batch=0 train rmse <loss>=1.0462713978173277\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:14 INFO 140434797135680] #quality_metric: host=algo-1, epoch=65, batch=0 train mse <loss>=1.094683837890625\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:14 INFO 140434797135680] #quality_metric: host=algo-1, epoch=65, batch=0 train absolute_loss <loss>=0.8720016479492188\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:14.441] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 132, \"duration\": 433, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:14 INFO 140434797135680] #quality_metric: host=algo-1, epoch=65, train rmse <loss>=0.9829121258567137\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:14 INFO 140434797135680] #quality_metric: host=algo-1, epoch=65, train mse <loss>=0.9661162471561642\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:14 INFO 140434797135680] #quality_metric: host=algo-1, epoch=65, train absolute_loss <loss>=0.7867486270443423\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879394.005797, \"EndTime\": 1630879394.4423583, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 435.6088638305664, \"count\": 1, \"min\": 435.6088638305664, \"max\": 435.6088638305664}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:14 INFO 140434797135680] #progress_metric: host=algo-1, completed 33.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879394.0067217, \"EndTime\": 1630879394.4426072, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 65, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5978620.0, \"count\": 1, \"min\": 5978620, \"max\": 5978620}, \"Total Batches Seen\": {\"sum\": 6007.0, \"count\": 1, \"min\": 6007, \"max\": 6007}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 67.0, \"count\": 1, \"min\": 67, \"max\": 67}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:14 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=207723.74009578043 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:14 INFO 140434797135680] #quality_metric: host=algo-1, epoch=66, batch=0 train rmse <loss>=1.0456512787156564\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:14 INFO 140434797135680] #quality_metric: host=algo-1, epoch=66, batch=0 train mse <loss>=1.0933865966796874\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:14 INFO 140434797135680] #quality_metric: host=algo-1, epoch=66, batch=0 train absolute_loss <loss>=0.8716102294921875\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:14.881] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 134, \"duration\": 436, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:14 INFO 140434797135680] #quality_metric: host=algo-1, epoch=66, train rmse <loss>=0.982172356545696\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:14 INFO 140434797135680] #quality_metric: host=algo-1, epoch=66, train mse <loss>=0.9646625379625258\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:14 INFO 140434797135680] #quality_metric: host=algo-1, epoch=66, train absolute_loss <loss>=0.7860670340401785\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879394.442432, \"EndTime\": 1630879394.882595, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 439.31126594543457, \"count\": 1, \"min\": 439.31126594543457, \"max\": 439.31126594543457}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:14 INFO 140434797135680] #progress_metric: host=algo-1, completed 33.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879394.443248, \"EndTime\": 1630879394.8829408, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 66, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6069190.0, \"count\": 1, \"min\": 6069190, \"max\": 6069190}, \"Total Batches Seen\": {\"sum\": 6098.0, \"count\": 1, \"min\": 6098, \"max\": 6098}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 68.0, \"count\": 1, \"min\": 68, \"max\": 68}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:14 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=205923.2295653192 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:14 INFO 140434797135680] #quality_metric: host=algo-1, epoch=67, batch=0 train rmse <loss>=1.0450404868427945\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:14 INFO 140434797135680] #quality_metric: host=algo-1, epoch=67, batch=0 train mse <loss>=1.092109619140625\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:14 INFO 140434797135680] #quality_metric: host=algo-1, epoch=67, batch=0 train absolute_loss <loss>=0.871227783203125\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:15.327] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 136, \"duration\": 442, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:15 INFO 140434797135680] #quality_metric: host=algo-1, epoch=67, train rmse <loss>=0.9814428693982358\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:15 INFO 140434797135680] #quality_metric: host=algo-1, epoch=67, train mse <loss>=0.9632301058926425\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:15 INFO 140434797135680] #quality_metric: host=algo-1, epoch=67, train absolute_loss <loss>=0.785395266354739\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879394.8826716, \"EndTime\": 1630879395.3285923, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 444.9326992034912, \"count\": 1, \"min\": 444.9326992034912, \"max\": 444.9326992034912}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:15 INFO 140434797135680] #progress_metric: host=algo-1, completed 34.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879394.8836331, \"EndTime\": 1630879395.3289251, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 67, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6159760.0, \"count\": 1, \"min\": 6159760, \"max\": 6159760}, \"Total Batches Seen\": {\"sum\": 6189.0, \"count\": 1, \"min\": 6189, \"max\": 6189}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 69.0, \"count\": 1, \"min\": 69, \"max\": 69}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:15 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=203337.79746624044 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:15 INFO 140434797135680] #quality_metric: host=algo-1, epoch=68, batch=0 train rmse <loss>=1.0444382204271647\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:15 INFO 140434797135680] #quality_metric: host=algo-1, epoch=68, batch=0 train mse <loss>=1.0908511962890626\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:15 INFO 140434797135680] #quality_metric: host=algo-1, epoch=68, batch=0 train absolute_loss <loss>=0.87084619140625\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:15.759] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 138, \"duration\": 428, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:15 INFO 140434797135680] #quality_metric: host=algo-1, epoch=68, train rmse <loss>=0.98072331429173\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:15 INFO 140434797135680] #quality_metric: host=algo-1, epoch=68, train mse <loss>=0.9618182191953554\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:15 INFO 140434797135680] #quality_metric: host=algo-1, epoch=68, train absolute_loss <loss>=0.7847331234439389\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879395.32867, \"EndTime\": 1630879395.7603168, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 430.6793212890625, \"count\": 1, \"min\": 430.6793212890625, \"max\": 430.6793212890625}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:15 INFO 140434797135680] #progress_metric: host=algo-1, completed 34.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879395.3296113, \"EndTime\": 1630879395.7605665, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 68, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6250330.0, \"count\": 1, \"min\": 6250330, \"max\": 6250330}, \"Total Batches Seen\": {\"sum\": 6280.0, \"count\": 1, \"min\": 6280, \"max\": 6280}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 70.0, \"count\": 1, \"min\": 70, \"max\": 70}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:15 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=210100.86046209367 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:15 INFO 140434797135680] #quality_metric: host=algo-1, epoch=69, batch=0 train rmse <loss>=1.043844084924953\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:15 INFO 140434797135680] #quality_metric: host=algo-1, epoch=69, batch=0 train mse <loss>=1.0896104736328125\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:15 INFO 140434797135680] #quality_metric: host=algo-1, epoch=69, batch=0 train absolute_loss <loss>=0.8704609375\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:16.208] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 140, \"duration\": 445, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:16 INFO 140434797135680] #quality_metric: host=algo-1, epoch=69, train rmse <loss>=0.980013393491088\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:16 INFO 140434797135680] #quality_metric: host=algo-1, epoch=69, train mse <loss>=0.960426251421918\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:16 INFO 140434797135680] #quality_metric: host=algo-1, epoch=69, train absolute_loss <loss>=0.7840793591174451\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879395.7603931, \"EndTime\": 1630879396.2087266, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 447.49975204467773, \"count\": 1, \"min\": 447.49975204467773, \"max\": 447.49975204467773}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:16 INFO 140434797135680] #progress_metric: host=algo-1, completed 35.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879395.7611988, \"EndTime\": 1630879396.208991, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 69, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6340900.0, \"count\": 1, \"min\": 6340900, \"max\": 6340900}, \"Total Batches Seen\": {\"sum\": 6371.0, \"count\": 1, \"min\": 6371, \"max\": 6371}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:16 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=202202.3243056513 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:16 INFO 140434797135680] #quality_metric: host=algo-1, epoch=70, batch=0 train rmse <loss>=1.0432574506795709\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:16 INFO 140434797135680] #quality_metric: host=algo-1, epoch=70, batch=0 train mse <loss>=1.0883861083984374\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:16 INFO 140434797135680] #quality_metric: host=algo-1, epoch=70, batch=0 train absolute_loss <loss>=0.8700797729492188\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:16.764] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 142, \"duration\": 553, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:16 INFO 140434797135680] #quality_metric: host=algo-1, epoch=70, train rmse <loss>=0.9793128444064643\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:16 INFO 140434797135680] #quality_metric: host=algo-1, epoch=70, train mse <loss>=0.9590536472194797\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:16 INFO 140434797135680] #quality_metric: host=algo-1, epoch=70, train absolute_loss <loss>=0.783434341598343\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879396.208805, \"EndTime\": 1630879396.7651527, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 555.4940700531006, \"count\": 1, \"min\": 555.4940700531006, \"max\": 555.4940700531006}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:16 INFO 140434797135680] #progress_metric: host=algo-1, completed 35.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879396.2096324, \"EndTime\": 1630879396.765402, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 70, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6431470.0, \"count\": 1, \"min\": 6431470, \"max\": 6431470}, \"Total Batches Seen\": {\"sum\": 6462.0, \"count\": 1, \"min\": 6462, \"max\": 6462}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:16 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=162926.21589675054 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:16 INFO 140434797135680] #quality_metric: host=algo-1, epoch=71, batch=0 train rmse <loss>=1.0426775693721788\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:16 INFO 140434797135680] #quality_metric: host=algo-1, epoch=71, batch=0 train mse <loss>=1.087176513671875\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:16 INFO 140434797135680] #quality_metric: host=algo-1, epoch=71, batch=0 train absolute_loss <loss>=0.8697034912109375\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:17.208] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 144, \"duration\": 440, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:17 INFO 140434797135680] #quality_metric: host=algo-1, epoch=71, train rmse <loss>=0.9786213283739457\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:17 INFO 140434797135680] #quality_metric: host=algo-1, epoch=71, train mse <loss>=0.957699704348386\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:17 INFO 140434797135680] #quality_metric: host=algo-1, epoch=71, train absolute_loss <loss>=0.7827979568649124\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879396.7652287, \"EndTime\": 1630879397.2092261, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 443.12119483947754, \"count\": 1, \"min\": 443.12119483947754, \"max\": 443.12119483947754}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:17 INFO 140434797135680] #progress_metric: host=algo-1, completed 36.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879396.7660782, \"EndTime\": 1630879397.2095351, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 71, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6522040.0, \"count\": 1, \"min\": 6522040, \"max\": 6522040}, \"Total Batches Seen\": {\"sum\": 6553.0, \"count\": 1, \"min\": 6553, \"max\": 6553}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 73.0, \"count\": 1, \"min\": 73, \"max\": 73}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:17 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=204163.31925587615 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:17 INFO 140434797135680] #quality_metric: host=algo-1, epoch=72, batch=0 train rmse <loss>=1.0421042179992723\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:17 INFO 140434797135680] #quality_metric: host=algo-1, epoch=72, batch=0 train mse <loss>=1.085981201171875\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:17 INFO 140434797135680] #quality_metric: host=algo-1, epoch=72, batch=0 train absolute_loss <loss>=0.8693222045898438\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:17.687] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 146, \"duration\": 476, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:17 INFO 140434797135680] #quality_metric: host=algo-1, epoch=72, train rmse <loss>=0.9779386430273113\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:17 INFO 140434797135680] #quality_metric: host=algo-1, epoch=72, train mse <loss>=0.9563639895260989\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:17 INFO 140434797135680] #quality_metric: host=algo-1, epoch=72, train absolute_loss <loss>=0.7821695724319626\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879397.2093263, \"EndTime\": 1630879397.689341, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 479.0627956390381, \"count\": 1, \"min\": 479.0627956390381, \"max\": 479.0627956390381}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:17 INFO 140434797135680] #progress_metric: host=algo-1, completed 36.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879397.21025, \"EndTime\": 1630879397.6899185, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 72, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6612610.0, \"count\": 1, \"min\": 6612610, \"max\": 6612610}, \"Total Batches Seen\": {\"sum\": 6644.0, \"count\": 1, \"min\": 6644, \"max\": 6644}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 74.0, \"count\": 1, \"min\": 74, \"max\": 74}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:17 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=188762.12479192237 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:17 INFO 140434797135680] #quality_metric: host=algo-1, epoch=73, batch=0 train rmse <loss>=1.041536762733318\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:17 INFO 140434797135680] #quality_metric: host=algo-1, epoch=73, batch=0 train mse <loss>=1.084798828125\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:17 INFO 140434797135680] #quality_metric: host=algo-1, epoch=73, batch=0 train absolute_loss <loss>=0.86894580078125\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:18.135] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 148, \"duration\": 439, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:18 INFO 140434797135680] #quality_metric: host=algo-1, epoch=73, train rmse <loss>=0.977264507294493\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:18 INFO 140434797135680] #quality_metric: host=algo-1, epoch=73, train mse <loss>=0.9550459172175481\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:18 INFO 140434797135680] #quality_metric: host=algo-1, epoch=73, train absolute_loss <loss>=0.7815488113571\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879397.68942, \"EndTime\": 1630879398.1368213, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 445.79100608825684, \"count\": 1, \"min\": 445.79100608825684, \"max\": 445.79100608825684}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:18 INFO 140434797135680] #progress_metric: host=algo-1, completed 37.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879397.6910017, \"EndTime\": 1630879398.1371233, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 73, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6703180.0, \"count\": 1, \"min\": 6703180, \"max\": 6703180}, \"Total Batches Seen\": {\"sum\": 6735.0, \"count\": 1, \"min\": 6735, \"max\": 6735}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:18 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=202943.25450197773 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:18 INFO 140434797135680] #quality_metric: host=algo-1, epoch=74, batch=0 train rmse <loss>=1.0409748027877823\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:18 INFO 140434797135680] #quality_metric: host=algo-1, epoch=74, batch=0 train mse <loss>=1.0836285400390624\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:18 INFO 140434797135680] #quality_metric: host=algo-1, epoch=74, batch=0 train absolute_loss <loss>=0.8685760498046875\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:18.569] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 150, \"duration\": 429, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:18 INFO 140434797135680] #quality_metric: host=algo-1, epoch=74, train rmse <loss>=0.9765986854559674\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:18 INFO 140434797135680] #quality_metric: host=algo-1, epoch=74, train mse <loss>=0.9537449924343235\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:18 INFO 140434797135680] #quality_metric: host=algo-1, epoch=74, train absolute_loss <loss>=0.780935812478537\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879398.1369197, \"EndTime\": 1630879398.5698094, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 431.96868896484375, \"count\": 1, \"min\": 431.96868896484375, \"max\": 431.96868896484375}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:18 INFO 140434797135680] #progress_metric: host=algo-1, completed 37.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879398.1378145, \"EndTime\": 1630879398.5701616, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 74, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6793750.0, \"count\": 1, \"min\": 6793750, \"max\": 6793750}, \"Total Batches Seen\": {\"sum\": 6826.0, \"count\": 1, \"min\": 6826, \"max\": 6826}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 76.0, \"count\": 1, \"min\": 76, \"max\": 76}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:18 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=209402.0333287581 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:18 INFO 140434797135680] #quality_metric: host=algo-1, epoch=75, batch=0 train rmse <loss>=1.040417760426521\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:18 INFO 140434797135680] #quality_metric: host=algo-1, epoch=75, batch=0 train mse <loss>=1.0824691162109374\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:18 INFO 140434797135680] #quality_metric: host=algo-1, epoch=75, batch=0 train absolute_loss <loss>=0.8682001953125\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:19.001] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 152, \"duration\": 429, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:19 INFO 140434797135680] #quality_metric: host=algo-1, epoch=75, train rmse <loss>=0.9759409488357803\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:19 INFO 140434797135680] #quality_metric: host=algo-1, epoch=75, train mse <loss>=0.9524607356144832\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:19 INFO 140434797135680] #quality_metric: host=algo-1, epoch=75, train absolute_loss <loss>=0.7803309849330358\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879398.5699267, \"EndTime\": 1630879399.0025625, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 431.6449165344238, \"count\": 1, \"min\": 431.6449165344238, \"max\": 431.6449165344238}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:19 INFO 140434797135680] #progress_metric: host=algo-1, completed 38.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879398.5708902, \"EndTime\": 1630879399.0028086, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 75, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6884320.0, \"count\": 1, \"min\": 6884320, \"max\": 6884320}, \"Total Batches Seen\": {\"sum\": 6917.0, \"count\": 1, \"min\": 6917, \"max\": 6917}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 77.0, \"count\": 1, \"min\": 77, \"max\": 77}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:19 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=209631.29656066772 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:19 INFO 140434797135680] #quality_metric: host=algo-1, epoch=76, batch=0 train rmse <loss>=1.0398652326856772\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:19 INFO 140434797135680] #quality_metric: host=algo-1, epoch=76, batch=0 train mse <loss>=1.0813197021484375\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:19 INFO 140434797135680] #quality_metric: host=algo-1, epoch=76, batch=0 train absolute_loss <loss>=0.8678180541992188\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:19.430] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 154, \"duration\": 425, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:19 INFO 140434797135680] #quality_metric: host=algo-1, epoch=76, train rmse <loss>=0.9752910497118986\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:19 INFO 140434797135680] #quality_metric: host=algo-1, epoch=76, train mse <loss>=0.951192631648137\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:19 INFO 140434797135680] #quality_metric: host=algo-1, epoch=76, train absolute_loss <loss>=0.7797331844790951\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879399.0026383, \"EndTime\": 1630879399.430852, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 427.3827075958252, \"count\": 1, \"min\": 427.3827075958252, \"max\": 427.3827075958252}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:19 INFO 140434797135680] #progress_metric: host=algo-1, completed 38.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879399.0034423, \"EndTime\": 1630879399.4311, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 76, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6974890.0, \"count\": 1, \"min\": 6974890, \"max\": 6974890}, \"Total Batches Seen\": {\"sum\": 7008.0, \"count\": 1, \"min\": 7008, \"max\": 7008}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 78.0, \"count\": 1, \"min\": 78, \"max\": 78}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:19 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=211718.42517894553 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:19 INFO 140434797135680] #quality_metric: host=algo-1, epoch=77, batch=0 train rmse <loss>=1.0393170505868867\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:19 INFO 140434797135680] #quality_metric: host=algo-1, epoch=77, batch=0 train mse <loss>=1.080179931640625\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:19 INFO 140434797135680] #quality_metric: host=algo-1, epoch=77, batch=0 train absolute_loss <loss>=0.8674297485351562\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:19.878] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 156, \"duration\": 445, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:19 INFO 140434797135680] #quality_metric: host=algo-1, epoch=77, train rmse <loss>=0.9746488158943957\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:19 INFO 140434797135680] #quality_metric: host=algo-1, epoch=77, train mse <loss>=0.9499403143243476\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:19 INFO 140434797135680] #quality_metric: host=algo-1, epoch=77, train absolute_loss <loss>=0.7791433695698833\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879399.4309275, \"EndTime\": 1630879399.8792722, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 447.45421409606934, \"count\": 1, \"min\": 447.45421409606934, \"max\": 447.45421409606934}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:19 INFO 140434797135680] #progress_metric: host=algo-1, completed 39.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879399.4317913, \"EndTime\": 1630879399.8796346, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 77, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 7065460.0, \"count\": 1, \"min\": 7065460, \"max\": 7065460}, \"Total Batches Seen\": {\"sum\": 7099.0, \"count\": 1, \"min\": 7099, \"max\": 7099}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 79.0, \"count\": 1, \"min\": 79, \"max\": 79}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:19 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=202185.75084745671 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:19 INFO 140434797135680] #quality_metric: host=algo-1, epoch=78, batch=0 train rmse <loss>=1.0387725746832472\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:19 INFO 140434797135680] #quality_metric: host=algo-1, epoch=78, batch=0 train mse <loss>=1.0790484619140626\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:19 INFO 140434797135680] #quality_metric: host=algo-1, epoch=78, batch=0 train absolute_loss <loss>=0.8670426635742188\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:20.303] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 158, \"duration\": 421, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:20 INFO 140434797135680] #quality_metric: host=algo-1, epoch=78, train rmse <loss>=0.9740139926108703\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:20 INFO 140434797135680] #quality_metric: host=algo-1, epoch=78, train mse <loss>=0.9487032578017686\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:20 INFO 140434797135680] #quality_metric: host=algo-1, epoch=78, train absolute_loss <loss>=0.7785606052272922\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879399.879337, \"EndTime\": 1630879400.3043725, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 423.9046573638916, \"count\": 1, \"min\": 423.9046573638916, \"max\": 423.9046573638916}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:20 INFO 140434797135680] #progress_metric: host=algo-1, completed 39.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879399.8803847, \"EndTime\": 1630879400.304635, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 78, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 7156030.0, \"count\": 1, \"min\": 7156030, \"max\": 7156030}, \"Total Batches Seen\": {\"sum\": 7190.0, \"count\": 1, \"min\": 7190, \"max\": 7190}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 80.0, \"count\": 1, \"min\": 80, \"max\": 80}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:20 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=213389.13561467084 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:20 INFO 140434797135680] #quality_metric: host=algo-1, epoch=79, batch=0 train rmse <loss>=1.0382316932304296\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:20 INFO 140434797135680] #quality_metric: host=algo-1, epoch=79, batch=0 train mse <loss>=1.077925048828125\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:20 INFO 140434797135680] #quality_metric: host=algo-1, epoch=79, batch=0 train absolute_loss <loss>=0.8666500854492187\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:20.736] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 160, \"duration\": 429, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:20 INFO 140434797135680] #quality_metric: host=algo-1, epoch=79, train rmse <loss>=0.9733864265756467\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:20 INFO 140434797135680] #quality_metric: host=algo-1, epoch=79, train mse <loss>=0.9474811354417068\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:20 INFO 140434797135680] #quality_metric: host=algo-1, epoch=79, train absolute_loss <loss>=0.7779846593835852\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879400.3044465, \"EndTime\": 1630879400.737535, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 432.15107917785645, \"count\": 1, \"min\": 432.15107917785645, \"max\": 432.15107917785645}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:20 INFO 140434797135680] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879400.3053567, \"EndTime\": 1630879400.7378922, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 79, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 7246600.0, \"count\": 1, \"min\": 7246600, \"max\": 7246600}, \"Total Batches Seen\": {\"sum\": 7281.0, \"count\": 1, \"min\": 7281, \"max\": 7281}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 81.0, \"count\": 1, \"min\": 81, \"max\": 81}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:20 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=209328.1843825234 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:20 INFO 140434797135680] #quality_metric: host=algo-1, epoch=80, batch=0 train rmse <loss>=1.0376938824865454\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:20 INFO 140434797135680] #quality_metric: host=algo-1, epoch=80, batch=0 train mse <loss>=1.07680859375\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:20 INFO 140434797135680] #quality_metric: host=algo-1, epoch=80, batch=0 train absolute_loss <loss>=0.866251220703125\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:21.175] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 162, \"duration\": 435, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:21 INFO 140434797135680] #quality_metric: host=algo-1, epoch=80, train rmse <loss>=0.9727658953381251\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:21 INFO 140434797135680] #quality_metric: host=algo-1, epoch=80, train mse <loss>=0.9462734871329842\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:21 INFO 140434797135680] #quality_metric: host=algo-1, epoch=80, train absolute_loss <loss>=0.777415026989612\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879400.7376301, \"EndTime\": 1630879401.1764712, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 437.882661819458, \"count\": 1, \"min\": 437.882661819458, \"max\": 437.882661819458}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:21 INFO 140434797135680] #progress_metric: host=algo-1, completed 40.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879400.73854, \"EndTime\": 1630879401.176842, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 80, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 7337170.0, \"count\": 1, \"min\": 7337170, \"max\": 7337170}, \"Total Batches Seen\": {\"sum\": 7372.0, \"count\": 1, \"min\": 7372, \"max\": 7372}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 82.0, \"count\": 1, \"min\": 82, \"max\": 82}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:21 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=206574.50122353094 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:21 INFO 140434797135680] #quality_metric: host=algo-1, epoch=81, batch=0 train rmse <loss>=1.0371589706832556\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:21 INFO 140434797135680] #quality_metric: host=algo-1, epoch=81, batch=0 train mse <loss>=1.07569873046875\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:21 INFO 140434797135680] #quality_metric: host=algo-1, epoch=81, batch=0 train absolute_loss <loss>=0.8658479614257812\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:21.665] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 164, \"duration\": 485, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:21 INFO 140434797135680] #quality_metric: host=algo-1, epoch=81, train rmse <loss>=0.9721522481662961\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:21 INFO 140434797135680] #quality_metric: host=algo-1, epoch=81, train mse <loss>=0.9450799936147837\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:21 INFO 140434797135680] #quality_metric: host=algo-1, epoch=81, train absolute_loss <loss>=0.7768521681565504\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879401.1765606, \"EndTime\": 1630879401.66607, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 488.44361305236816, \"count\": 1, \"min\": 488.44361305236816, \"max\": 488.44361305236816}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:21 INFO 140434797135680] #progress_metric: host=algo-1, completed 41.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879401.1775987, \"EndTime\": 1630879401.6664379, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 81, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 7427740.0, \"count\": 1, \"min\": 7427740, \"max\": 7427740}, \"Total Batches Seen\": {\"sum\": 7463.0, \"count\": 1, \"min\": 7463, \"max\": 7463}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 83.0, \"count\": 1, \"min\": 83, \"max\": 83}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:21 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=185232.84572857412 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:21 INFO 140434797135680] #quality_metric: host=algo-1, epoch=82, batch=0 train rmse <loss>=1.036626491279224\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:21 INFO 140434797135680] #quality_metric: host=algo-1, epoch=82, batch=0 train mse <loss>=1.074594482421875\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:21 INFO 140434797135680] #quality_metric: host=algo-1, epoch=82, batch=0 train absolute_loss <loss>=0.8654445190429687\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:22.211] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 166, \"duration\": 542, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:22 INFO 140434797135680] #quality_metric: host=algo-1, epoch=82, train rmse <loss>=0.9715452657983751\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:22 INFO 140434797135680] #quality_metric: host=algo-1, epoch=82, train mse <loss>=0.9439002034952352\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:22 INFO 140434797135680] #quality_metric: host=algo-1, epoch=82, train absolute_loss <loss>=0.7762956945398352\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879401.6661355, \"EndTime\": 1630879402.2123942, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 545.2170372009277, \"count\": 1, \"min\": 545.2170372009277, \"max\": 545.2170372009277}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:22 INFO 140434797135680] #progress_metric: host=algo-1, completed 41.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879401.6671503, \"EndTime\": 1630879402.212753, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 82, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 7518310.0, \"count\": 1, \"min\": 7518310, \"max\": 7518310}, \"Total Batches Seen\": {\"sum\": 7554.0, \"count\": 1, \"min\": 7554, \"max\": 7554}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 84.0, \"count\": 1, \"min\": 84, \"max\": 84}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:22 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=165956.58723969766 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:22 INFO 140434797135680] #quality_metric: host=algo-1, epoch=83, batch=0 train rmse <loss>=1.0360963302071626\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:22 INFO 140434797135680] #quality_metric: host=algo-1, epoch=83, batch=0 train mse <loss>=1.07349560546875\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:22 INFO 140434797135680] #quality_metric: host=algo-1, epoch=83, batch=0 train absolute_loss <loss>=0.8650426025390625\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:22.699] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 168, \"duration\": 484, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:22 INFO 140434797135680] #quality_metric: host=algo-1, epoch=83, train rmse <loss>=0.9709448028889828\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:22 INFO 140434797135680] #quality_metric: host=algo-1, epoch=83, train mse <loss>=0.9427338102571257\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:22 INFO 140434797135680] #quality_metric: host=algo-1, epoch=83, train absolute_loss <loss>=0.7757449790200034\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879402.2125156, \"EndTime\": 1630879402.7010207, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 487.53809928894043, \"count\": 1, \"min\": 487.53809928894043, \"max\": 487.53809928894043}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:22 INFO 140434797135680] #progress_metric: host=algo-1, completed 42.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879402.2134552, \"EndTime\": 1630879402.7017713, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 83, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 7608880.0, \"count\": 1, \"min\": 7608880, \"max\": 7608880}, \"Total Batches Seen\": {\"sum\": 7645.0, \"count\": 1, \"min\": 7645, \"max\": 7645}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 85.0, \"count\": 1, \"min\": 85, \"max\": 85}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:22 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=185302.4194992888 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:22 INFO 140434797135680] #quality_metric: host=algo-1, epoch=84, batch=0 train rmse <loss>=1.0355681963336902\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:22 INFO 140434797135680] #quality_metric: host=algo-1, epoch=84, batch=0 train mse <loss>=1.0724014892578124\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:22 INFO 140434797135680] #quality_metric: host=algo-1, epoch=84, batch=0 train absolute_loss <loss>=0.8646428833007812\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:23.143] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 170, \"duration\": 438, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:23 INFO 140434797135680] #quality_metric: host=algo-1, epoch=84, train rmse <loss>=0.9703506925176926\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:23 INFO 140434797135680] #quality_metric: host=algo-1, epoch=84, train mse <loss>=0.9415804664695656\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:23 INFO 140434797135680] #quality_metric: host=algo-1, epoch=84, train absolute_loss <loss>=0.7751999780005151\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879402.7014081, \"EndTime\": 1630879403.1443338, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 441.27917289733887, \"count\": 1, \"min\": 441.27917289733887, \"max\": 441.27917289733887}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:23 INFO 140434797135680] #progress_metric: host=algo-1, completed 42.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879402.7030263, \"EndTime\": 1630879403.1445875, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 84, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 7699450.0, \"count\": 1, \"min\": 7699450, \"max\": 7699450}, \"Total Batches Seen\": {\"sum\": 7736.0, \"count\": 1, \"min\": 7736, \"max\": 7736}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 86.0, \"count\": 1, \"min\": 86, \"max\": 86}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:23 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=205050.5656515386 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:23 INFO 140434797135680] #quality_metric: host=algo-1, epoch=85, batch=0 train rmse <loss>=1.035041797918084\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:23 INFO 140434797135680] #quality_metric: host=algo-1, epoch=85, batch=0 train mse <loss>=1.0713115234375\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:23 INFO 140434797135680] #quality_metric: host=algo-1, epoch=85, batch=0 train absolute_loss <loss>=0.86423583984375\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:23.573] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 172, \"duration\": 427, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:23 INFO 140434797135680] #quality_metric: host=algo-1, epoch=85, train rmse <loss>=0.969762761349132\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:23 INFO 140434797135680] #quality_metric: host=algo-1, epoch=85, train mse <loss>=0.9404398132994934\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:23 INFO 140434797135680] #quality_metric: host=algo-1, epoch=85, train absolute_loss <loss>=0.7746609658042153\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879403.1444113, \"EndTime\": 1630879403.5744772, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 429.20780181884766, \"count\": 1, \"min\": 429.20780181884766, \"max\": 429.20780181884766}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:23 INFO 140434797135680] #progress_metric: host=algo-1, completed 43.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879403.1452444, \"EndTime\": 1630879403.574722, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 85, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 7790020.0, \"count\": 1, \"min\": 7790020, \"max\": 7790020}, \"Total Batches Seen\": {\"sum\": 7827.0, \"count\": 1, \"min\": 7827, \"max\": 7827}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 87.0, \"count\": 1, \"min\": 87, \"max\": 87}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:23 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=210822.38413396623 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:23 INFO 140434797135680] #quality_metric: host=algo-1, epoch=86, batch=0 train rmse <loss>=1.0345169606134426\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:23 INFO 140434797135680] #quality_metric: host=algo-1, epoch=86, batch=0 train mse <loss>=1.070225341796875\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:23 INFO 140434797135680] #quality_metric: host=algo-1, epoch=86, batch=0 train absolute_loss <loss>=0.8638214111328125\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:24.166] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 174, \"duration\": 590, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:24 INFO 140434797135680] #quality_metric: host=algo-1, epoch=86, train rmse <loss>=0.9691808451955166\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:24 INFO 140434797135680] #quality_metric: host=algo-1, epoch=86, train mse <loss>=0.939311510693896\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:24 INFO 140434797135680] #quality_metric: host=algo-1, epoch=86, train absolute_loss <loss>=0.7741274051875858\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879403.5745533, \"EndTime\": 1630879404.1683438, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 592.8823947906494, \"count\": 1, \"min\": 592.8823947906494, \"max\": 592.8823947906494}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:24 INFO 140434797135680] #progress_metric: host=algo-1, completed 43.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879403.5754123, \"EndTime\": 1630879404.1690252, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 86, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 7880590.0, \"count\": 1, \"min\": 7880590, \"max\": 7880590}, \"Total Batches Seen\": {\"sum\": 7918.0, \"count\": 1, \"min\": 7918, \"max\": 7918}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 88.0, \"count\": 1, \"min\": 88, \"max\": 88}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:24 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=152517.94097348108 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:24 INFO 140434797135680] #quality_metric: host=algo-1, epoch=87, batch=0 train rmse <loss>=1.0339935097112554\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:24 INFO 140434797135680] #quality_metric: host=algo-1, epoch=87, batch=0 train mse <loss>=1.069142578125\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:24 INFO 140434797135680] #quality_metric: host=algo-1, epoch=87, batch=0 train absolute_loss <loss>=0.8634027709960937\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:24.749] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 176, \"duration\": 577, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:24 INFO 140434797135680] #quality_metric: host=algo-1, epoch=87, train rmse <loss>=0.9686048292171912\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:24 INFO 140434797135680] #quality_metric: host=algo-1, epoch=87, train mse <loss>=0.938195315182864\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:24 INFO 140434797135680] #quality_metric: host=algo-1, epoch=87, train absolute_loss <loss>=0.7735994423667153\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879404.168502, \"EndTime\": 1630879404.7506468, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 580.4195404052734, \"count\": 1, \"min\": 580.4195404052734, \"max\": 580.4195404052734}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:24 INFO 140434797135680] #progress_metric: host=algo-1, completed 44.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879404.1701896, \"EndTime\": 1630879404.7509985, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 87, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 7971160.0, \"count\": 1, \"min\": 7971160, \"max\": 7971160}, \"Total Batches Seen\": {\"sum\": 8009.0, \"count\": 1, \"min\": 8009, \"max\": 8009}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 89.0, \"count\": 1, \"min\": 89, \"max\": 89}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:24 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=155898.4058705554 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:24 INFO 140434797135680] #quality_metric: host=algo-1, epoch=88, batch=0 train rmse <loss>=1.0334711520261766\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:24 INFO 140434797135680] #quality_metric: host=algo-1, epoch=88, batch=0 train mse <loss>=1.0680626220703124\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:24 INFO 140434797135680] #quality_metric: host=algo-1, epoch=88, batch=0 train absolute_loss <loss>=0.8629768676757813\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:25.199] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 178, \"duration\": 446, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:25 INFO 140434797135680] #quality_metric: host=algo-1, epoch=88, train rmse <loss>=0.9680345434556353\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:25 INFO 140434797135680] #quality_metric: host=algo-1, epoch=88, train mse <loss>=0.9370908773233603\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:25 INFO 140434797135680] #quality_metric: host=algo-1, epoch=88, train absolute_loss <loss>=0.7730770981337998\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879404.750724, \"EndTime\": 1630879405.2005546, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 448.58503341674805, \"count\": 1, \"min\": 448.58503341674805, \"max\": 448.58503341674805}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:25 INFO 140434797135680] #progress_metric: host=algo-1, completed 44.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879404.751922, \"EndTime\": 1630879405.2009234, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 88, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 8061730.0, \"count\": 1, \"min\": 8061730, \"max\": 8061730}, \"Total Batches Seen\": {\"sum\": 8100.0, \"count\": 1, \"min\": 8100, \"max\": 8100}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 90.0, \"count\": 1, \"min\": 90, \"max\": 90}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:25 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=201630.82145275973 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:25 INFO 140434797135680] #quality_metric: host=algo-1, epoch=89, batch=0 train rmse <loss>=1.03294977104029\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:25 INFO 140434797135680] #quality_metric: host=algo-1, epoch=89, batch=0 train mse <loss>=1.0669852294921875\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:25 INFO 140434797135680] #quality_metric: host=algo-1, epoch=89, batch=0 train absolute_loss <loss>=0.8625505981445313\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:25.628] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 180, \"duration\": 425, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:25 INFO 140434797135680] #quality_metric: host=algo-1, epoch=89, train rmse <loss>=0.9674698430986526\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:25 INFO 140434797135680] #quality_metric: host=algo-1, epoch=89, train mse <loss>=0.9359978973053313\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:25 INFO 140434797135680] #quality_metric: host=algo-1, epoch=89, train absolute_loss <loss>=0.7725601726154705\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879405.2006445, \"EndTime\": 1630879405.6292899, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 427.5648593902588, \"count\": 1, \"min\": 427.5648593902588, \"max\": 427.5648593902588}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:25 INFO 140434797135680] #progress_metric: host=algo-1, completed 45.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879405.2016692, \"EndTime\": 1630879405.6296196, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 89, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 8152300.0, \"count\": 1, \"min\": 8152300, \"max\": 8152300}, \"Total Batches Seen\": {\"sum\": 8191.0, \"count\": 1, \"min\": 8191, \"max\": 8191}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:25 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=211567.3781398597 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:25 INFO 140434797135680] #quality_metric: host=algo-1, epoch=90, batch=0 train rmse <loss>=1.032429249997306\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:25 INFO 140434797135680] #quality_metric: host=algo-1, epoch=90, batch=0 train mse <loss>=1.06591015625\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:25 INFO 140434797135680] #quality_metric: host=algo-1, epoch=90, batch=0 train absolute_loss <loss>=0.862118408203125\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:26.078] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 182, \"duration\": 446, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:26 INFO 140434797135680] #quality_metric: host=algo-1, epoch=90, train rmse <loss>=0.9669106130718684\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:26 INFO 140434797135680] #quality_metric: host=algo-1, epoch=90, train mse <loss>=0.9349161336710164\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:26 INFO 140434797135680] #quality_metric: host=algo-1, epoch=90, train absolute_loss <loss>=0.7720483143565419\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879405.62939, \"EndTime\": 1630879406.078976, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 448.61745834350586, \"count\": 1, \"min\": 448.61745834350586, \"max\": 448.61745834350586}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:26 INFO 140434797135680] #progress_metric: host=algo-1, completed 45.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879405.6303122, \"EndTime\": 1630879406.079313, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 90, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 8242870.0, \"count\": 1, \"min\": 8242870, \"max\": 8242870}, \"Total Batches Seen\": {\"sum\": 8282.0, \"count\": 1, \"min\": 8282, \"max\": 8282}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 92.0, \"count\": 1, \"min\": 92, \"max\": 92}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:26 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=201630.17932797392 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:26 INFO 140434797135680] #quality_metric: host=algo-1, epoch=91, batch=0 train rmse <loss>=1.0319094127552149\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:26 INFO 140434797135680] #quality_metric: host=algo-1, epoch=91, batch=0 train mse <loss>=1.0648370361328126\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:26 INFO 140434797135680] #quality_metric: host=algo-1, epoch=91, batch=0 train absolute_loss <loss>=0.861678955078125\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:26.515] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 184, \"duration\": 434, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:26 INFO 140434797135680] #quality_metric: host=algo-1, epoch=91, train rmse <loss>=0.9663567074013851\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:26 INFO 140434797135680] #quality_metric: host=algo-1, epoch=91, train mse <loss>=0.9338452859396463\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:26 INFO 140434797135680] #quality_metric: host=algo-1, epoch=91, train absolute_loss <loss>=0.7715406735598386\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879406.0790648, \"EndTime\": 1630879406.5165844, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 436.41018867492676, \"count\": 1, \"min\": 436.41018867492676, \"max\": 436.41018867492676}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:26 INFO 140434797135680] #progress_metric: host=algo-1, completed 46.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879406.0801387, \"EndTime\": 1630879406.5169427, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 91, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 8333440.0, \"count\": 1, \"min\": 8333440, \"max\": 8333440}, \"Total Batches Seen\": {\"sum\": 8373.0, \"count\": 1, \"min\": 8373, \"max\": 8373}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 93.0, \"count\": 1, \"min\": 93, \"max\": 93}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:26 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=207278.527282787 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:26 INFO 140434797135680] #quality_metric: host=algo-1, epoch=92, batch=0 train rmse <loss>=1.0313900828152691\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:26 INFO 140434797135680] #quality_metric: host=algo-1, epoch=92, batch=0 train mse <loss>=1.0637655029296875\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:26 INFO 140434797135680] #quality_metric: host=algo-1, epoch=92, batch=0 train absolute_loss <loss>=0.8612322998046875\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:26.949] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 186, \"duration\": 430, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:26 INFO 140434797135680] #quality_metric: host=algo-1, epoch=92, train rmse <loss>=0.9658079980919602\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:26 INFO 140434797135680] #quality_metric: host=algo-1, epoch=92, train mse <loss>=0.9327850891783998\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:26 INFO 140434797135680] #quality_metric: host=algo-1, epoch=92, train absolute_loss <loss>=0.7710379169170674\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879406.5166628, \"EndTime\": 1630879406.9501328, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 432.45553970336914, \"count\": 1, \"min\": 432.45553970336914, \"max\": 432.45553970336914}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:26 INFO 140434797135680] #progress_metric: host=algo-1, completed 46.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879406.5176494, \"EndTime\": 1630879406.9504566, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 92, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 8424010.0, \"count\": 1, \"min\": 8424010, \"max\": 8424010}, \"Total Batches Seen\": {\"sum\": 8464.0, \"count\": 1, \"min\": 8464, \"max\": 8464}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:26 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=209193.42904250082 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:26 INFO 140434797135680] #quality_metric: host=algo-1, epoch=93, batch=0 train rmse <loss>=1.0308713201515198\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:26 INFO 140434797135680] #quality_metric: host=algo-1, epoch=93, batch=0 train mse <loss>=1.0626956787109374\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:26 INFO 140434797135680] #quality_metric: host=algo-1, epoch=93, batch=0 train absolute_loss <loss>=0.8607786254882812\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:27.450] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 188, \"duration\": 497, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:27 INFO 140434797135680] #quality_metric: host=algo-1, epoch=93, train rmse <loss>=0.9652643717113171\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:27 INFO 140434797135680] #quality_metric: host=algo-1, epoch=93, train mse <loss>=0.9317353072952438\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:27 INFO 140434797135680] #quality_metric: host=algo-1, epoch=93, train absolute_loss <loss>=0.7705399089435955\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879406.950229, \"EndTime\": 1630879407.451229, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 500.0569820404053, \"count\": 1, \"min\": 500.0569820404053, \"max\": 500.0569820404053}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:27 INFO 140434797135680] #progress_metric: host=algo-1, completed 47.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879406.951143, \"EndTime\": 1630879407.451592, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 93, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 8514580.0, \"count\": 1, \"min\": 8514580, \"max\": 8514580}, \"Total Batches Seen\": {\"sum\": 8555.0, \"count\": 1, \"min\": 8555, \"max\": 8555}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 95.0, \"count\": 1, \"min\": 95, \"max\": 95}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:27 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=180936.47200705306 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:27 INFO 140434797135680] #quality_metric: host=algo-1, epoch=94, batch=0 train rmse <loss>=1.0303530071465496\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:27 INFO 140434797135680] #quality_metric: host=algo-1, epoch=94, batch=0 train mse <loss>=1.0616273193359376\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:27 INFO 140434797135680] #quality_metric: host=algo-1, epoch=94, batch=0 train absolute_loss <loss>=0.8603179931640625\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:27.893] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 190, \"duration\": 439, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:27 INFO 140434797135680] #quality_metric: host=algo-1, epoch=94, train rmse <loss>=0.9647257144899506\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:27 INFO 140434797135680] #quality_metric: host=algo-1, epoch=94, train mse <loss>=0.9306957041981456\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:27 INFO 140434797135680] #quality_metric: host=algo-1, epoch=94, train absolute_loss <loss>=0.7700469313401442\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879407.4513013, \"EndTime\": 1630879407.8941495, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 441.8370723724365, \"count\": 1, \"min\": 441.8370723724365, \"max\": 441.8370723724365}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:27 INFO 140434797135680] #progress_metric: host=algo-1, completed 47.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879407.4522636, \"EndTime\": 1630879407.8945289, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 94, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 8605150.0, \"count\": 1, \"min\": 8605150, \"max\": 8605150}, \"Total Batches Seen\": {\"sum\": 8646.0, \"count\": 1, \"min\": 8646, \"max\": 8646}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 96.0, \"count\": 1, \"min\": 96, \"max\": 96}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:27 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=204724.3516805448 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:27 INFO 140434797135680] #quality_metric: host=algo-1, epoch=95, batch=0 train rmse <loss>=1.0298349074115898\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:27 INFO 140434797135680] #quality_metric: host=algo-1, epoch=95, batch=0 train mse <loss>=1.0605599365234375\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:27 INFO 140434797135680] #quality_metric: host=algo-1, epoch=95, batch=0 train absolute_loss <loss>=0.8598533325195312\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:28.345] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 192, \"duration\": 448, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:28 INFO 140434797135680] #quality_metric: host=algo-1, epoch=95, train rmse <loss>=0.9641918998048553\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:28 INFO 140434797135680] #quality_metric: host=algo-1, epoch=95, train mse <loss>=0.9296660196492961\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:28 INFO 140434797135680] #quality_metric: host=algo-1, epoch=95, train absolute_loss <loss>=0.7695585736285199\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879407.894241, \"EndTime\": 1630879408.3458462, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 450.5610466003418, \"count\": 1, \"min\": 450.5610466003418, \"max\": 450.5610466003418}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:28 INFO 140434797135680] #progress_metric: host=algo-1, completed 48.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879407.8952587, \"EndTime\": 1630879408.346221, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 95, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 8695720.0, \"count\": 1, \"min\": 8695720, \"max\": 8695720}, \"Total Batches Seen\": {\"sum\": 8737.0, \"count\": 1, \"min\": 8737, \"max\": 8737}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 97.0, \"count\": 1, \"min\": 97, \"max\": 97}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:28 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=200771.48113305273 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:28 INFO 140434797135680] #quality_metric: host=algo-1, epoch=96, batch=0 train rmse <loss>=1.0293171398621819\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:28 INFO 140434797135680] #quality_metric: host=algo-1, epoch=96, batch=0 train mse <loss>=1.0594937744140625\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:28 INFO 140434797135680] #quality_metric: host=algo-1, epoch=96, batch=0 train absolute_loss <loss>=0.85938671875\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:28.775] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 194, \"duration\": 427, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:28 INFO 140434797135680] #quality_metric: host=algo-1, epoch=96, train rmse <loss>=0.9636628326944846\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:28 INFO 140434797135680] #quality_metric: host=algo-1, epoch=96, train mse <loss>=0.9286460551167582\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:28 INFO 140434797135680] #quality_metric: host=algo-1, epoch=96, train absolute_loss <loss>=0.7690748163579585\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879408.345964, \"EndTime\": 1630879408.7765343, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 429.6243190765381, \"count\": 1, \"min\": 429.6243190765381, \"max\": 429.6243190765381}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:28 INFO 140434797135680] #progress_metric: host=algo-1, completed 48.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879408.3468826, \"EndTime\": 1630879408.7768235, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 96, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 8786290.0, \"count\": 1, \"min\": 8786290, \"max\": 8786290}, \"Total Batches Seen\": {\"sum\": 8828.0, \"count\": 1, \"min\": 8828, \"max\": 8828}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 98.0, \"count\": 1, \"min\": 98, \"max\": 98}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:28 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=210592.14410011435 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:28 INFO 140434797135680] #quality_metric: host=algo-1, epoch=97, batch=0 train rmse <loss>=1.0287996456732962\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:28 INFO 140434797135680] #quality_metric: host=algo-1, epoch=97, batch=0 train mse <loss>=1.0584287109375\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:28 INFO 140434797135680] #quality_metric: host=algo-1, epoch=97, batch=0 train absolute_loss <loss>=0.8589164428710937\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:29.217] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 196, \"duration\": 438, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:29 INFO 140434797135680] #quality_metric: host=algo-1, epoch=97, train rmse <loss>=0.963138396677715\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:29 INFO 140434797135680] #quality_metric: host=algo-1, epoch=97, train mse <loss>=0.9276355711549193\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:29 INFO 140434797135680] #quality_metric: host=algo-1, epoch=97, train absolute_loss <loss>=0.76859569977142\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879408.7766066, \"EndTime\": 1630879409.2183733, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 440.8833980560303, \"count\": 1, \"min\": 440.8833980560303, \"max\": 440.8833980560303}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:29 INFO 140434797135680] #progress_metric: host=algo-1, completed 49.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879408.7774632, \"EndTime\": 1630879409.2187054, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 97, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 8876860.0, \"count\": 1, \"min\": 8876860, \"max\": 8876860}, \"Total Batches Seen\": {\"sum\": 8919.0, \"count\": 1, \"min\": 8919, \"max\": 8919}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 99.0, \"count\": 1, \"min\": 99, \"max\": 99}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:29 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=205203.08836827407 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:29 INFO 140434797135680] #quality_metric: host=algo-1, epoch=98, batch=0 train rmse <loss>=1.0282823659012332\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:29 INFO 140434797135680] #quality_metric: host=algo-1, epoch=98, batch=0 train mse <loss>=1.0573646240234376\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:29 INFO 140434797135680] #quality_metric: host=algo-1, epoch=98, batch=0 train absolute_loss <loss>=0.8584427490234375\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:29.658] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 198, \"duration\": 437, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:29 INFO 140434797135680] #quality_metric: host=algo-1, epoch=98, train rmse <loss>=0.9626185076994263\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:29 INFO 140434797135680] #quality_metric: host=algo-1, epoch=98, train mse <loss>=0.9266343913654704\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:29 INFO 140434797135680] #quality_metric: host=algo-1, epoch=98, train absolute_loss <loss>=0.7681212171617445\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879409.2184682, \"EndTime\": 1630879409.6590338, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 439.5637512207031, \"count\": 1, \"min\": 439.5637512207031, \"max\": 439.5637512207031}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:29 INFO 140434797135680] #progress_metric: host=algo-1, completed 49.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879409.2194405, \"EndTime\": 1630879409.659374, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 98, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 8967430.0, \"count\": 1, \"min\": 8967430, \"max\": 8967430}, \"Total Batches Seen\": {\"sum\": 9010.0, \"count\": 1, \"min\": 9010, \"max\": 9010}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 100.0, \"count\": 1, \"min\": 100, \"max\": 100}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:29 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=205801.96326556485 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:29 INFO 140434797135680] #quality_metric: host=algo-1, epoch=99, batch=0 train rmse <loss>=1.0277653008697438\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:29 INFO 140434797135680] #quality_metric: host=algo-1, epoch=99, batch=0 train mse <loss>=1.056301513671875\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:29 INFO 140434797135680] #quality_metric: host=algo-1, epoch=99, batch=0 train absolute_loss <loss>=0.8579628295898437\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:30.097] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 200, \"duration\": 436, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:30 INFO 140434797135680] #quality_metric: host=algo-1, epoch=99, train rmse <loss>=0.9621030619377566\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:30 INFO 140434797135680] #quality_metric: host=algo-1, epoch=99, train mse <loss>=0.9256423017900068\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:30 INFO 140434797135680] #quality_metric: host=algo-1, epoch=99, train absolute_loss <loss>=0.7676507876888736\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879409.6591325, \"EndTime\": 1630879410.0986924, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 438.5395050048828, \"count\": 1, \"min\": 438.5395050048828, \"max\": 438.5395050048828}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:30 INFO 140434797135680] #progress_metric: host=algo-1, completed 50.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879409.6601233, \"EndTime\": 1630879410.0990603, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 99, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9058000.0, \"count\": 1, \"min\": 9058000, \"max\": 9058000}, \"Total Batches Seen\": {\"sum\": 9101.0, \"count\": 1, \"min\": 9101, \"max\": 9101}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 101.0, \"count\": 1, \"min\": 101, \"max\": 101}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:30 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=206279.93418644785 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:30 INFO 140434797135680] #quality_metric: host=algo-1, epoch=100, batch=0 train rmse <loss>=1.027248450903097\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:30 INFO 140434797135680] #quality_metric: host=algo-1, epoch=100, batch=0 train mse <loss>=1.0552393798828126\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:30 INFO 140434797135680] #quality_metric: host=algo-1, epoch=100, batch=0 train absolute_loss <loss>=0.8574771728515626\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:30.532] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 202, \"duration\": 431, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:30 INFO 140434797135680] #quality_metric: host=algo-1, epoch=100, train rmse <loss>=0.9615919681895309\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:30 INFO 140434797135680] #quality_metric: host=algo-1, epoch=100, train mse <loss>=0.9246591132866158\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:30 INFO 140434797135680] #quality_metric: host=algo-1, epoch=100, train absolute_loss <loss>=0.7671844764122596\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879410.0987754, \"EndTime\": 1630879410.533458, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 433.72297286987305, \"count\": 1, \"min\": 433.72297286987305, \"max\": 433.72297286987305}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:30 INFO 140434797135680] #progress_metric: host=algo-1, completed 50.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879410.0997078, \"EndTime\": 1630879410.5337045, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 100, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9148570.0, \"count\": 1, \"min\": 9148570, \"max\": 9148570}, \"Total Batches Seen\": {\"sum\": 9192.0, \"count\": 1, \"min\": 9192, \"max\": 9192}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 102.0, \"count\": 1, \"min\": 102, \"max\": 102}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:30 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=208607.89904531263 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:30 INFO 140434797135680] #quality_metric: host=algo-1, epoch=101, batch=0 train rmse <loss>=1.0267318163260792\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:30 INFO 140434797135680] #quality_metric: host=algo-1, epoch=101, batch=0 train mse <loss>=1.05417822265625\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:30 INFO 140434797135680] #quality_metric: host=algo-1, epoch=101, batch=0 train absolute_loss <loss>=0.8569938354492187\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:30.974] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 204, \"duration\": 438, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:30 INFO 140434797135680] #quality_metric: host=algo-1, epoch=101, train rmse <loss>=0.9610851095252262\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:30 INFO 140434797135680] #quality_metric: host=algo-1, epoch=101, train mse <loss>=0.9236845877511161\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:30 INFO 140434797135680] #quality_metric: host=algo-1, epoch=101, train absolute_loss <loss>=0.7667225073510474\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879410.5335333, \"EndTime\": 1630879410.9751925, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 440.77444076538086, \"count\": 1, \"min\": 440.77444076538086, \"max\": 440.77444076538086}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:30 INFO 140434797135680] #progress_metric: host=algo-1, completed 51.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879410.5343904, \"EndTime\": 1630879410.97545, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 101, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9239140.0, \"count\": 1, \"min\": 9239140, \"max\": 9239140}, \"Total Batches Seen\": {\"sum\": 9283.0, \"count\": 1, \"min\": 9283, \"max\": 9283}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 103.0, \"count\": 1, \"min\": 103, \"max\": 103}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:30 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=205285.03693344092 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:30 INFO 140434797135680] #quality_metric: host=algo-1, epoch=102, batch=0 train rmse <loss>=1.0262154569399644\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:30 INFO 140434797135680] #quality_metric: host=algo-1, epoch=102, batch=0 train mse <loss>=1.0531181640625\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:30 INFO 140434797135680] #quality_metric: host=algo-1, epoch=102, batch=0 train absolute_loss <loss>=0.8565065307617188\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:31.416] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 206, \"duration\": 438, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:31 INFO 140434797135680] #quality_metric: host=algo-1, epoch=102, train rmse <loss>=0.9605824472633401\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:31 INFO 140434797135680] #quality_metric: host=algo-1, epoch=102, train mse <loss>=0.9227186379904275\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:31 INFO 140434797135680] #quality_metric: host=algo-1, epoch=102, train absolute_loss <loss>=0.7662644519177112\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879410.9752698, \"EndTime\": 1630879411.417081, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 440.90986251831055, \"count\": 1, \"min\": 440.90986251831055, \"max\": 440.90986251831055}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:31 INFO 140434797135680] #progress_metric: host=algo-1, completed 51.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879410.9761074, \"EndTime\": 1630879411.4174342, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 102, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9329710.0, \"count\": 1, \"min\": 9329710, \"max\": 9329710}, \"Total Batches Seen\": {\"sum\": 9374.0, \"count\": 1, \"min\": 9374, \"max\": 9374}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 104.0, \"count\": 1, \"min\": 104, \"max\": 104}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:31 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=205155.8784569056 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:31 INFO 140434797135680] #quality_metric: host=algo-1, epoch=103, batch=0 train rmse <loss>=1.0256994326662539\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:31 INFO 140434797135680] #quality_metric: host=algo-1, epoch=103, batch=0 train mse <loss>=1.052059326171875\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:31 INFO 140434797135680] #quality_metric: host=algo-1, epoch=103, batch=0 train absolute_loss <loss>=0.8560151977539062\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:31.852] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 208, \"duration\": 432, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:31 INFO 140434797135680] #quality_metric: host=algo-1, epoch=103, train rmse <loss>=0.9600838556101154\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:31 INFO 140434797135680] #quality_metric: host=algo-1, epoch=103, train mse <loss>=0.9217610098031851\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:31 INFO 140434797135680] #quality_metric: host=algo-1, epoch=103, train absolute_loss <loss>=0.7658109379024296\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879411.4171486, \"EndTime\": 1630879411.8529067, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 434.7052574157715, \"count\": 1, \"min\": 434.7052574157715, \"max\": 434.7052574157715}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:31 INFO 140434797135680] #progress_metric: host=algo-1, completed 52.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879411.4181716, \"EndTime\": 1630879411.8532717, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 103, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9420280.0, \"count\": 1, \"min\": 9420280, \"max\": 9420280}, \"Total Batches Seen\": {\"sum\": 9465.0, \"count\": 1, \"min\": 9465, \"max\": 9465}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 105.0, \"count\": 1, \"min\": 105, \"max\": 105}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:31 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=208105.29632472212 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:31 INFO 140434797135680] #quality_metric: host=algo-1, epoch=104, batch=0 train rmse <loss>=1.0251837440109821\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:31 INFO 140434797135680] #quality_metric: host=algo-1, epoch=104, batch=0 train mse <loss>=1.051001708984375\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:31 INFO 140434797135680] #quality_metric: host=algo-1, epoch=104, batch=0 train absolute_loss <loss>=0.8555231323242187\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:32.309] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 210, \"duration\": 453, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:32 INFO 140434797135680] #quality_metric: host=algo-1, epoch=104, train rmse <loss>=0.9595892835958332\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:32 INFO 140434797135680] #quality_metric: host=algo-1, epoch=104, train mse <loss>=0.9208115931919643\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:32 INFO 140434797135680] #quality_metric: host=algo-1, epoch=104, train absolute_loss <loss>=0.7653614636096325\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879411.8529713, \"EndTime\": 1630879412.3100247, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 456.0537338256836, \"count\": 1, \"min\": 456.0537338256836, \"max\": 456.0537338256836}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:32 INFO 140434797135680] #progress_metric: host=algo-1, completed 52.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879411.8539438, \"EndTime\": 1630879412.3103628, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 104, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9510850.0, \"count\": 1, \"min\": 9510850, \"max\": 9510850}, \"Total Batches Seen\": {\"sum\": 9556.0, \"count\": 1, \"min\": 9556, \"max\": 9556}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 106.0, \"count\": 1, \"min\": 106, \"max\": 106}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:32 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=198356.09936025296 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:32 INFO 140434797135680] #quality_metric: host=algo-1, epoch=105, batch=0 train rmse <loss>=1.0246683914808732\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:32 INFO 140434797135680] #quality_metric: host=algo-1, epoch=105, batch=0 train mse <loss>=1.0499453125\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:32 INFO 140434797135680] #quality_metric: host=algo-1, epoch=105, batch=0 train absolute_loss <loss>=0.8550274047851563\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:32.829] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 212, \"duration\": 516, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:32 INFO 140434797135680] #quality_metric: host=algo-1, epoch=105, train rmse <loss>=0.9590986297436965\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:32 INFO 140434797135680] #quality_metric: host=algo-1, epoch=105, train mse <loss>=0.9198701815762362\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:32 INFO 140434797135680] #quality_metric: host=algo-1, epoch=105, train absolute_loss <loss>=0.764915790264423\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879412.310154, \"EndTime\": 1630879412.8306103, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 519.0131664276123, \"count\": 1, \"min\": 519.0131664276123, \"max\": 519.0131664276123}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:32 INFO 140434797135680] #progress_metric: host=algo-1, completed 53.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879412.311568, \"EndTime\": 1630879412.8309286, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 105, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9601420.0, \"count\": 1, \"min\": 9601420, \"max\": 9601420}, \"Total Batches Seen\": {\"sum\": 9647.0, \"count\": 1, \"min\": 9647, \"max\": 9647}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 107.0, \"count\": 1, \"min\": 107, \"max\": 107}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:32 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=174341.74662035643 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:32 INFO 140434797135680] #quality_metric: host=algo-1, epoch=106, batch=0 train rmse <loss>=1.0241534947747701\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:32 INFO 140434797135680] #quality_metric: host=algo-1, epoch=106, batch=0 train mse <loss>=1.048890380859375\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:32 INFO 140434797135680] #quality_metric: host=algo-1, epoch=106, batch=0 train absolute_loss <loss>=0.8545316772460938\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:33.271] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 214, \"duration\": 438, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:33 INFO 140434797135680] #quality_metric: host=algo-1, epoch=106, train rmse <loss>=0.9586118472446941\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:33 INFO 140434797135680] #quality_metric: host=algo-1, epoch=106, train mse <loss>=0.9189366736778846\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:33 INFO 140434797135680] #quality_metric: host=algo-1, epoch=106, train absolute_loss <loss>=0.7644731170318939\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879412.830675, \"EndTime\": 1630879413.2719643, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 440.36269187927246, \"count\": 1, \"min\": 440.36269187927246, \"max\": 440.36269187927246}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:33 INFO 140434797135680] #progress_metric: host=algo-1, completed 53.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879412.8315737, \"EndTime\": 1630879413.2722297, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 106, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9691990.0, \"count\": 1, \"min\": 9691990, \"max\": 9691990}, \"Total Batches Seen\": {\"sum\": 9738.0, \"count\": 1, \"min\": 9738, \"max\": 9738}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 108.0, \"count\": 1, \"min\": 108, \"max\": 108}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:33 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=205472.46693130638 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:33 INFO 140434797135680] #quality_metric: host=algo-1, epoch=107, batch=0 train rmse <loss>=1.0236389949548559\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:33 INFO 140434797135680] #quality_metric: host=algo-1, epoch=107, batch=0 train mse <loss>=1.0478367919921876\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:33 INFO 140434797135680] #quality_metric: host=algo-1, epoch=107, batch=0 train absolute_loss <loss>=0.8540362548828125\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:33.711] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 216, \"duration\": 437, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:33 INFO 140434797135680] #quality_metric: host=algo-1, epoch=107, train rmse <loss>=0.9581288289450643\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:33 INFO 140434797135680] #quality_metric: host=algo-1, epoch=107, train mse <loss>=0.9180108528556404\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:33 INFO 140434797135680] #quality_metric: host=algo-1, epoch=107, train absolute_loss <loss>=0.7640342655391483\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879413.27204, \"EndTime\": 1630879413.7122936, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 439.35680389404297, \"count\": 1, \"min\": 439.35680389404297, \"max\": 439.35680389404297}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:33 INFO 140434797135680] #progress_metric: host=algo-1, completed 54.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879413.2729106, \"EndTime\": 1630879413.7125528, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 107, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9782560.0, \"count\": 1, \"min\": 9782560, \"max\": 9782560}, \"Total Batches Seen\": {\"sum\": 9829.0, \"count\": 1, \"min\": 9829, \"max\": 9829}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 109.0, \"count\": 1, \"min\": 109, \"max\": 109}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:33 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=205947.12035833285 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:33 INFO 140434797135680] #quality_metric: host=algo-1, epoch=108, batch=0 train rmse <loss>=1.0231251312423557\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:33 INFO 140434797135680] #quality_metric: host=algo-1, epoch=108, batch=0 train mse <loss>=1.0467850341796876\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:33 INFO 140434797135680] #quality_metric: host=algo-1, epoch=108, batch=0 train absolute_loss <loss>=0.853539306640625\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:34.172] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 218, \"duration\": 457, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:34 INFO 140434797135680] #quality_metric: host=algo-1, epoch=108, train rmse <loss>=0.9576495140047131\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:34 INFO 140434797135680] #quality_metric: host=algo-1, epoch=108, train mse <loss>=0.9170925916734632\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:34 INFO 140434797135680] #quality_metric: host=algo-1, epoch=108, train absolute_loss <loss>=0.7635990278642256\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879413.7123704, \"EndTime\": 1630879414.1735296, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 460.1402282714844, \"count\": 1, \"min\": 460.1402282714844, \"max\": 460.1402282714844}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:34 INFO 140434797135680] #progress_metric: host=algo-1, completed 54.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879413.7133348, \"EndTime\": 1630879414.1740067, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 108, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9873130.0, \"count\": 1, \"min\": 9873130, \"max\": 9873130}, \"Total Batches Seen\": {\"sum\": 9920.0, \"count\": 1, \"min\": 9920, \"max\": 9920}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 110.0, \"count\": 1, \"min\": 110, \"max\": 110}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:34 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=196489.52622037163 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:34 INFO 140434797135680] #quality_metric: host=algo-1, epoch=109, batch=0 train rmse <loss>=1.0226118449106496\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:34 INFO 140434797135680] #quality_metric: host=algo-1, epoch=109, batch=0 train mse <loss>=1.0457349853515625\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:34 INFO 140434797135680] #quality_metric: host=algo-1, epoch=109, batch=0 train absolute_loss <loss>=0.8530384521484375\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:34.600] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 220, \"duration\": 423, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:34 INFO 140434797135680] #quality_metric: host=algo-1, epoch=109, train rmse <loss>=0.9571738431700338\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:34 INFO 140434797135680] #quality_metric: host=algo-1, epoch=109, train mse <loss>=0.9161817660488926\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:34 INFO 140434797135680] #quality_metric: host=algo-1, epoch=109, train absolute_loss <loss>=0.7631676776592549\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879414.1737251, \"EndTime\": 1630879414.6013799, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 426.2545108795166, \"count\": 1, \"min\": 426.2545108795166, \"max\": 426.2545108795166}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:34 INFO 140434797135680] #progress_metric: host=algo-1, completed 55.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879414.1750965, \"EndTime\": 1630879414.6016483, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 109, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9963700.0, \"count\": 1, \"min\": 9963700, \"max\": 9963700}, \"Total Batches Seen\": {\"sum\": 10011.0, \"count\": 1, \"min\": 10011, \"max\": 10011}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 111.0, \"count\": 1, \"min\": 111, \"max\": 111}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:34 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=212244.22693729412 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:34 INFO 140434797135680] #quality_metric: host=algo-1, epoch=110, batch=0 train rmse <loss>=1.0220992562605833\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:34 INFO 140434797135680] #quality_metric: host=algo-1, epoch=110, batch=0 train mse <loss>=1.0446868896484376\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:34 INFO 140434797135680] #quality_metric: host=algo-1, epoch=110, batch=0 train absolute_loss <loss>=0.85253564453125\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:35.048] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 222, \"duration\": 444, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:35 INFO 140434797135680] #quality_metric: host=algo-1, epoch=110, train rmse <loss>=0.9567017451092705\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:35 INFO 140434797135680] #quality_metric: host=algo-1, epoch=110, train mse <loss>=0.9152782290951236\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:35 INFO 140434797135680] #quality_metric: host=algo-1, epoch=110, train absolute_loss <loss>=0.7627395737197373\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879414.601454, \"EndTime\": 1630879415.049405, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 446.54202461242676, \"count\": 1, \"min\": 446.54202461242676, \"max\": 446.54202461242676}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:35 INFO 140434797135680] #progress_metric: host=algo-1, completed 55.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879414.6028354, \"EndTime\": 1630879415.0497496, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 110, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 10054270.0, \"count\": 1, \"min\": 10054270, \"max\": 10054270}, \"Total Batches Seen\": {\"sum\": 10102.0, \"count\": 1, \"min\": 10102, \"max\": 10102}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 112.0, \"count\": 1, \"min\": 112, \"max\": 112}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:35 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=202592.90840235702 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:35 INFO 140434797135680] #quality_metric: host=algo-1, epoch=111, batch=0 train rmse <loss>=1.0215874858331702\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:35 INFO 140434797135680] #quality_metric: host=algo-1, epoch=111, batch=0 train mse <loss>=1.0436409912109375\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:35 INFO 140434797135680] #quality_metric: host=algo-1, epoch=111, batch=0 train absolute_loss <loss>=0.8520342407226562\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:35.483] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 224, \"duration\": 431, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:35 INFO 140434797135680] #quality_metric: host=algo-1, epoch=111, train rmse <loss>=0.9562331546219468\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:35 INFO 140434797135680] #quality_metric: host=algo-1, epoch=111, train mse <loss>=0.91438184599824\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:35 INFO 140434797135680] #quality_metric: host=algo-1, epoch=111, train absolute_loss <loss>=0.7623150976830786\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879415.0495005, \"EndTime\": 1630879415.483763, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 433.2857131958008, \"count\": 1, \"min\": 433.2857131958008, \"max\": 433.2857131958008}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:35 INFO 140434797135680] #progress_metric: host=algo-1, completed 56.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879415.0504515, \"EndTime\": 1630879415.4840102, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 111, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 10144840.0, \"count\": 1, \"min\": 10144840, \"max\": 10144840}, \"Total Batches Seen\": {\"sum\": 10193.0, \"count\": 1, \"min\": 10193, \"max\": 10193}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 113.0, \"count\": 1, \"min\": 113, \"max\": 113}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:35 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=208838.06628667933 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:35 INFO 140434797135680] #quality_metric: host=algo-1, epoch=112, batch=0 train rmse <loss>=1.0210764750834043\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:35 INFO 140434797135680] #quality_metric: host=algo-1, epoch=112, batch=0 train mse <loss>=1.04259716796875\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:35 INFO 140434797135680] #quality_metric: host=algo-1, epoch=112, batch=0 train absolute_loss <loss>=0.8515302734375\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:35.931] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 226, \"duration\": 445, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:35 INFO 140434797135680] #quality_metric: host=algo-1, epoch=112, train rmse <loss>=0.9557680189722302\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:35 INFO 140434797135680] #quality_metric: host=algo-1, epoch=112, train mse <loss>=0.9134925060901014\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:35 INFO 140434797135680] #quality_metric: host=algo-1, epoch=112, train absolute_loss <loss>=0.7618940033965058\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879415.4838371, \"EndTime\": 1630879415.932246, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 447.49999046325684, \"count\": 1, \"min\": 447.49999046325684, \"max\": 447.49999046325684}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:35 INFO 140434797135680] #progress_metric: host=algo-1, completed 56.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879415.4846997, \"EndTime\": 1630879415.9326694, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 112, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 10235410.0, \"count\": 1, \"min\": 10235410, \"max\": 10235410}, \"Total Batches Seen\": {\"sum\": 10284.0, \"count\": 1, \"min\": 10284, \"max\": 10284}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 114.0, \"count\": 1, \"min\": 114, \"max\": 114}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:35 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=202112.38675015522 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:35 INFO 140434797135680] #quality_metric: host=algo-1, epoch=113, batch=0 train rmse <loss>=1.0205664045679792\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:35 INFO 140434797135680] #quality_metric: host=algo-1, epoch=113, batch=0 train mse <loss>=1.0415557861328124\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:35 INFO 140434797135680] #quality_metric: host=algo-1, epoch=113, batch=0 train absolute_loss <loss>=0.8510222778320312\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:36.376] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 228, \"duration\": 441, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:36 INFO 140434797135680] #quality_metric: host=algo-1, epoch=113, train rmse <loss>=0.9553062487747596\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:36 INFO 140434797135680] #quality_metric: host=algo-1, epoch=113, train mse <loss>=0.9126100289481027\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:36 INFO 140434797135680] #quality_metric: host=algo-1, epoch=113, train absolute_loss <loss>=0.7614761319003263\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879415.9323375, \"EndTime\": 1630879416.3775601, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 444.1046714782715, \"count\": 1, \"min\": 444.1046714782715, \"max\": 444.1046714782715}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:36 INFO 140434797135680] #progress_metric: host=algo-1, completed 57.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879415.9333937, \"EndTime\": 1630879416.3778827, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 113, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 10325980.0, \"count\": 1, \"min\": 10325980, \"max\": 10325980}, \"Total Batches Seen\": {\"sum\": 10375.0, \"count\": 1, \"min\": 10375, \"max\": 10375}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 115.0, \"count\": 1, \"min\": 115, \"max\": 115}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:36 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=203696.62483290178 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:36 INFO 140434797135680] #quality_metric: host=algo-1, epoch=114, batch=0 train rmse <loss>=1.0200573355323894\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:36 INFO 140434797135680] #quality_metric: host=algo-1, epoch=114, batch=0 train mse <loss>=1.0405169677734376\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:36 INFO 140434797135680] #quality_metric: host=algo-1, epoch=114, batch=0 train absolute_loss <loss>=0.850515625\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:36.809] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 230, \"duration\": 429, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:36 INFO 140434797135680] #quality_metric: host=algo-1, epoch=114, train rmse <loss>=0.9548478071174693\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:36 INFO 140434797135680] #quality_metric: host=algo-1, epoch=114, train mse <loss>=0.9117343347570398\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:36 INFO 140434797135680] #quality_metric: host=algo-1, epoch=114, train absolute_loss <loss>=0.7610616750193167\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879416.377624, \"EndTime\": 1630879416.8102815, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 431.66446685791016, \"count\": 1, \"min\": 431.66446685791016, \"max\": 431.66446685791016}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:36 INFO 140434797135680] #progress_metric: host=algo-1, completed 57.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879416.378589, \"EndTime\": 1630879416.810616, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 114, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 10416550.0, \"count\": 1, \"min\": 10416550, \"max\": 10416550}, \"Total Batches Seen\": {\"sum\": 10466.0, \"count\": 1, \"min\": 10466, \"max\": 10466}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 116.0, \"count\": 1, \"min\": 116, \"max\": 116}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:36 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=209554.28026727846 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:36 INFO 140434797135680] #quality_metric: host=algo-1, epoch=115, batch=0 train rmse <loss>=1.0195493293416154\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:36 INFO 140434797135680] #quality_metric: host=algo-1, epoch=115, batch=0 train mse <loss>=1.0394808349609375\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:36 INFO 140434797135680] #quality_metric: host=algo-1, epoch=115, batch=0 train absolute_loss <loss>=0.85000927734375\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:37.278] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 232, \"duration\": 465, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:37 INFO 140434797135680] #quality_metric: host=algo-1, epoch=115, train rmse <loss>=0.9543926344937309\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:37 INFO 140434797135680] #quality_metric: host=algo-1, epoch=115, train mse <loss>=0.9108653007758842\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:37 INFO 140434797135680] #quality_metric: host=algo-1, epoch=115, train absolute_loss <loss>=0.7606502940418957\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879416.8103788, \"EndTime\": 1630879417.2791412, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 467.7903652191162, \"count\": 1, \"min\": 467.7903652191162, \"max\": 467.7903652191162}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:37 INFO 140434797135680] #progress_metric: host=algo-1, completed 58.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879416.811324, \"EndTime\": 1630879417.2794483, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 115, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 10507120.0, \"count\": 1, \"min\": 10507120, \"max\": 10507120}, \"Total Batches Seen\": {\"sum\": 10557.0, \"count\": 1, \"min\": 10557, \"max\": 10557}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 117.0, \"count\": 1, \"min\": 117, \"max\": 117}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:37 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=193413.2419994145 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:37 INFO 140434797135680] #quality_metric: host=algo-1, epoch=116, batch=0 train rmse <loss>=1.0190425672690273\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:37 INFO 140434797135680] #quality_metric: host=algo-1, epoch=116, batch=0 train mse <loss>=1.03844775390625\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:37 INFO 140434797135680] #quality_metric: host=algo-1, epoch=116, batch=0 train absolute_loss <loss>=0.849505859375\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:37.765] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 234, \"duration\": 484, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:37 INFO 140434797135680] #quality_metric: host=algo-1, epoch=116, train rmse <loss>=0.9539406677338206\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:37 INFO 140434797135680] #quality_metric: host=algo-1, epoch=116, train mse <loss>=0.9100027975564474\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:37 INFO 140434797135680] #quality_metric: host=algo-1, epoch=116, train absolute_loss <loss>=0.7602418165940504\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879417.2792435, \"EndTime\": 1630879417.7667232, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 486.5155220031738, \"count\": 1, \"min\": 486.5155220031738, \"max\": 486.5155220031738}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:37 INFO 140434797135680] #progress_metric: host=algo-1, completed 58.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879417.2801793, \"EndTime\": 1630879417.7671015, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 116, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 10597690.0, \"count\": 1, \"min\": 10597690, \"max\": 10597690}, \"Total Batches Seen\": {\"sum\": 10648.0, \"count\": 1, \"min\": 10648, \"max\": 10648}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 118.0, \"count\": 1, \"min\": 118, \"max\": 118}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:37 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=185955.6085709964 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:37 INFO 140434797135680] #quality_metric: host=algo-1, epoch=117, batch=0 train rmse <loss>=1.0185370511716179\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:37 INFO 140434797135680] #quality_metric: host=algo-1, epoch=117, batch=0 train mse <loss>=1.037417724609375\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:37 INFO 140434797135680] #quality_metric: host=algo-1, epoch=117, batch=0 train absolute_loss <loss>=0.8490083618164063\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:38.210] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 236, \"duration\": 440, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:38 INFO 140434797135680] #quality_metric: host=algo-1, epoch=117, train rmse <loss>=0.9534918540669454\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:38 INFO 140434797135680] #quality_metric: host=algo-1, epoch=117, train mse <loss>=0.909146715772021\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:38 INFO 140434797135680] #quality_metric: host=algo-1, epoch=117, train absolute_loss <loss>=0.7598366866897751\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879417.7667875, \"EndTime\": 1630879418.2109537, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 443.12047958374023, \"count\": 1, \"min\": 443.12047958374023, \"max\": 443.12047958374023}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:38 INFO 140434797135680] #progress_metric: host=algo-1, completed 59.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879417.7678072, \"EndTime\": 1630879418.2113104, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 117, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 10688260.0, \"count\": 1, \"min\": 10688260, \"max\": 10688260}, \"Total Batches Seen\": {\"sum\": 10739.0, \"count\": 1, \"min\": 10739, \"max\": 10739}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 119.0, \"count\": 1, \"min\": 119, \"max\": 119}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:38 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=204138.19500055618 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:38 INFO 140434797135680] #quality_metric: host=algo-1, epoch=118, batch=0 train rmse <loss>=1.0180329028135278\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:38 INFO 140434797135680] #quality_metric: host=algo-1, epoch=118, batch=0 train mse <loss>=1.0363909912109375\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:38 INFO 140434797135680] #quality_metric: host=algo-1, epoch=118, batch=0 train absolute_loss <loss>=0.8485082397460938\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:38.643] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 238, \"duration\": 429, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:38 INFO 140434797135680] #quality_metric: host=algo-1, epoch=118, train rmse <loss>=0.9530461469251026\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:38 INFO 140434797135680] #quality_metric: host=algo-1, epoch=118, train mse <loss>=0.9082969581687843\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:38 INFO 140434797135680] #quality_metric: host=algo-1, epoch=118, train absolute_loss <loss>=0.7594342832460508\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879418.2110748, \"EndTime\": 1630879418.6444345, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 432.3689937591553, \"count\": 1, \"min\": 432.3689937591553, \"max\": 432.3689937591553}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:38 INFO 140434797135680] #progress_metric: host=algo-1, completed 59.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879418.212037, \"EndTime\": 1630879418.6446874, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 118, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 10778830.0, \"count\": 1, \"min\": 10778830, \"max\": 10778830}, \"Total Batches Seen\": {\"sum\": 10830.0, \"count\": 1, \"min\": 10830, \"max\": 10830}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 120.0, \"count\": 1, \"min\": 120, \"max\": 120}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:38 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=209275.59877809943 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:38 INFO 140434797135680] #quality_metric: host=algo-1, epoch=119, batch=0 train rmse <loss>=1.0175301842113824\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:38 INFO 140434797135680] #quality_metric: host=algo-1, epoch=119, batch=0 train mse <loss>=1.03536767578125\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:38 INFO 140434797135680] #quality_metric: host=algo-1, epoch=119, batch=0 train absolute_loss <loss>=0.8480051879882813\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:39.080] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 240, \"duration\": 433, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:39 INFO 140434797135680] #quality_metric: host=algo-1, epoch=119, train rmse <loss>=0.952603484484562\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:39 INFO 140434797135680] #quality_metric: host=algo-1, epoch=119, train mse <loss>=0.9074533986521292\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:39 INFO 140434797135680] #quality_metric: host=algo-1, epoch=119, train absolute_loss <loss>=0.7590345841292496\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879418.6445096, \"EndTime\": 1630879419.0813854, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 436.0013008117676, \"count\": 1, \"min\": 436.0013008117676, \"max\": 436.0013008117676}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:39 INFO 140434797135680] #progress_metric: host=algo-1, completed 60.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879418.6453578, \"EndTime\": 1630879419.0816376, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 119, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 10869400.0, \"count\": 1, \"min\": 10869400, \"max\": 10869400}, \"Total Batches Seen\": {\"sum\": 10921.0, \"count\": 1, \"min\": 10921, \"max\": 10921}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 121.0, \"count\": 1, \"min\": 121, \"max\": 121}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:39 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=207534.56328639179 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:39 INFO 140434797135680] #quality_metric: host=algo-1, epoch=120, batch=0 train rmse <loss>=1.017029017511761\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:39 INFO 140434797135680] #quality_metric: host=algo-1, epoch=120, batch=0 train mse <loss>=1.0343480224609376\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:39 INFO 140434797135680] #quality_metric: host=algo-1, epoch=120, batch=0 train absolute_loss <loss>=0.8475025634765625\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:39.553] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 242, \"duration\": 469, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:39 INFO 140434797135680] #quality_metric: host=algo-1, epoch=120, train rmse <loss>=0.9521638347145448\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:39 INFO 140434797135680] #quality_metric: host=algo-1, epoch=120, train mse <loss>=0.906615968138307\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:39 INFO 140434797135680] #quality_metric: host=algo-1, epoch=120, train absolute_loss <loss>=0.7586380782913376\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879419.0814633, \"EndTime\": 1630879419.553827, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 471.47536277770996, \"count\": 1, \"min\": 471.47536277770996, \"max\": 471.47536277770996}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:39 INFO 140434797135680] #progress_metric: host=algo-1, completed 60.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879419.082268, \"EndTime\": 1630879419.5540948, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 120, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 10959970.0, \"count\": 1, \"min\": 10959970, \"max\": 10959970}, \"Total Batches Seen\": {\"sum\": 11012.0, \"count\": 1, \"min\": 11012, \"max\": 11012}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 122.0, \"count\": 1, \"min\": 122, \"max\": 122}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:39 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=191878.95285334735 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:39 INFO 140434797135680] #quality_metric: host=algo-1, epoch=121, batch=0 train rmse <loss>=1.0165294650526921\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:39 INFO 140434797135680] #quality_metric: host=algo-1, epoch=121, batch=0 train mse <loss>=1.0333321533203126\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:39 INFO 140434797135680] #quality_metric: host=algo-1, epoch=121, batch=0 train absolute_loss <loss>=0.8469983520507812\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:39.986] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 244, \"duration\": 430, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:39 INFO 140434797135680] #quality_metric: host=algo-1, epoch=121, train rmse <loss>=0.9517271246216078\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:39 INFO 140434797135680] #quality_metric: host=algo-1, epoch=121, train mse <loss>=0.9057845197405134\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:39 INFO 140434797135680] #quality_metric: host=algo-1, epoch=121, train absolute_loss <loss>=0.7582447120750343\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879419.553903, \"EndTime\": 1630879419.98718, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 432.27195739746094, \"count\": 1, \"min\": 432.27195739746094, \"max\": 432.27195739746094}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:39 INFO 140434797135680] #progress_metric: host=algo-1, completed 61.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879419.5548818, \"EndTime\": 1630879419.9874752, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 121, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 11050540.0, \"count\": 1, \"min\": 11050540, \"max\": 11050540}, \"Total Batches Seen\": {\"sum\": 11103.0, \"count\": 1, \"min\": 11103, \"max\": 11103}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 123.0, \"count\": 1, \"min\": 123, \"max\": 123}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:39 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=209304.19468890998 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:39 INFO 140434797135680] #quality_metric: host=algo-1, epoch=122, batch=0 train rmse <loss>=1.016031769503604\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:39 INFO 140434797135680] #quality_metric: host=algo-1, epoch=122, batch=0 train mse <loss>=1.032320556640625\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:39 INFO 140434797135680] #quality_metric: host=algo-1, epoch=122, batch=0 train absolute_loss <loss>=0.846491943359375\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:40.433] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 246, \"duration\": 443, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:40 INFO 140434797135680] #quality_metric: host=algo-1, epoch=122, train rmse <loss>=0.9512933328722514\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:40 INFO 140434797135680] #quality_metric: host=algo-1, epoch=122, train mse <loss>=0.9049590051671961\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:40 INFO 140434797135680] #quality_metric: host=algo-1, epoch=122, train absolute_loss <loss>=0.7578541843288548\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879419.9872544, \"EndTime\": 1630879420.433963, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 445.81079483032227, \"count\": 1, \"min\": 445.81079483032227, \"max\": 445.81079483032227}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:40 INFO 140434797135680] #progress_metric: host=algo-1, completed 61.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879419.9881237, \"EndTime\": 1630879420.4342165, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 122, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 11141110.0, \"count\": 1, \"min\": 11141110, \"max\": 11141110}, \"Total Batches Seen\": {\"sum\": 11194.0, \"count\": 1, \"min\": 11194, \"max\": 11194}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 124.0, \"count\": 1, \"min\": 124, \"max\": 124}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:40 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=202964.83215567053 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:40 INFO 140434797135680] #quality_metric: host=algo-1, epoch=123, batch=0 train rmse <loss>=1.01553575329032\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:40 INFO 140434797135680] #quality_metric: host=algo-1, epoch=123, batch=0 train mse <loss>=1.0313128662109374\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:40 INFO 140434797135680] #quality_metric: host=algo-1, epoch=123, batch=0 train absolute_loss <loss>=0.8459834594726563\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:40.860] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 248, \"duration\": 424, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:40 INFO 140434797135680] #quality_metric: host=algo-1, epoch=123, train rmse <loss>=0.950862389043377\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:40 INFO 140434797135680] #quality_metric: host=algo-1, epoch=123, train mse <loss>=0.9041392828972785\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:40 INFO 140434797135680] #quality_metric: host=algo-1, epoch=123, train absolute_loss <loss>=0.7574661523169214\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879420.4340405, \"EndTime\": 1630879420.86138, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 426.4791011810303, \"count\": 1, \"min\": 426.4791011810303, \"max\": 426.4791011810303}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:40 INFO 140434797135680] #progress_metric: host=algo-1, completed 62.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879420.4348724, \"EndTime\": 1630879420.8617163, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 123, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 11231680.0, \"count\": 1, \"min\": 11231680, \"max\": 11231680}, \"Total Batches Seen\": {\"sum\": 11285.0, \"count\": 1, \"min\": 11285, \"max\": 11285}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 125.0, \"count\": 1, \"min\": 125, \"max\": 125}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:40 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=212114.8117491239 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:40 INFO 140434797135680] #quality_metric: host=algo-1, epoch=124, batch=0 train rmse <loss>=1.0150418397895908\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:40 INFO 140434797135680] #quality_metric: host=algo-1, epoch=124, batch=0 train mse <loss>=1.0303099365234376\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:40 INFO 140434797135680] #quality_metric: host=algo-1, epoch=124, batch=0 train absolute_loss <loss>=0.8454752807617187\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:41.322] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 250, \"duration\": 458, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:41 INFO 140434797135680] #quality_metric: host=algo-1, epoch=124, train rmse <loss>=0.9504342698396498\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:41 INFO 140434797135680] #quality_metric: host=algo-1, epoch=124, train mse <loss>=0.9033253012856284\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:41 INFO 140434797135680] #quality_metric: host=algo-1, epoch=124, train absolute_loss <loss>=0.7570806509164664\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879420.8614767, \"EndTime\": 1630879421.3228729, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 460.44421195983887, \"count\": 1, \"min\": 460.44421195983887, \"max\": 460.44421195983887}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:41 INFO 140434797135680] #progress_metric: host=algo-1, completed 62.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879420.8624, \"EndTime\": 1630879421.3232477, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 124, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 11322250.0, \"count\": 1, \"min\": 11322250, \"max\": 11322250}, \"Total Batches Seen\": {\"sum\": 11376.0, \"count\": 1, \"min\": 11376, \"max\": 11376}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 126.0, \"count\": 1, \"min\": 126, \"max\": 126}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:41 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=196466.5598580022 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:41 INFO 140434797135680] #quality_metric: host=algo-1, epoch=125, batch=0 train rmse <loss>=1.014549851592906\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:41 INFO 140434797135680] #quality_metric: host=algo-1, epoch=125, batch=0 train mse <loss>=1.0293114013671876\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:41 INFO 140434797135680] #quality_metric: host=algo-1, epoch=125, batch=0 train absolute_loss <loss>=0.8449688110351562\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:41.761] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 252, \"duration\": 436, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:41 INFO 140434797135680] #quality_metric: host=algo-1, epoch=125, train rmse <loss>=0.9500089042427199\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:41 INFO 140434797135680] #quality_metric: host=algo-1, epoch=125, train mse <loss>=0.9025169181404533\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:41 INFO 140434797135680] #quality_metric: host=algo-1, epoch=125, train absolute_loss <loss>=0.7566981201171875\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879421.3229702, \"EndTime\": 1630879421.7630732, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 439.0835762023926, \"count\": 1, \"min\": 439.0835762023926, \"max\": 439.0835762023926}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:41 INFO 140434797135680] #progress_metric: host=algo-1, completed 63.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879421.3239625, \"EndTime\": 1630879421.7636497, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 125, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 11412820.0, \"count\": 1, \"min\": 11412820, \"max\": 11412820}, \"Total Batches Seen\": {\"sum\": 11467.0, \"count\": 1, \"min\": 11467, \"max\": 11467}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 127.0, \"count\": 1, \"min\": 127, \"max\": 127}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:41 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=205842.77846865606 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:41 INFO 140434797135680] #quality_metric: host=algo-1, epoch=126, batch=0 train rmse <loss>=1.014060092447065\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:41 INFO 140434797135680] #quality_metric: host=algo-1, epoch=126, batch=0 train mse <loss>=1.02831787109375\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:41 INFO 140434797135680] #quality_metric: host=algo-1, epoch=126, batch=0 train absolute_loss <loss>=0.8444611206054687\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:42.197] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 254, \"duration\": 430, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:42 INFO 140434797135680] #quality_metric: host=algo-1, epoch=126, train rmse <loss>=0.9495862729974633\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:42 INFO 140434797135680] #quality_metric: host=algo-1, epoch=126, train mse <loss>=0.901714089865213\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:42 INFO 140434797135680] #quality_metric: host=algo-1, epoch=126, train absolute_loss <loss>=0.7563180045662345\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879421.7633524, \"EndTime\": 1630879422.1978757, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 433.1076145172119, \"count\": 1, \"min\": 433.1076145172119, \"max\": 433.1076145172119}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:42 INFO 140434797135680] #progress_metric: host=algo-1, completed 63.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879421.76474, \"EndTime\": 1630879422.19812, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 126, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 11503390.0, \"count\": 1, \"min\": 11503390, \"max\": 11503390}, \"Total Batches Seen\": {\"sum\": 11558.0, \"count\": 1, \"min\": 11558, \"max\": 11558}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 128.0, \"count\": 1, \"min\": 128, \"max\": 128}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:42 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=208919.7272392794 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:42 INFO 140434797135680] #quality_metric: host=algo-1, epoch=127, batch=0 train rmse <loss>=1.0135724451476076\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:42 INFO 140434797135680] #quality_metric: host=algo-1, epoch=127, batch=0 train mse <loss>=1.0273291015625\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:42 INFO 140434797135680] #quality_metric: host=algo-1, epoch=127, batch=0 train absolute_loss <loss>=0.8439522094726563\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:42.661] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 256, \"duration\": 460, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:42 INFO 140434797135680] #quality_metric: host=algo-1, epoch=127, train rmse <loss>=0.9491663281719231\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:42 INFO 140434797135680] #quality_metric: host=algo-1, epoch=127, train mse <loss>=0.9009167185353709\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:42 INFO 140434797135680] #quality_metric: host=algo-1, epoch=127, train absolute_loss <loss>=0.7559403196900756\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879422.1979513, \"EndTime\": 1630879422.6620326, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 463.2232189178467, \"count\": 1, \"min\": 463.2232189178467, \"max\": 463.2232189178467}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:42 INFO 140434797135680] #progress_metric: host=algo-1, completed 64.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879422.1987815, \"EndTime\": 1630879422.6624136, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 127, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 11593960.0, \"count\": 1, \"min\": 11593960, \"max\": 11593960}, \"Total Batches Seen\": {\"sum\": 11649.0, \"count\": 1, \"min\": 11649, \"max\": 11649}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 129.0, \"count\": 1, \"min\": 129, \"max\": 129}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:42 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=195280.9675061302 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:42 INFO 140434797135680] #quality_metric: host=algo-1, epoch=128, batch=0 train rmse <loss>=1.0130872139776517\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:42 INFO 140434797135680] #quality_metric: host=algo-1, epoch=128, batch=0 train mse <loss>=1.026345703125\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:42 INFO 140434797135680] #quality_metric: host=algo-1, epoch=128, batch=0 train absolute_loss <loss>=0.8434422607421875\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:43.166] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 258, \"duration\": 502, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:43 INFO 140434797135680] #quality_metric: host=algo-1, epoch=128, train rmse <loss>=0.948749035865139\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:43 INFO 140434797135680] #quality_metric: host=algo-1, epoch=128, train mse <loss>=0.9001247330550309\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:43 INFO 140434797135680] #quality_metric: host=algo-1, epoch=128, train absolute_loss <loss>=0.7555648857368218\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879422.6621435, \"EndTime\": 1630879423.1675584, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 504.38547134399414, \"count\": 1, \"min\": 504.38547134399414, \"max\": 504.38547134399414}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:43 INFO 140434797135680] #progress_metric: host=algo-1, completed 64.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879422.6631436, \"EndTime\": 1630879423.1678622, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 128, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 11684530.0, \"count\": 1, \"min\": 11684530, \"max\": 11684530}, \"Total Batches Seen\": {\"sum\": 11740.0, \"count\": 1, \"min\": 11740, \"max\": 11740}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 130.0, \"count\": 1, \"min\": 130, \"max\": 130}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:43 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=179394.60079450082 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:43 INFO 140434797135680] #quality_metric: host=algo-1, epoch=129, batch=0 train rmse <loss>=1.012604342135139\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:43 INFO 140434797135680] #quality_metric: host=algo-1, epoch=129, batch=0 train mse <loss>=1.0253675537109375\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:43 INFO 140434797135680] #quality_metric: host=algo-1, epoch=129, batch=0 train absolute_loss <loss>=0.842931640625\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:43.620] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 260, \"duration\": 450, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:43 INFO 140434797135680] #quality_metric: host=algo-1, epoch=129, train rmse <loss>=0.9483343472416385\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:43 INFO 140434797135680] #quality_metric: host=algo-1, epoch=129, train mse <loss>=0.8993380341582246\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:43 INFO 140434797135680] #quality_metric: host=algo-1, epoch=129, train absolute_loss <loss>=0.7551918261182177\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879423.167657, \"EndTime\": 1630879423.6216695, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 452.99458503723145, \"count\": 1, \"min\": 452.99458503723145, \"max\": 452.99458503723145}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:43 INFO 140434797135680] #progress_metric: host=algo-1, completed 65.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879423.168647, \"EndTime\": 1630879423.6219153, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 129, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 11775100.0, \"count\": 1, \"min\": 11775100, \"max\": 11775100}, \"Total Batches Seen\": {\"sum\": 11831.0, \"count\": 1, \"min\": 11831, \"max\": 11831}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 131.0, \"count\": 1, \"min\": 131, \"max\": 131}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:43 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=199757.22408225486 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:43 INFO 140434797135680] #quality_metric: host=algo-1, epoch=130, batch=0 train rmse <loss>=1.0121240139089922\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:43 INFO 140434797135680] #quality_metric: host=algo-1, epoch=130, batch=0 train mse <loss>=1.02439501953125\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:43 INFO 140434797135680] #quality_metric: host=algo-1, epoch=130, batch=0 train absolute_loss <loss>=0.8424227905273437\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:44.082] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 262, \"duration\": 458, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:44 INFO 140434797135680] #quality_metric: host=algo-1, epoch=130, train rmse <loss>=0.9479222094671627\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:44 INFO 140434797135680] #quality_metric: host=algo-1, epoch=130, train mse <loss>=0.8985565152011075\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:44 INFO 140434797135680] #quality_metric: host=algo-1, epoch=130, train absolute_loss <loss>=0.7548207229781937\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879423.621744, \"EndTime\": 1630879424.083425, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 460.8116149902344, \"count\": 1, \"min\": 460.8116149902344, \"max\": 460.8116149902344}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:44 INFO 140434797135680] #progress_metric: host=algo-1, completed 65.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879423.6225677, \"EndTime\": 1630879424.0838406, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 130, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 11865670.0, \"count\": 1, \"min\": 11865670, \"max\": 11865670}, \"Total Batches Seen\": {\"sum\": 11922.0, \"count\": 1, \"min\": 11922, \"max\": 11922}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 132.0, \"count\": 1, \"min\": 132, \"max\": 132}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:44 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=196280.99368650792 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:44 INFO 140434797135680] #quality_metric: host=algo-1, epoch=131, batch=0 train rmse <loss>=1.0116462932548362\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:44 INFO 140434797135680] #quality_metric: host=algo-1, epoch=131, batch=0 train mse <loss>=1.02342822265625\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:44 INFO 140434797135680] #quality_metric: host=algo-1, epoch=131, batch=0 train absolute_loss <loss>=0.8419180297851563\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:44.530] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 264, \"duration\": 444, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:44 INFO 140434797135680] #quality_metric: host=algo-1, epoch=131, train rmse <loss>=0.9475126272860661\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:44 INFO 140434797135680] #quality_metric: host=algo-1, epoch=131, train mse <loss>=0.8977801788665436\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:44 INFO 140434797135680] #quality_metric: host=algo-1, epoch=131, train absolute_loss <loss>=0.7544517936287346\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879424.0835154, \"EndTime\": 1630879424.530973, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 446.3365077972412, \"count\": 1, \"min\": 446.3365077972412, \"max\": 446.3365077972412}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:44 INFO 140434797135680] #progress_metric: host=algo-1, completed 66.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879424.0846114, \"EndTime\": 1630879424.5312731, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 131, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 11956240.0, \"count\": 1, \"min\": 11956240, \"max\": 11956240}, \"Total Batches Seen\": {\"sum\": 12013.0, \"count\": 1, \"min\": 12013, \"max\": 12013}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 133.0, \"count\": 1, \"min\": 133, \"max\": 133}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:44 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=202712.26022517885 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:44 INFO 140434797135680] #quality_metric: host=algo-1, epoch=132, batch=0 train rmse <loss>=1.0111711838684572\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:44 INFO 140434797135680] #quality_metric: host=algo-1, epoch=132, batch=0 train mse <loss>=1.0224671630859374\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:44 INFO 140434797135680] #quality_metric: host=algo-1, epoch=132, batch=0 train absolute_loss <loss>=0.841416015625\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:44.961] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 266, \"duration\": 427, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:44 INFO 140434797135680] #quality_metric: host=algo-1, epoch=132, train rmse <loss>=0.9471055144298254\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:44 INFO 140434797135680] #quality_metric: host=algo-1, epoch=132, train mse <loss>=0.8970088554633843\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:44 INFO 140434797135680] #quality_metric: host=algo-1, epoch=132, train absolute_loss <loss>=0.754085441170158\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879424.5310488, \"EndTime\": 1630879424.9620135, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 430.0720691680908, \"count\": 1, \"min\": 430.0720691680908, \"max\": 430.0720691680908}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:44 INFO 140434797135680] #progress_metric: host=algo-1, completed 66.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879424.5319142, \"EndTime\": 1630879424.9623518, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 132, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12046810.0, \"count\": 1, \"min\": 12046810, \"max\": 12046810}, \"Total Batches Seen\": {\"sum\": 12104.0, \"count\": 1, \"min\": 12104, \"max\": 12104}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 134.0, \"count\": 1, \"min\": 134, \"max\": 134}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:44 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=210345.86600323705 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:44 INFO 140434797135680] #quality_metric: host=algo-1, epoch=133, batch=0 train rmse <loss>=1.010698900794102\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:44 INFO 140434797135680] #quality_metric: host=algo-1, epoch=133, batch=0 train mse <loss>=1.0215122680664062\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:44 INFO 140434797135680] #quality_metric: host=algo-1, epoch=133, batch=0 train absolute_loss <loss>=0.8409179077148438\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:45.396] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 268, \"duration\": 432, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:45 INFO 140434797135680] #quality_metric: host=algo-1, epoch=133, train rmse <loss>=0.9467008648739123\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:45 INFO 140434797135680] #quality_metric: host=algo-1, epoch=133, train mse <loss>=0.8962425275530134\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:45 INFO 140434797135680] #quality_metric: host=algo-1, epoch=133, train absolute_loss <loss>=0.7537219459617531\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879424.9621117, \"EndTime\": 1630879425.3976817, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 434.6010684967041, \"count\": 1, \"min\": 434.6010684967041, \"max\": 434.6010684967041}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:45 INFO 140434797135680] #progress_metric: host=algo-1, completed 67.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879424.9630325, \"EndTime\": 1630879425.3980408, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 133, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12137380.0, \"count\": 1, \"min\": 12137380, \"max\": 12137380}, \"Total Batches Seen\": {\"sum\": 12195.0, \"count\": 1, \"min\": 12195, \"max\": 12195}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 135.0, \"count\": 1, \"min\": 135, \"max\": 135}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:45 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=208138.70500569826 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:45 INFO 140434797135680] #quality_metric: host=algo-1, epoch=134, batch=0 train rmse <loss>=1.0102294782042407\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:45 INFO 140434797135680] #quality_metric: host=algo-1, epoch=134, batch=0 train mse <loss>=1.0205635986328125\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:45 INFO 140434797135680] #quality_metric: host=algo-1, epoch=134, batch=0 train absolute_loss <loss>=0.8404219970703125\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:45.839] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 270, \"duration\": 439, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:45 INFO 140434797135680] #quality_metric: host=algo-1, epoch=134, train rmse <loss>=0.9462986424411454\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:45 INFO 140434797135680] #quality_metric: host=algo-1, epoch=134, train mse <loss>=0.8954811206859546\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:45 INFO 140434797135680] #quality_metric: host=algo-1, epoch=134, train absolute_loss <loss>=0.7533609833769745\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879425.3977692, \"EndTime\": 1630879425.8407848, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 441.9260025024414, \"count\": 1, \"min\": 441.9260025024414, \"max\": 441.9260025024414}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:45 INFO 140434797135680] #progress_metric: host=algo-1, completed 67.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879425.3987763, \"EndTime\": 1630879425.8411107, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 134, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12227950.0, \"count\": 1, \"min\": 12227950, \"max\": 12227950}, \"Total Batches Seen\": {\"sum\": 12286.0, \"count\": 1, \"min\": 12286, \"max\": 12286}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 136.0, \"count\": 1, \"min\": 136, \"max\": 136}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:45 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=204698.5376494038 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:45 INFO 140434797135680] #quality_metric: host=algo-1, epoch=135, batch=0 train rmse <loss>=1.0097629805332877\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:45 INFO 140434797135680] #quality_metric: host=algo-1, epoch=135, batch=0 train mse <loss>=1.0196212768554687\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:45 INFO 140434797135680] #quality_metric: host=algo-1, epoch=135, batch=0 train absolute_loss <loss>=0.8399278564453125\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:46.273] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 272, \"duration\": 430, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:46 INFO 140434797135680] #quality_metric: host=algo-1, epoch=135, train rmse <loss>=0.9458988087467051\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:46 INFO 140434797135680] #quality_metric: host=algo-1, epoch=135, train mse <loss>=0.8947245563884357\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:46 INFO 140434797135680] #quality_metric: host=algo-1, epoch=135, train absolute_loss <loss>=0.75300244140625\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879425.8408616, \"EndTime\": 1630879426.2742233, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 432.4333667755127, \"count\": 1, \"min\": 432.4333667755127, \"max\": 432.4333667755127}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:46 INFO 140434797135680] #progress_metric: host=algo-1, completed 68.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879425.8417609, \"EndTime\": 1630879426.2745817, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 135, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12318520.0, \"count\": 1, \"min\": 12318520, \"max\": 12318520}, \"Total Batches Seen\": {\"sum\": 12377.0, \"count\": 1, \"min\": 12377, \"max\": 12377}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 137.0, \"count\": 1, \"min\": 137, \"max\": 137}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:46 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=209201.608549619 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:46 INFO 140434797135680] #quality_metric: host=algo-1, epoch=136, batch=0 train rmse <loss>=1.0092994420733281\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:46 INFO 140434797135680] #quality_metric: host=algo-1, epoch=136, batch=0 train mse <loss>=1.0186853637695312\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:46 INFO 140434797135680] #quality_metric: host=algo-1, epoch=136, batch=0 train absolute_loss <loss>=0.8394388427734375\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:46.716] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 274, \"duration\": 439, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:46 INFO 140434797135680] #quality_metric: host=algo-1, epoch=136, train rmse <loss>=0.9455013207115982\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:46 INFO 140434797135680] #quality_metric: host=algo-1, epoch=136, train mse <loss>=0.8939727474673764\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:46 INFO 140434797135680] #quality_metric: host=algo-1, epoch=136, train absolute_loss <loss>=0.7526462791359032\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879426.2742972, \"EndTime\": 1630879426.717072, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 441.8013095855713, \"count\": 1, \"min\": 441.8013095855713, \"max\": 441.8013095855713}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:46 INFO 140434797135680] #progress_metric: host=algo-1, completed 68.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879426.2752442, \"EndTime\": 1630879426.717327, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 136, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12409090.0, \"count\": 1, \"min\": 12409090, \"max\": 12409090}, \"Total Batches Seen\": {\"sum\": 12468.0, \"count\": 1, \"min\": 12468, \"max\": 12468}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 138.0, \"count\": 1, \"min\": 138, \"max\": 138}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:46 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=204812.76440376588 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:46 INFO 140434797135680] #quality_metric: host=algo-1, epoch=137, batch=0 train rmse <loss>=1.0088390484046192\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:46 INFO 140434797135680] #quality_metric: host=algo-1, epoch=137, batch=0 train mse <loss>=1.0177562255859376\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:46 INFO 140434797135680] #quality_metric: host=algo-1, epoch=137, batch=0 train absolute_loss <loss>=0.8389505615234375\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:47.151] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 276, \"duration\": 432, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:47 INFO 140434797135680] #quality_metric: host=algo-1, epoch=137, train rmse <loss>=0.945106145102096\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:47 INFO 140434797135680] #quality_metric: host=algo-1, epoch=137, train mse <loss>=0.8932256255097442\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:47 INFO 140434797135680] #quality_metric: host=algo-1, epoch=137, train absolute_loss <loss>=0.7522920317597441\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879426.7171478, \"EndTime\": 1630879427.1524355, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 434.43965911865234, \"count\": 1, \"min\": 434.43965911865234, \"max\": 434.43965911865234}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:47 INFO 140434797135680] #progress_metric: host=algo-1, completed 69.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879426.7179697, \"EndTime\": 1630879427.1527948, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 137, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12499660.0, \"count\": 1, \"min\": 12499660, \"max\": 12499660}, \"Total Batches Seen\": {\"sum\": 12559.0, \"count\": 1, \"min\": 12559, \"max\": 12559}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 139.0, \"count\": 1, \"min\": 139, \"max\": 139}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:47 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=208210.1192330586 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:47 INFO 140434797135680] #quality_metric: host=algo-1, epoch=138, batch=0 train rmse <loss>=1.0083817433067572\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:47 INFO 140434797135680] #quality_metric: host=algo-1, epoch=138, batch=0 train mse <loss>=1.016833740234375\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:47 INFO 140434797135680] #quality_metric: host=algo-1, epoch=138, batch=0 train absolute_loss <loss>=0.8384630737304688\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:47.598] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 278, \"duration\": 443, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:47 INFO 140434797135680] #quality_metric: host=algo-1, epoch=138, train rmse <loss>=0.9447132408020726\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:47 INFO 140434797135680] #quality_metric: host=algo-1, epoch=138, train mse <loss>=0.8924831073467548\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:47 INFO 140434797135680] #quality_metric: host=algo-1, epoch=138, train absolute_loss <loss>=0.7519399065290179\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879427.1525598, \"EndTime\": 1630879427.5993264, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 445.74928283691406, \"count\": 1, \"min\": 445.74928283691406, \"max\": 445.74928283691406}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:47 INFO 140434797135680] #progress_metric: host=algo-1, completed 69.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879427.153549, \"EndTime\": 1630879427.5995762, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 138, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12590230.0, \"count\": 1, \"min\": 12590230, \"max\": 12590230}, \"Total Batches Seen\": {\"sum\": 12650.0, \"count\": 1, \"min\": 12650, \"max\": 12650}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 140.0, \"count\": 1, \"min\": 140, \"max\": 140}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:47 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=203000.08191009556 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:47 INFO 140434797135680] #quality_metric: host=algo-1, epoch=139, batch=0 train rmse <loss>=1.0079277732040595\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:47 INFO 140434797135680] #quality_metric: host=algo-1, epoch=139, batch=0 train mse <loss>=1.0159183959960938\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:47 INFO 140434797135680] #quality_metric: host=algo-1, epoch=139, batch=0 train absolute_loss <loss>=0.8379768676757813\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:48.037] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 280, \"duration\": 435, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:48 INFO 140434797135680] #quality_metric: host=algo-1, epoch=139, train rmse <loss>=0.9443226074504223\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:48 INFO 140434797135680] #quality_metric: host=algo-1, epoch=139, train mse <loss>=0.8917451869419643\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:48 INFO 140434797135680] #quality_metric: host=algo-1, epoch=139, train absolute_loss <loss>=0.751589598267943\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879427.5994027, \"EndTime\": 1630879428.0386386, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 438.27176094055176, \"count\": 1, \"min\": 438.27176094055176, \"max\": 438.27176094055176}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:48 INFO 140434797135680] #progress_metric: host=algo-1, completed 70.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879427.6003392, \"EndTime\": 1630879428.0390341, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 139, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12680800.0, \"count\": 1, \"min\": 12680800, \"max\": 12680800}, \"Total Batches Seen\": {\"sum\": 12741.0, \"count\": 1, \"min\": 12741, \"max\": 12741}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 141.0, \"count\": 1, \"min\": 141, \"max\": 141}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:48 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=206374.96524725677 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:48 INFO 140434797135680] #quality_metric: host=algo-1, epoch=140, batch=0 train rmse <loss>=1.007477021440424\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:48 INFO 140434797135680] #quality_metric: host=algo-1, epoch=140, batch=0 train mse <loss>=1.0150099487304687\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:48 INFO 140434797135680] #quality_metric: host=algo-1, epoch=140, batch=0 train absolute_loss <loss>=0.8374918212890625\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:48.533] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 282, \"duration\": 492, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:48 INFO 140434797135680] #quality_metric: host=algo-1, epoch=140, train rmse <loss>=0.9439341803639342\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:48 INFO 140434797135680] #quality_metric: host=algo-1, epoch=140, train mse <loss>=0.8910117368593321\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:48 INFO 140434797135680] #quality_metric: host=algo-1, epoch=140, train absolute_loss <loss>=0.7512415288568853\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879428.0387502, \"EndTime\": 1630879428.534085, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 494.2162036895752, \"count\": 1, \"min\": 494.2162036895752, \"max\": 494.2162036895752}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:48 INFO 140434797135680] #progress_metric: host=algo-1, completed 70.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879428.0398233, \"EndTime\": 1630879428.5344424, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 140, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12771370.0, \"count\": 1, \"min\": 12771370, \"max\": 12771370}, \"Total Batches Seen\": {\"sum\": 12832.0, \"count\": 1, \"min\": 12832, \"max\": 12832}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 142.0, \"count\": 1, \"min\": 142, \"max\": 142}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:48 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=183061.17375043553 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:48 INFO 140434797135680] #quality_metric: host=algo-1, epoch=141, batch=0 train rmse <loss>=1.0070296741647873\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:48 INFO 140434797135680] #quality_metric: host=algo-1, epoch=141, batch=0 train mse <loss>=1.0141087646484375\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:48 INFO 140434797135680] #quality_metric: host=algo-1, epoch=141, batch=0 train absolute_loss <loss>=0.83700830078125\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:48.967] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 284, \"duration\": 430, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:48 INFO 140434797135680] #quality_metric: host=algo-1, epoch=141, train rmse <loss>=0.9435479448516509\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:48 INFO 140434797135680] #quality_metric: host=algo-1, epoch=141, train mse <loss>=0.8902827242337741\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:48 INFO 140434797135680] #quality_metric: host=algo-1, epoch=141, train absolute_loss <loss>=0.7508953971443596\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879428.5341733, \"EndTime\": 1630879428.968318, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 433.1097602844238, \"count\": 1, \"min\": 433.1097602844238, \"max\": 433.1097602844238}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:48 INFO 140434797135680] #progress_metric: host=algo-1, completed 71.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879428.5351815, \"EndTime\": 1630879428.9687245, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 141, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12861940.0, \"count\": 1, \"min\": 12861940, \"max\": 12861940}, \"Total Batches Seen\": {\"sum\": 12923.0, \"count\": 1, \"min\": 12923, \"max\": 12923}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 143.0, \"count\": 1, \"min\": 143, \"max\": 143}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:48 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=208832.44080861678 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:48 INFO 140434797135680] #quality_metric: host=algo-1, epoch=142, batch=0 train rmse <loss>=1.006585735916221\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:48 INFO 140434797135680] #quality_metric: host=algo-1, epoch=142, batch=0 train mse <loss>=1.01321484375\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:48 INFO 140434797135680] #quality_metric: host=algo-1, epoch=142, batch=0 train absolute_loss <loss>=0.8365263671875\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:49.418] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 286, \"duration\": 447, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:49 INFO 140434797135680] #quality_metric: host=algo-1, epoch=142, train rmse <loss>=0.9431638609379442\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:49 INFO 140434797135680] #quality_metric: host=algo-1, epoch=142, train mse <loss>=0.8895580685793698\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:49 INFO 140434797135680] #quality_metric: host=algo-1, epoch=142, train absolute_loss <loss>=0.7505514050158826\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879428.9684405, \"EndTime\": 1630879429.4190662, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 449.5959281921387, \"count\": 1, \"min\": 449.5959281921387, \"max\": 449.5959281921387}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:49 INFO 140434797135680] #progress_metric: host=algo-1, completed 71.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879428.969442, \"EndTime\": 1630879429.4194567, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 142, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12952510.0, \"count\": 1, \"min\": 12952510, \"max\": 12952510}, \"Total Batches Seen\": {\"sum\": 13014.0, \"count\": 1, \"min\": 13014, \"max\": 13014}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 144.0, \"count\": 1, \"min\": 144, \"max\": 144}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:49 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=201188.5123055657 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:49 INFO 140434797135680] #quality_metric: host=algo-1, epoch=143, batch=0 train rmse <loss>=1.0061452415383738\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:49 INFO 140434797135680] #quality_metric: host=algo-1, epoch=143, batch=0 train mse <loss>=1.0123282470703125\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:49 INFO 140434797135680] #quality_metric: host=algo-1, epoch=143, batch=0 train absolute_loss <loss>=0.8360462646484375\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:49.851] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 288, \"duration\": 429, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:49 INFO 140434797135680] #quality_metric: host=algo-1, epoch=143, train rmse <loss>=0.9427819081312386\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:49 INFO 140434797135680] #quality_metric: host=algo-1, epoch=143, train mse <loss>=0.8888377262995794\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:49 INFO 140434797135680] #quality_metric: host=algo-1, epoch=143, train absolute_loss <loss>=0.7502092620514251\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879429.4192207, \"EndTime\": 1630879429.8521254, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 431.868314743042, \"count\": 1, \"min\": 431.868314743042, \"max\": 431.868314743042}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:49 INFO 140434797135680] #progress_metric: host=algo-1, completed 72.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879429.4201899, \"EndTime\": 1630879429.8524342, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 143, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 13043080.0, \"count\": 1, \"min\": 13043080, \"max\": 13043080}, \"Total Batches Seen\": {\"sum\": 13105.0, \"count\": 1, \"min\": 13105, \"max\": 13105}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 145.0, \"count\": 1, \"min\": 145, \"max\": 145}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:49 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=209455.8373836527 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:49 INFO 140434797135680] #quality_metric: host=algo-1, epoch=144, batch=0 train rmse <loss>=1.0057083169338912\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:49 INFO 140434797135680] #quality_metric: host=algo-1, epoch=144, batch=0 train mse <loss>=1.01144921875\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:49 INFO 140434797135680] #quality_metric: host=algo-1, epoch=144, batch=0 train absolute_loss <loss>=0.835571044921875\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:50.312] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 290, \"duration\": 457, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:50 INFO 140434797135680] #quality_metric: host=algo-1, epoch=144, train rmse <loss>=0.9424020409823729\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:50 INFO 140434797135680] #quality_metric: host=algo-1, epoch=144, train mse <loss>=0.8881216068477421\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:50 INFO 140434797135680] #quality_metric: host=algo-1, epoch=144, train absolute_loss <loss>=0.7498688823993389\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879429.8522425, \"EndTime\": 1630879430.3127391, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 459.6221446990967, \"count\": 1, \"min\": 459.6221446990967, \"max\": 459.6221446990967}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:50 INFO 140434797135680] #progress_metric: host=algo-1, completed 72.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879429.8530915, \"EndTime\": 1630879430.3129911, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 144, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 13133650.0, \"count\": 1, \"min\": 13133650, \"max\": 13133650}, \"Total Batches Seen\": {\"sum\": 13196.0, \"count\": 1, \"min\": 13196, \"max\": 13196}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 146.0, \"count\": 1, \"min\": 146, \"max\": 146}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:50 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=196865.1669434028 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:50 INFO 140434797135680] #quality_metric: host=algo-1, epoch=145, batch=0 train rmse <loss>=1.0052749971148287\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:50 INFO 140434797135680] #quality_metric: host=algo-1, epoch=145, batch=0 train mse <loss>=1.0105778198242188\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:50 INFO 140434797135680] #quality_metric: host=algo-1, epoch=145, batch=0 train absolute_loss <loss>=0.8350982666015625\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:50.751] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 292, \"duration\": 436, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:50 INFO 140434797135680] #quality_metric: host=algo-1, epoch=145, train rmse <loss>=0.9420242499105392\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:50 INFO 140434797135680] #quality_metric: host=algo-1, epoch=145, train mse <loss>=0.8874096874195141\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:50 INFO 140434797135680] #quality_metric: host=algo-1, epoch=145, train absolute_loss <loss>=0.7495303753863324\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879430.3128154, \"EndTime\": 1630879430.752238, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 438.518762588501, \"count\": 1, \"min\": 438.518762588501, \"max\": 438.518762588501}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:50 INFO 140434797135680] #progress_metric: host=algo-1, completed 73.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879430.3136916, \"EndTime\": 1630879430.752588, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 145, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 13224220.0, \"count\": 1, \"min\": 13224220, \"max\": 13224220}, \"Total Batches Seen\": {\"sum\": 13287.0, \"count\": 1, \"min\": 13287, \"max\": 13287}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 147.0, \"count\": 1, \"min\": 147, \"max\": 147}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:50 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=206285.31096627892 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:50 INFO 140434797135680] #quality_metric: host=algo-1, epoch=146, batch=0 train rmse <loss>=1.0048452867446653\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:50 INFO 140434797135680] #quality_metric: host=algo-1, epoch=146, batch=0 train mse <loss>=1.0097140502929687\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:50 INFO 140434797135680] #quality_metric: host=algo-1, epoch=146, batch=0 train absolute_loss <loss>=0.8346292114257813\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:51.192] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 294, \"duration\": 437, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:51 INFO 140434797135680] #quality_metric: host=algo-1, epoch=146, train rmse <loss>=0.9416484832813479\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:51 INFO 140434797135680] #quality_metric: host=algo-1, epoch=146, train mse <loss>=0.8867018660660628\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:51 INFO 140434797135680] #quality_metric: host=algo-1, epoch=146, train absolute_loss <loss>=0.7491937906453897\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879430.7523487, \"EndTime\": 1630879431.1929557, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 439.62955474853516, \"count\": 1, \"min\": 439.62955474853516, \"max\": 439.62955474853516}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:51 INFO 140434797135680] #progress_metric: host=algo-1, completed 73.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879430.7532973, \"EndTime\": 1630879431.1932063, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 146, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 13314790.0, \"count\": 1, \"min\": 13314790, \"max\": 13314790}, \"Total Batches Seen\": {\"sum\": 13378.0, \"count\": 1, \"min\": 13378, \"max\": 13378}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 148.0, \"count\": 1, \"min\": 148, \"max\": 148}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:51 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=205822.70339505118 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:51 INFO 140434797135680] #quality_metric: host=algo-1, epoch=147, batch=0 train rmse <loss>=1.0044193119892086\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:51 INFO 140434797135680] #quality_metric: host=algo-1, epoch=147, batch=0 train mse <loss>=1.008858154296875\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:51 INFO 140434797135680] #quality_metric: host=algo-1, epoch=147, batch=0 train absolute_loss <loss>=0.8341655883789062\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:51.629] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 296, \"duration\": 434, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:51 INFO 140434797135680] #quality_metric: host=algo-1, epoch=147, train rmse <loss>=0.9412747267741424\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:51 INFO 140434797135680] #quality_metric: host=algo-1, epoch=147, train mse <loss>=0.8859981112637363\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:51 INFO 140434797135680] #quality_metric: host=algo-1, epoch=147, train absolute_loss <loss>=0.7488590497027386\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879431.1930325, \"EndTime\": 1630879431.6304188, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 436.4895820617676, \"count\": 1, \"min\": 436.4895820617676, \"max\": 436.4895820617676}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:51 INFO 140434797135680] #progress_metric: host=algo-1, completed 74.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879431.1939023, \"EndTime\": 1630879431.630666, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 147, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 13405360.0, \"count\": 1, \"min\": 13405360, \"max\": 13405360}, \"Total Batches Seen\": {\"sum\": 13469.0, \"count\": 1, \"min\": 13469, \"max\": 13469}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 149.0, \"count\": 1, \"min\": 149, \"max\": 149}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:51 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=207305.5618173434 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:51 INFO 140434797135680] #quality_metric: host=algo-1, epoch=148, batch=0 train rmse <loss>=1.0039970776032854\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:51 INFO 140434797135680] #quality_metric: host=algo-1, epoch=148, batch=0 train mse <loss>=1.0080101318359376\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:51 INFO 140434797135680] #quality_metric: host=algo-1, epoch=148, batch=0 train absolute_loss <loss>=0.8337046508789062\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:52.060] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 298, \"duration\": 428, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:52 INFO 140434797135680] #quality_metric: host=algo-1, epoch=148, train rmse <loss>=0.9409029731609961\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:52 INFO 140434797135680] #quality_metric: host=algo-1, epoch=148, train mse <loss>=0.8852984049032022\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:52 INFO 140434797135680] #quality_metric: host=algo-1, epoch=148, train absolute_loss <loss>=0.7485260854867788\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879431.630494, \"EndTime\": 1630879432.0615816, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 430.22751808166504, \"count\": 1, \"min\": 430.22751808166504, \"max\": 430.22751808166504}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:52 INFO 140434797135680] #progress_metric: host=algo-1, completed 74.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879431.6313272, \"EndTime\": 1630879432.0619352, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 148, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 13495930.0, \"count\": 1, \"min\": 13495930, \"max\": 13495930}, \"Total Batches Seen\": {\"sum\": 13560.0, \"count\": 1, \"min\": 13560, \"max\": 13560}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 150.0, \"count\": 1, \"min\": 150, \"max\": 150}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:52 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=210265.41423400087 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:52 INFO 140434797135680] #quality_metric: host=algo-1, epoch=149, batch=0 train rmse <loss>=1.003578527490422\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:52 INFO 140434797135680] #quality_metric: host=algo-1, epoch=149, batch=0 train mse <loss>=1.0071698608398438\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:52 INFO 140434797135680] #quality_metric: host=algo-1, epoch=149, batch=0 train absolute_loss <loss>=0.8332462768554687\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:52.519] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 300, \"duration\": 455, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:52 INFO 140434797135680] #quality_metric: host=algo-1, epoch=149, train rmse <loss>=0.9405331346068102\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:52 INFO 140434797135680] #quality_metric: host=algo-1, epoch=149, train mse <loss>=0.8846025772933122\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:52 INFO 140434797135680] #quality_metric: host=algo-1, epoch=149, train absolute_loss <loss>=0.748195060310783\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879432.0616577, \"EndTime\": 1630879432.5203993, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 457.65042304992676, \"count\": 1, \"min\": 457.65042304992676, \"max\": 457.65042304992676}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:52 INFO 140434797135680] #progress_metric: host=algo-1, completed 75.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879432.0626614, \"EndTime\": 1630879432.5207357, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 149, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 13586500.0, \"count\": 1, \"min\": 13586500, \"max\": 13586500}, \"Total Batches Seen\": {\"sum\": 13651.0, \"count\": 1, \"min\": 13651, \"max\": 13651}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 151.0, \"count\": 1, \"min\": 151, \"max\": 151}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:52 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=197660.8764389646 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:52 INFO 140434797135680] #quality_metric: host=algo-1, epoch=150, batch=0 train rmse <loss>=1.0031639096328395\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:52 INFO 140434797135680] #quality_metric: host=algo-1, epoch=150, batch=0 train mse <loss>=1.0063378295898437\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:52 INFO 140434797135680] #quality_metric: host=algo-1, epoch=150, batch=0 train absolute_loss <loss>=0.8327910766601563\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:52.948] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 302, \"duration\": 425, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:52 INFO 140434797135680] #quality_metric: host=algo-1, epoch=150, train rmse <loss>=0.9401652461881039\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:52 INFO 140434797135680] #quality_metric: host=algo-1, epoch=150, train mse <loss>=0.8839106901399382\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:52 INFO 140434797135680] #quality_metric: host=algo-1, epoch=150, train absolute_loss <loss>=0.747865966126159\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879432.5204825, \"EndTime\": 1630879432.9495122, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 428.09057235717773, \"count\": 1, \"min\": 428.09057235717773, \"max\": 428.09057235717773}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:52 INFO 140434797135680] #progress_metric: host=algo-1, completed 75.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879432.5213847, \"EndTime\": 1630879432.9498556, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 150, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 13677070.0, \"count\": 1, \"min\": 13677070, \"max\": 13677070}, \"Total Batches Seen\": {\"sum\": 13742.0, \"count\": 1, \"min\": 13742, \"max\": 13742}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 152.0, \"count\": 1, \"min\": 152, \"max\": 152}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:52 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=211313.87803054578 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:52 INFO 140434797135680] #quality_metric: host=algo-1, epoch=151, batch=0 train rmse <loss>=1.0027531376068932\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:52 INFO 140434797135680] #quality_metric: host=algo-1, epoch=151, batch=0 train mse <loss>=1.0055138549804687\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:52 INFO 140434797135680] #quality_metric: host=algo-1, epoch=151, batch=0 train absolute_loss <loss>=0.8323388671875\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:53.452] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 304, \"duration\": 500, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:53 INFO 140434797135680] #quality_metric: host=algo-1, epoch=151, train rmse <loss>=0.9397992416817582\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:53 INFO 140434797135680] #quality_metric: host=algo-1, epoch=151, train mse <loss>=0.8832226146656078\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:53 INFO 140434797135680] #quality_metric: host=algo-1, epoch=151, train absolute_loss <loss>=0.7475384984278417\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879432.949588, \"EndTime\": 1630879433.4533637, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 502.7778148651123, \"count\": 1, \"min\": 502.7778148651123, \"max\": 502.7778148651123}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:53 INFO 140434797135680] #progress_metric: host=algo-1, completed 76.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879432.9505572, \"EndTime\": 1630879433.453665, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 151, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 13767640.0, \"count\": 1, \"min\": 13767640, \"max\": 13767640}, \"Total Batches Seen\": {\"sum\": 13833.0, \"count\": 1, \"min\": 13833, \"max\": 13833}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 153.0, \"count\": 1, \"min\": 153, \"max\": 153}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:53 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=179974.83963123642 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:53 INFO 140434797135680] #quality_metric: host=algo-1, epoch=152, batch=0 train rmse <loss>=1.0023462465869142\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:53 INFO 140434797135680] #quality_metric: host=algo-1, epoch=152, batch=0 train mse <loss>=1.004697998046875\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:53 INFO 140434797135680] #quality_metric: host=algo-1, epoch=152, batch=0 train absolute_loss <loss>=0.8318934936523438\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:53.926] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 306, \"duration\": 470, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:53 INFO 140434797135680] #quality_metric: host=algo-1, epoch=152, train rmse <loss>=0.9394351097245157\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:53 INFO 140434797135680] #quality_metric: host=algo-1, epoch=152, train mse <loss>=0.8825383253831129\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:53 INFO 140434797135680] #quality_metric: host=algo-1, epoch=152, train absolute_loss <loss>=0.7472128269069798\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879433.4534278, \"EndTime\": 1630879433.9271176, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 472.72586822509766, \"count\": 1, \"min\": 472.72586822509766, \"max\": 472.72586822509766}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:53 INFO 140434797135680] #progress_metric: host=algo-1, completed 76.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879433.4543533, \"EndTime\": 1630879433.9274826, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 152, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 13858210.0, \"count\": 1, \"min\": 13858210, \"max\": 13858210}, \"Total Batches Seen\": {\"sum\": 13924.0, \"count\": 1, \"min\": 13924, \"max\": 13924}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 154.0, \"count\": 1, \"min\": 154, \"max\": 154}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:53 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=191372.91822983706 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:53 INFO 140434797135680] #quality_metric: host=algo-1, epoch=153, batch=0 train rmse <loss>=1.0019433022179325\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:53 INFO 140434797135680] #quality_metric: host=algo-1, epoch=153, batch=0 train mse <loss>=1.003890380859375\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:53 INFO 140434797135680] #quality_metric: host=algo-1, epoch=153, batch=0 train absolute_loss <loss>=0.8314515991210938\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:54.361] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 308, \"duration\": 431, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:54 INFO 140434797135680] #quality_metric: host=algo-1, epoch=153, train rmse <loss>=0.9390728199970956\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:54 INFO 140434797135680] #quality_metric: host=algo-1, epoch=153, train mse <loss>=0.8818577612572974\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:54 INFO 140434797135680] #quality_metric: host=algo-1, epoch=153, train absolute_loss <loss>=0.7468888301639767\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879433.9271965, \"EndTime\": 1630879434.3619392, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 433.78424644470215, \"count\": 1, \"min\": 433.78424644470215, \"max\": 433.78424644470215}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:54 INFO 140434797135680] #progress_metric: host=algo-1, completed 77.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879433.928127, \"EndTime\": 1630879434.36227, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 153, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 13948780.0, \"count\": 1, \"min\": 13948780, \"max\": 13948780}, \"Total Batches Seen\": {\"sum\": 14015.0, \"count\": 1, \"min\": 14015, \"max\": 14015}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 155.0, \"count\": 1, \"min\": 155, \"max\": 155}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:54 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=208542.27919815018 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:54 INFO 140434797135680] #quality_metric: host=algo-1, epoch=154, batch=0 train rmse <loss>=1.0015443397339556\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:54 INFO 140434797135680] #quality_metric: host=algo-1, epoch=154, batch=0 train mse <loss>=1.003091064453125\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:54 INFO 140434797135680] #quality_metric: host=algo-1, epoch=154, batch=0 train absolute_loss <loss>=0.8310133056640625\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:54.991] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 310, \"duration\": 627, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:54 INFO 140434797135680] #quality_metric: host=algo-1, epoch=154, train rmse <loss>=0.93871234498047\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:54 INFO 140434797135680] #quality_metric: host=algo-1, epoch=154, train mse <loss>=0.8811808666187328\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:54 INFO 140434797135680] #quality_metric: host=algo-1, epoch=154, train absolute_loss <loss>=0.7465666081355168\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879434.3620365, \"EndTime\": 1630879434.9932702, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 630.2599906921387, \"count\": 1, \"min\": 630.2599906921387, \"max\": 630.2599906921387}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:54 INFO 140434797135680] #progress_metric: host=algo-1, completed 77.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879434.362984, \"EndTime\": 1630879434.993904, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 154, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 14039350.0, \"count\": 1, \"min\": 14039350, \"max\": 14039350}, \"Total Batches Seen\": {\"sum\": 14106.0, \"count\": 1, \"min\": 14106, \"max\": 14106}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 156.0, \"count\": 1, \"min\": 156, \"max\": 156}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:54 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=143464.51580107777 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:55 INFO 140434797135680] #quality_metric: host=algo-1, epoch=155, batch=0 train rmse <loss>=1.0011493638953806\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:55 INFO 140434797135680] #quality_metric: host=algo-1, epoch=155, batch=0 train mse <loss>=1.002300048828125\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:55 INFO 140434797135680] #quality_metric: host=algo-1, epoch=155, batch=0 train absolute_loss <loss>=0.8305786743164062\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:55.555] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 312, \"duration\": 558, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:55 INFO 140434797135680] #quality_metric: host=algo-1, epoch=155, train rmse <loss>=0.9383536828347525\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:55 INFO 140434797135680] #quality_metric: host=algo-1, epoch=155, train mse <loss>=0.8805076340895432\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:55 INFO 140434797135680] #quality_metric: host=algo-1, epoch=155, train absolute_loss <loss>=0.7462461621630323\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879434.9935894, \"EndTime\": 1630879435.5558875, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 560.8220100402832, \"count\": 1, \"min\": 560.8220100402832, \"max\": 560.8220100402832}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:55 INFO 140434797135680] #progress_metric: host=algo-1, completed 78.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879434.995038, \"EndTime\": 1630879435.5562787, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 155, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 14129920.0, \"count\": 1, \"min\": 14129920, \"max\": 14129920}, \"Total Batches Seen\": {\"sum\": 14197.0, \"count\": 1, \"min\": 14197, \"max\": 14197}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 157.0, \"count\": 1, \"min\": 157, \"max\": 157}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:55 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=161330.14078023055 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:55 INFO 140434797135680] #quality_metric: host=algo-1, epoch=156, batch=0 train rmse <loss>=1.0007584099169646\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:55 INFO 140434797135680] #quality_metric: host=algo-1, epoch=156, batch=0 train mse <loss>=1.0015173950195313\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:55 INFO 140434797135680] #quality_metric: host=algo-1, epoch=156, batch=0 train absolute_loss <loss>=0.8301478881835938\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:55.989] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 314, \"duration\": 430, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:55 INFO 140434797135680] #quality_metric: host=algo-1, epoch=156, train rmse <loss>=0.9379967730725027\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:55 INFO 140434797135680] #quality_metric: host=algo-1, epoch=156, train mse <loss>=0.8798379462944282\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:55 INFO 140434797135680] #quality_metric: host=algo-1, epoch=156, train absolute_loss <loss>=0.7459273802369506\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879435.5560033, \"EndTime\": 1630879435.9900823, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 433.0456256866455, \"count\": 1, \"min\": 433.0456256866455, \"max\": 433.0456256866455}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:55 INFO 140434797135680] #progress_metric: host=algo-1, completed 78.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879435.5569978, \"EndTime\": 1630879435.9904258, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 156, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 14220490.0, \"count\": 1, \"min\": 14220490, \"max\": 14220490}, \"Total Batches Seen\": {\"sum\": 14288.0, \"count\": 1, \"min\": 14288, \"max\": 14288}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 158.0, \"count\": 1, \"min\": 158, \"max\": 158}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:55 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=208891.6957495047 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:55 INFO 140434797135680] #quality_metric: host=algo-1, epoch=157, batch=0 train rmse <loss>=1.0003715435265321\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:55 INFO 140434797135680] #quality_metric: host=algo-1, epoch=157, batch=0 train mse <loss>=1.0007432250976562\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:55 INFO 140434797135680] #quality_metric: host=algo-1, epoch=157, batch=0 train absolute_loss <loss>=0.8297212524414063\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:56.421] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 316, \"duration\": 429, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:56 INFO 140434797135680] #quality_metric: host=algo-1, epoch=157, train rmse <loss>=0.9376416151912071\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:56 INFO 140434797135680] #quality_metric: host=algo-1, epoch=157, train mse <loss>=0.8791717985383757\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:56 INFO 140434797135680] #quality_metric: host=algo-1, epoch=157, train absolute_loss <loss>=0.7456102455893716\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879435.9901552, \"EndTime\": 1630879436.4227145, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 431.52689933776855, \"count\": 1, \"min\": 431.52689933776855, \"max\": 431.52689933776855}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:56 INFO 140434797135680] #progress_metric: host=algo-1, completed 79.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879435.9911587, \"EndTime\": 1630879436.4230993, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 157, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 14311060.0, \"count\": 1, \"min\": 14311060, \"max\": 14311060}, \"Total Batches Seen\": {\"sum\": 14379.0, \"count\": 1, \"min\": 14379, \"max\": 14379}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 159.0, \"count\": 1, \"min\": 159, \"max\": 159}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:56 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=209615.56491035232 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:56 INFO 140434797135680] #quality_metric: host=algo-1, epoch=158, batch=0 train rmse <loss>=0.9999886779144208\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:56 INFO 140434797135680] #quality_metric: host=algo-1, epoch=158, batch=0 train mse <loss>=0.9999773559570313\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:56 INFO 140434797135680] #quality_metric: host=algo-1, epoch=158, batch=0 train absolute_loss <loss>=0.8293002319335937\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:56.878] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 318, \"duration\": 452, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:56 INFO 140434797135680] #quality_metric: host=algo-1, epoch=158, train rmse <loss>=0.9372881689624046\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:56 INFO 140434797135680] #quality_metric: host=algo-1, epoch=158, train mse <loss>=0.8785091116768973\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:56 INFO 140434797135680] #quality_metric: host=algo-1, epoch=158, train absolute_loss <loss>=0.745294933947888\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879436.4227962, \"EndTime\": 1630879436.8788743, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 454.9825191497803, \"count\": 1, \"min\": 454.9825191497803, \"max\": 454.9825191497803}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:56 INFO 140434797135680] #progress_metric: host=algo-1, completed 79.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879436.4238634, \"EndTime\": 1630879436.8792055, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 158, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 14401630.0, \"count\": 1, \"min\": 14401630, \"max\": 14401630}, \"Total Batches Seen\": {\"sum\": 14470.0, \"count\": 1, \"min\": 14470, \"max\": 14470}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 160.0, \"count\": 1, \"min\": 160, \"max\": 160}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:56 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=198843.8822173391 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:56 INFO 140434797135680] #quality_metric: host=algo-1, epoch=159, batch=0 train rmse <loss>=0.9996100008546301\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:56 INFO 140434797135680] #quality_metric: host=algo-1, epoch=159, batch=0 train mse <loss>=0.9992201538085937\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:56 INFO 140434797135680] #quality_metric: host=algo-1, epoch=159, batch=0 train absolute_loss <loss>=0.8288860473632812\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:57.306] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 320, \"duration\": 425, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:57 INFO 140434797135680] #quality_metric: host=algo-1, epoch=159, train rmse <loss>=0.9369364191425291\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:57 INFO 140434797135680] #quality_metric: host=algo-1, epoch=159, train mse <loss>=0.877849853515625\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:57 INFO 140434797135680] #quality_metric: host=algo-1, epoch=159, train absolute_loss <loss>=0.7449816223815248\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879436.8789687, \"EndTime\": 1630879437.3075473, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 427.631139755249, \"count\": 1, \"min\": 427.631139755249, \"max\": 427.631139755249}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:57 INFO 140434797135680] #progress_metric: host=algo-1, completed 80.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879436.879888, \"EndTime\": 1630879437.3077924, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 159, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 14492200.0, \"count\": 1, \"min\": 14492200, \"max\": 14492200}, \"Total Batches Seen\": {\"sum\": 14561.0, \"count\": 1, \"min\": 14561, \"max\": 14561}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 161.0, \"count\": 1, \"min\": 161, \"max\": 161}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:57 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=211594.48234067395 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:57 INFO 140434797135680] #quality_metric: host=algo-1, epoch=160, batch=0 train rmse <loss>=0.999235333863553\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:57 INFO 140434797135680] #quality_metric: host=algo-1, epoch=160, batch=0 train mse <loss>=0.9984712524414062\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:57 INFO 140434797135680] #quality_metric: host=algo-1, epoch=160, batch=0 train absolute_loss <loss>=0.8284833374023437\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:57.751] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 322, \"duration\": 441, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:57 INFO 140434797135680] #quality_metric: host=algo-1, epoch=160, train rmse <loss>=0.9365863486655198\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:57 INFO 140434797135680] #quality_metric: host=algo-1, epoch=160, train mse <loss>=0.8771939885066106\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:57 INFO 140434797135680] #quality_metric: host=algo-1, epoch=160, train absolute_loss <loss>=0.7446702290629292\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879437.3076222, \"EndTime\": 1630879437.7523723, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 443.8462257385254, \"count\": 1, \"min\": 443.8462257385254, \"max\": 443.8462257385254}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:57 INFO 140434797135680] #progress_metric: host=algo-1, completed 80.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879437.3084989, \"EndTime\": 1630879437.752618, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 160, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 14582770.0, \"count\": 1, \"min\": 14582770, \"max\": 14582770}, \"Total Batches Seen\": {\"sum\": 14652.0, \"count\": 1, \"min\": 14652, \"max\": 14652}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 162.0, \"count\": 1, \"min\": 162, \"max\": 162}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:57 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=203873.28605891144 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:57 INFO 140434797135680] #quality_metric: host=algo-1, epoch=161, batch=0 train rmse <loss>=0.9988648342149452\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:57 INFO 140434797135680] #quality_metric: host=algo-1, epoch=161, batch=0 train mse <loss>=0.99773095703125\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:57 INFO 140434797135680] #quality_metric: host=algo-1, epoch=161, batch=0 train absolute_loss <loss>=0.8280891723632813\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:58.174] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 324, \"duration\": 419, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:58 INFO 140434797135680] #quality_metric: host=algo-1, epoch=161, train rmse <loss>=0.9362379346995345\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:58 INFO 140434797135680] #quality_metric: host=algo-1, epoch=161, train mse <loss>=0.8765414703704498\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:58 INFO 140434797135680] #quality_metric: host=algo-1, epoch=161, train absolute_loss <loss>=0.7443603106488238\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879437.752447, \"EndTime\": 1630879438.1751094, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 421.7684268951416, \"count\": 1, \"min\": 421.7684268951416, \"max\": 421.7684268951416}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:58 INFO 140434797135680] #progress_metric: host=algo-1, completed 81.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879437.7533133, \"EndTime\": 1630879438.1755567, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 161, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 14673340.0, \"count\": 1, \"min\": 14673340, \"max\": 14673340}, \"Total Batches Seen\": {\"sum\": 14743.0, \"count\": 1, \"min\": 14743, \"max\": 14743}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 163.0, \"count\": 1, \"min\": 163, \"max\": 163}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:58 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=214429.83906392794 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:58 INFO 140434797135680] #quality_metric: host=algo-1, epoch=162, batch=0 train rmse <loss>=0.998498506547769\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:58 INFO 140434797135680] #quality_metric: host=algo-1, epoch=162, batch=0 train mse <loss>=0.996999267578125\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:58 INFO 140434797135680] #quality_metric: host=algo-1, epoch=162, batch=0 train absolute_loss <loss>=0.8277005615234375\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:58.621] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 326, \"duration\": 444, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:58 INFO 140434797135680] #quality_metric: host=algo-1, epoch=162, train rmse <loss>=0.9358911407533093\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:58 INFO 140434797135680] #quality_metric: host=algo-1, epoch=162, train mse <loss>=0.8758922273405305\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:58 INFO 140434797135680] #quality_metric: host=algo-1, epoch=162, train absolute_loss <loss>=0.7440517799461281\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879438.1752295, \"EndTime\": 1630879438.6227696, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 446.38729095458984, \"count\": 1, \"min\": 446.38729095458984, \"max\": 446.38729095458984}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:58 INFO 140434797135680] #progress_metric: host=algo-1, completed 81.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879438.1763375, \"EndTime\": 1630879438.6231272, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 162, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 14763910.0, \"count\": 1, \"min\": 14763910, \"max\": 14763910}, \"Total Batches Seen\": {\"sum\": 14834.0, \"count\": 1, \"min\": 14834, \"max\": 14834}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 164.0, \"count\": 1, \"min\": 164, \"max\": 164}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:58 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=202649.86406366527 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:58 INFO 140434797135680] #quality_metric: host=algo-1, epoch=163, batch=0 train rmse <loss>=0.9981362943064032\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:58 INFO 140434797135680] #quality_metric: host=algo-1, epoch=163, batch=0 train mse <loss>=0.9962760620117187\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:58 INFO 140434797135680] #quality_metric: host=algo-1, epoch=163, batch=0 train absolute_loss <loss>=0.8273165283203125\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:59.130] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 328, \"duration\": 504, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:59 INFO 140434797135680] #quality_metric: host=algo-1, epoch=163, train rmse <loss>=0.935545949271434\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:59 INFO 140434797135680] #quality_metric: host=algo-1, epoch=163, train mse <loss>=0.8752462231981886\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:59 INFO 140434797135680] #quality_metric: host=algo-1, epoch=163, train absolute_loss <loss>=0.7437447127457504\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879438.6228588, \"EndTime\": 1630879439.130983, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 507.08842277526855, \"count\": 1, \"min\": 507.08842277526855, \"max\": 507.08842277526855}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:59 INFO 140434797135680] #progress_metric: host=algo-1, completed 82.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879438.6238682, \"EndTime\": 1630879439.1313086, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 163, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 14854480.0, \"count\": 1, \"min\": 14854480, \"max\": 14854480}, \"Total Batches Seen\": {\"sum\": 14925.0, \"count\": 1, \"min\": 14925, \"max\": 14925}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 165.0, \"count\": 1, \"min\": 165, \"max\": 165}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:59 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=178431.97835583237 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:59 INFO 140434797135680] #quality_metric: host=algo-1, epoch=164, batch=0 train rmse <loss>=0.9977783243149033\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:59 INFO 140434797135680] #quality_metric: host=algo-1, epoch=164, batch=0 train mse <loss>=0.9955615844726563\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:59 INFO 140434797135680] #quality_metric: host=algo-1, epoch=164, batch=0 train absolute_loss <loss>=0.8269379272460937\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:03:59.559] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 330, \"duration\": 426, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:59 INFO 140434797135680] #quality_metric: host=algo-1, epoch=164, train rmse <loss>=0.9352023609525779\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:59 INFO 140434797135680] #quality_metric: host=algo-1, epoch=164, train mse <loss>=0.8746034559312758\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:59 INFO 140434797135680] #quality_metric: host=algo-1, epoch=164, train absolute_loss <loss>=0.7434393223353795\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879439.1310816, \"EndTime\": 1630879439.5604942, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 428.4548759460449, \"count\": 1, \"min\": 428.4548759460449, \"max\": 428.4548759460449}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:59 INFO 140434797135680] #progress_metric: host=algo-1, completed 82.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879439.1320124, \"EndTime\": 1630879439.5608442, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 164, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 14945050.0, \"count\": 1, \"min\": 14945050, \"max\": 14945050}, \"Total Batches Seen\": {\"sum\": 15016.0, \"count\": 1, \"min\": 15016, \"max\": 15016}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 166.0, \"count\": 1, \"min\": 166, \"max\": 166}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:59 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=211131.13298192804 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:59 INFO 140434797135680] #quality_metric: host=algo-1, epoch=165, batch=0 train rmse <loss>=0.9974244481589352\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:59 INFO 140434797135680] #quality_metric: host=algo-1, epoch=165, batch=0 train mse <loss>=0.9948555297851562\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:03:59 INFO 140434797135680] #quality_metric: host=algo-1, epoch=165, batch=0 train absolute_loss <loss>=0.8265667114257812\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:04:00.022] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 332, \"duration\": 459, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:00 INFO 140434797135680] #quality_metric: host=algo-1, epoch=165, train rmse <loss>=0.9348603133525499\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:00 INFO 140434797135680] #quality_metric: host=algo-1, epoch=165, train mse <loss>=0.8739638054816278\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:00 INFO 140434797135680] #quality_metric: host=algo-1, epoch=165, train absolute_loss <loss>=0.7431355141440591\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879439.560608, \"EndTime\": 1630879440.0266917, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 465.1310443878174, \"count\": 1, \"min\": 465.1310443878174, \"max\": 465.1310443878174}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:00 INFO 140434797135680] #progress_metric: host=algo-1, completed 83.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879439.5615299, \"EndTime\": 1630879440.0271237, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 165, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 15035620.0, \"count\": 1, \"min\": 15035620, \"max\": 15035620}, \"Total Batches Seen\": {\"sum\": 15107.0, \"count\": 1, \"min\": 15107, \"max\": 15107}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 167.0, \"count\": 1, \"min\": 167, \"max\": 167}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:00 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=194458.9635594951 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:00 INFO 140434797135680] #quality_metric: host=algo-1, epoch=166, batch=0 train rmse <loss>=0.9970748232329407\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:00 INFO 140434797135680] #quality_metric: host=algo-1, epoch=166, batch=0 train mse <loss>=0.994158203125\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:00 INFO 140434797135680] #quality_metric: host=algo-1, epoch=166, batch=0 train absolute_loss <loss>=0.8262019653320313\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:04:00.465] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 334, \"duration\": 432, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:00 INFO 140434797135680] #quality_metric: host=algo-1, epoch=166, train rmse <loss>=0.9345198239527873\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:00 INFO 140434797135680] #quality_metric: host=algo-1, epoch=166, train mse <loss>=0.8733273013607487\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:00 INFO 140434797135680] #quality_metric: host=algo-1, epoch=166, train absolute_loss <loss>=0.7428333304268974\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879440.026797, \"EndTime\": 1630879440.466207, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 434.62562561035156, \"count\": 1, \"min\": 434.62562561035156, \"max\": 434.62562561035156}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:00 INFO 140434797135680] #progress_metric: host=algo-1, completed 83.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879440.0315518, \"EndTime\": 1630879440.4666238, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 166, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 15126190.0, \"count\": 1, \"min\": 15126190, \"max\": 15126190}, \"Total Batches Seen\": {\"sum\": 15198.0, \"count\": 1, \"min\": 15198, \"max\": 15198}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 168.0, \"count\": 1, \"min\": 168, \"max\": 168}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:00 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=208082.49792261558 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:00 INFO 140434797135680] #quality_metric: host=algo-1, epoch=167, batch=0 train rmse <loss>=0.9967293315396927\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:00 INFO 140434797135680] #quality_metric: host=algo-1, epoch=167, batch=0 train mse <loss>=0.9934693603515625\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:00 INFO 140434797135680] #quality_metric: host=algo-1, epoch=167, batch=0 train absolute_loss <loss>=0.825843994140625\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:04:00.909] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 336, \"duration\": 440, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:00 INFO 140434797135680] #quality_metric: host=algo-1, epoch=167, train rmse <loss>=0.934180865379206\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:00 INFO 140434797135680] #quality_metric: host=algo-1, epoch=167, train mse <loss>=0.8726938892406422\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:00 INFO 140434797135680] #quality_metric: host=algo-1, epoch=167, train absolute_loss <loss>=0.7425325605790694\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879440.4663503, \"EndTime\": 1630879440.9098086, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 442.4440860748291, \"count\": 1, \"min\": 442.4440860748291, \"max\": 442.4440860748291}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:00 INFO 140434797135680] #progress_metric: host=algo-1, completed 84.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879440.4673362, \"EndTime\": 1630879440.910141, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 167, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 15216760.0, \"count\": 1, \"min\": 15216760, \"max\": 15216760}, \"Total Batches Seen\": {\"sum\": 15289.0, \"count\": 1, \"min\": 15289, \"max\": 15289}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 169.0, \"count\": 1, \"min\": 169, \"max\": 169}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:00 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=204469.25533163175 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:00 INFO 140434797135680] #quality_metric: host=algo-1, epoch=168, batch=0 train rmse <loss>=0.9963880386351275\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:00 INFO 140434797135680] #quality_metric: host=algo-1, epoch=168, batch=0 train mse <loss>=0.9927891235351562\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:00 INFO 140434797135680] #quality_metric: host=algo-1, epoch=168, batch=0 train absolute_loss <loss>=0.825494384765625\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:04:01.339] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 338, \"duration\": 427, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:01 INFO 140434797135680] #quality_metric: host=algo-1, epoch=168, train rmse <loss>=0.9338434051827362\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:01 INFO 140434797135680] #quality_metric: host=algo-1, epoch=168, train mse <loss>=0.8720635054032881\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:01 INFO 140434797135680] #quality_metric: host=algo-1, epoch=168, train absolute_loss <loss>=0.7422333581945398\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879440.9099083, \"EndTime\": 1630879441.340793, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 429.8510551452637, \"count\": 1, \"min\": 429.8510551452637, \"max\": 429.8510551452637}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:01 INFO 140434797135680] #progress_metric: host=algo-1, completed 84.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879440.910859, \"EndTime\": 1630879441.3410633, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 168, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 15307330.0, \"count\": 1, \"min\": 15307330, \"max\": 15307330}, \"Total Batches Seen\": {\"sum\": 15380.0, \"count\": 1, \"min\": 15380, \"max\": 15380}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 170.0, \"count\": 1, \"min\": 170, \"max\": 170}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:01 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=210463.68573673183 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:01 INFO 140434797135680] #quality_metric: host=algo-1, epoch=169, batch=0 train rmse <loss>=0.9960509488353401\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:01 INFO 140434797135680] #quality_metric: host=algo-1, epoch=169, batch=0 train mse <loss>=0.9921174926757812\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:01 INFO 140434797135680] #quality_metric: host=algo-1, epoch=169, batch=0 train absolute_loss <loss>=0.825151123046875\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:04:02.126] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 340, \"duration\": 783, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:02 INFO 140434797135680] #quality_metric: host=algo-1, epoch=169, train rmse <loss>=0.9335074252298727\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:02 INFO 140434797135680] #quality_metric: host=algo-1, epoch=169, train mse <loss>=0.8714361129593063\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:02 INFO 140434797135680] #quality_metric: host=algo-1, epoch=169, train absolute_loss <loss>=0.7419357185782967\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879441.340867, \"EndTime\": 1630879442.1274774, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 785.7165336608887, \"count\": 1, \"min\": 785.7165336608887, \"max\": 785.7165336608887}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:02 INFO 140434797135680] #progress_metric: host=algo-1, completed 85.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879441.3417127, \"EndTime\": 1630879442.1278641, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 169, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 15397900.0, \"count\": 1, \"min\": 15397900, \"max\": 15397900}, \"Total Batches Seen\": {\"sum\": 15471.0, \"count\": 1, \"min\": 15471, \"max\": 15471}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 171.0, \"count\": 1, \"min\": 171, \"max\": 171}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:02 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=115178.80068886894 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:02 INFO 140434797135680] #quality_metric: host=algo-1, epoch=170, batch=0 train rmse <loss>=0.995718127706707\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:02 INFO 140434797135680] #quality_metric: host=algo-1, epoch=170, batch=0 train mse <loss>=0.99145458984375\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:02 INFO 140434797135680] #quality_metric: host=algo-1, epoch=170, batch=0 train absolute_loss <loss>=0.82481298828125\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:04:02.583] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 342, \"duration\": 452, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:02 INFO 140434797135680] #quality_metric: host=algo-1, epoch=170, train rmse <loss>=0.9331729400569183\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:02 INFO 140434797135680] #quality_metric: host=algo-1, epoch=170, train mse <loss>=0.8708117360544728\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:02 INFO 140434797135680] #quality_metric: host=algo-1, epoch=170, train absolute_loss <loss>=0.741639649108216\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879442.1275988, \"EndTime\": 1630879442.583926, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 455.0635814666748, \"count\": 1, \"min\": 455.0635814666748, \"max\": 455.0635814666748}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:02 INFO 140434797135680] #progress_metric: host=algo-1, completed 85.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879442.1288242, \"EndTime\": 1630879442.5843005, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 170, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 15488470.0, \"count\": 1, \"min\": 15488470, \"max\": 15488470}, \"Total Batches Seen\": {\"sum\": 15562.0, \"count\": 1, \"min\": 15562, \"max\": 15562}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 172.0, \"count\": 1, \"min\": 172, \"max\": 172}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:02 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=198771.15474433228 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:02 INFO 140434797135680] #quality_metric: host=algo-1, epoch=171, batch=0 train rmse <loss>=0.9953893955774921\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:02 INFO 140434797135680] #quality_metric: host=algo-1, epoch=171, batch=0 train mse <loss>=0.990800048828125\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:02 INFO 140434797135680] #quality_metric: host=algo-1, epoch=171, batch=0 train absolute_loss <loss>=0.8244797973632813\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:04:03.024] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 344, \"duration\": 437, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:03 INFO 140434797135680] #quality_metric: host=algo-1, epoch=171, train rmse <loss>=0.932839889077927\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:03 INFO 140434797135680] #quality_metric: host=algo-1, epoch=171, train mse <loss>=0.8701902586549193\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:03 INFO 140434797135680] #quality_metric: host=algo-1, epoch=171, train absolute_loss <loss>=0.7413450183239612\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879442.5840018, \"EndTime\": 1630879443.0251522, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 440.1133060455322, \"count\": 1, \"min\": 440.1133060455322, \"max\": 440.1133060455322}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:03 INFO 140434797135680] #progress_metric: host=algo-1, completed 86.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879442.5850115, \"EndTime\": 1630879443.0254867, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 171, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 15579040.0, \"count\": 1, \"min\": 15579040, \"max\": 15579040}, \"Total Batches Seen\": {\"sum\": 15653.0, \"count\": 1, \"min\": 15653, \"max\": 15653}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 173.0, \"count\": 1, \"min\": 173, \"max\": 173}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:03 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=205547.29011487289 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:03 INFO 140434797135680] #quality_metric: host=algo-1, epoch=172, batch=0 train rmse <loss>=0.9950649098449244\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:03 INFO 140434797135680] #quality_metric: host=algo-1, epoch=172, batch=0 train mse <loss>=0.9901541748046875\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:03 INFO 140434797135680] #quality_metric: host=algo-1, epoch=172, batch=0 train absolute_loss <loss>=0.8241532592773437\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:04:03.461] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 346, \"duration\": 433, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:03 INFO 140434797135680] #quality_metric: host=algo-1, epoch=172, train rmse <loss>=0.9325082662773609\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:03 INFO 140434797135680] #quality_metric: host=algo-1, epoch=172, train mse <loss>=0.8695716666756096\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:03 INFO 140434797135680] #quality_metric: host=algo-1, epoch=172, train absolute_loss <loss>=0.7410520757318853\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879443.025252, \"EndTime\": 1630879443.46259, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 436.2027645111084, \"count\": 1, \"min\": 436.2027645111084, \"max\": 436.2027645111084}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:03 INFO 140434797135680] #progress_metric: host=algo-1, completed 86.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879443.0263383, \"EndTime\": 1630879443.4629552, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 172, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 15669610.0, \"count\": 1, \"min\": 15669610, \"max\": 15669610}, \"Total Batches Seen\": {\"sum\": 15744.0, \"count\": 1, \"min\": 15744, \"max\": 15744}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 174.0, \"count\": 1, \"min\": 174, \"max\": 174}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:03 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=207367.46238348214 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:03 INFO 140434797135680] #quality_metric: host=algo-1, epoch=173, batch=0 train rmse <loss>=0.9947446439857223\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:03 INFO 140434797135680] #quality_metric: host=algo-1, epoch=173, batch=0 train mse <loss>=0.9895169067382813\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:03 INFO 140434797135680] #quality_metric: host=algo-1, epoch=173, batch=0 train absolute_loss <loss>=0.8238328857421875\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:04:03.976] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 348, \"duration\": 511, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:03 INFO 140434797135680] #quality_metric: host=algo-1, epoch=173, train rmse <loss>=0.9321780681428412\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:03 INFO 140434797135680] #quality_metric: host=algo-1, epoch=173, train mse <loss>=0.8689559507265195\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:03 INFO 140434797135680] #quality_metric: host=algo-1, epoch=173, train absolute_loss <loss>=0.7407605845692393\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879443.4626782, \"EndTime\": 1630879443.97762, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 513.9071941375732, \"count\": 1, \"min\": 513.9071941375732, \"max\": 513.9071941375732}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:03 INFO 140434797135680] #progress_metric: host=algo-1, completed 87.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879443.4636862, \"EndTime\": 1630879443.9780629, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 173, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 15760180.0, \"count\": 1, \"min\": 15760180, \"max\": 15760180}, \"Total Batches Seen\": {\"sum\": 15835.0, \"count\": 1, \"min\": 15835, \"max\": 15835}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 175.0, \"count\": 1, \"min\": 175, \"max\": 175}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:03 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=176006.96158527516 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:03 INFO 140434797135680] #quality_metric: host=algo-1, epoch=174, batch=0 train rmse <loss>=0.9944285713884884\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:03 INFO 140434797135680] #quality_metric: host=algo-1, epoch=174, batch=0 train mse <loss>=0.98888818359375\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:03 INFO 140434797135680] #quality_metric: host=algo-1, epoch=174, batch=0 train absolute_loss <loss>=0.8235177612304687\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:04:04.643] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 350, \"duration\": 663, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:04 INFO 140434797135680] #quality_metric: host=algo-1, epoch=174, train rmse <loss>=0.9318492738760155\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:04 INFO 140434797135680] #quality_metric: host=algo-1, epoch=174, train mse <loss>=0.8683430692232572\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:04 INFO 140434797135680] #quality_metric: host=algo-1, epoch=174, train absolute_loss <loss>=0.7404706575163118\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879443.9777613, \"EndTime\": 1630879444.6444366, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 665.346622467041, \"count\": 1, \"min\": 665.346622467041, \"max\": 665.346622467041}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:04 INFO 140434797135680] #progress_metric: host=algo-1, completed 87.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879443.9790623, \"EndTime\": 1630879444.6446683, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 174, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 15850750.0, \"count\": 1, \"min\": 15850750, \"max\": 15850750}, \"Total Batches Seen\": {\"sum\": 15926.0, \"count\": 1, \"min\": 15926, \"max\": 15926}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 176.0, \"count\": 1, \"min\": 176, \"max\": 176}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:04 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=136043.757573891 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:04 INFO 140434797135680] #quality_metric: host=algo-1, epoch=175, batch=0 train rmse <loss>=0.9941166960528798\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:04 INFO 140434797135680] #quality_metric: host=algo-1, epoch=175, batch=0 train mse <loss>=0.9882680053710937\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:04 INFO 140434797135680] #quality_metric: host=algo-1, epoch=175, batch=0 train absolute_loss <loss>=0.8232079467773438\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:04:05.229] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 352, \"duration\": 581, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:05 INFO 140434797135680] #quality_metric: host=algo-1, epoch=175, train rmse <loss>=0.9315218583226258\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:05 INFO 140434797135680] #quality_metric: host=algo-1, epoch=175, train mse <loss>=0.8677329725328382\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:05 INFO 140434797135680] #quality_metric: host=algo-1, epoch=175, train absolute_loss <loss>=0.7401822536594265\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879444.6445074, \"EndTime\": 1630879445.2304502, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 585.1585865020752, \"count\": 1, \"min\": 585.1585865020752, \"max\": 585.1585865020752}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:05 INFO 140434797135680] #progress_metric: host=algo-1, completed 88.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879444.6452541, \"EndTime\": 1630879445.2307887, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 175, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 15941320.0, \"count\": 1, \"min\": 15941320, \"max\": 15941320}, \"Total Batches Seen\": {\"sum\": 16017.0, \"count\": 1, \"min\": 16017, \"max\": 16017}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 177.0, \"count\": 1, \"min\": 177, \"max\": 177}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:05 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=154643.65317117138 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:05 INFO 140434797135680] #quality_metric: host=algo-1, epoch=176, batch=0 train rmse <loss>=0.9938090526381156\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:05 INFO 140434797135680] #quality_metric: host=algo-1, epoch=176, batch=0 train mse <loss>=0.9876564331054688\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:05 INFO 140434797135680] #quality_metric: host=algo-1, epoch=176, batch=0 train absolute_loss <loss>=0.8229034423828125\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:04:05.679] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 354, \"duration\": 446, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:05 INFO 140434797135680] #quality_metric: host=algo-1, epoch=176, train rmse <loss>=0.9311958196957386\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:05 INFO 140434797135680] #quality_metric: host=algo-1, epoch=176, train mse <loss>=0.8671256546188186\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:05 INFO 140434797135680] #quality_metric: host=algo-1, epoch=176, train absolute_loss <loss>=0.7398954058636675\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879445.2305248, \"EndTime\": 1630879445.6807747, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 449.31840896606445, \"count\": 1, \"min\": 449.31840896606445, \"max\": 449.31840896606445}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:05 INFO 140434797135680] #progress_metric: host=algo-1, completed 88.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879445.2314284, \"EndTime\": 1630879445.681103, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 176, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 16031890.0, \"count\": 1, \"min\": 16031890, \"max\": 16031890}, \"Total Batches Seen\": {\"sum\": 16108.0, \"count\": 1, \"min\": 16108, \"max\": 16108}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 178.0, \"count\": 1, \"min\": 178, \"max\": 178}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:05 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=201347.1869027213 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:05 INFO 140434797135680] #quality_metric: host=algo-1, epoch=177, batch=0 train rmse <loss>=0.9935055836413615\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:05 INFO 140434797135680] #quality_metric: host=algo-1, epoch=177, batch=0 train mse <loss>=0.9870533447265625\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:05 INFO 140434797135680] #quality_metric: host=algo-1, epoch=177, batch=0 train absolute_loss <loss>=0.8226054077148437\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:04:06.367] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 356, \"duration\": 684, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:06 INFO 140434797135680] #quality_metric: host=algo-1, epoch=177, train rmse <loss>=0.9308711288198481\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:06 INFO 140434797135680] #quality_metric: host=algo-1, epoch=177, train mse <loss>=0.8665210584703382\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:06 INFO 140434797135680] #quality_metric: host=algo-1, epoch=177, train absolute_loss <loss>=0.7396101644327352\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879445.6808732, \"EndTime\": 1630879446.3681548, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 686.3129138946533, \"count\": 1, \"min\": 686.3129138946533, \"max\": 686.3129138946533}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:06 INFO 140434797135680] #progress_metric: host=algo-1, completed 89.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879445.681814, \"EndTime\": 1630879446.3684428, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 177, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 16122460.0, \"count\": 1, \"min\": 16122460, \"max\": 16122460}, \"Total Batches Seen\": {\"sum\": 16199.0, \"count\": 1, \"min\": 16199, \"max\": 16199}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 179.0, \"count\": 1, \"min\": 179, \"max\": 179}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:06 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=131880.82940775188 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:06 INFO 140434797135680] #quality_metric: host=algo-1, epoch=178, batch=0 train rmse <loss>=0.9932062928890327\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:06 INFO 140434797135680] #quality_metric: host=algo-1, epoch=178, batch=0 train mse <loss>=0.986458740234375\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:06 INFO 140434797135680] #quality_metric: host=algo-1, epoch=178, batch=0 train absolute_loss <loss>=0.8223143920898438\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:04:07.151] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 358, \"duration\": 779, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:07 INFO 140434797135680] #quality_metric: host=algo-1, epoch=178, train rmse <loss>=0.9305477838622545\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:07 INFO 140434797135680] #quality_metric: host=algo-1, epoch=178, train mse <loss>=0.865919178050953\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:07 INFO 140434797135680] #quality_metric: host=algo-1, epoch=178, train absolute_loss <loss>=0.7393264924772494\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879446.3682609, \"EndTime\": 1630879447.152603, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 783.3683490753174, \"count\": 1, \"min\": 783.3683490753174, \"max\": 783.3683490753174}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:07 INFO 140434797135680] #progress_metric: host=algo-1, completed 89.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879446.3692055, \"EndTime\": 1630879447.1530433, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 178, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 16213030.0, \"count\": 1, \"min\": 16213030, \"max\": 16213030}, \"Total Batches Seen\": {\"sum\": 16290.0, \"count\": 1, \"min\": 16290, \"max\": 16290}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 180.0, \"count\": 1, \"min\": 180, \"max\": 180}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:07 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=115521.95219323414 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:07 INFO 140434797135680] #quality_metric: host=algo-1, epoch=179, batch=0 train rmse <loss>=0.9929112148948981\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:07 INFO 140434797135680] #quality_metric: host=algo-1, epoch=179, batch=0 train mse <loss>=0.9858726806640625\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:07 INFO 140434797135680] #quality_metric: host=algo-1, epoch=179, batch=0 train absolute_loss <loss>=0.8220288696289062\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:04:07.830] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 360, \"duration\": 675, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:07 INFO 140434797135680] #quality_metric: host=algo-1, epoch=179, train rmse <loss>=0.9302257696429006\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:07 INFO 140434797135680] #quality_metric: host=algo-1, epoch=179, train mse <loss>=0.8653199825077267\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:07 INFO 140434797135680] #quality_metric: host=algo-1, epoch=179, train absolute_loss <loss>=0.7390444651174022\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879447.1527102, \"EndTime\": 1630879447.8313131, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 677.4013042449951, \"count\": 1, \"min\": 677.4013042449951, \"max\": 677.4013042449951}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:07 INFO 140434797135680] #progress_metric: host=algo-1, completed 90.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879447.1538901, \"EndTime\": 1630879447.8314588, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 179, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 16303600.0, \"count\": 1, \"min\": 16303600, \"max\": 16303600}, \"Total Batches Seen\": {\"sum\": 16381.0, \"count\": 1, \"min\": 16381, \"max\": 16381}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 181.0, \"count\": 1, \"min\": 181, \"max\": 181}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:07 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=133646.7698750776 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:07 INFO 140434797135680] #quality_metric: host=algo-1, epoch=180, batch=0 train rmse <loss>=0.9926202919270352\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:07 INFO 140434797135680] #quality_metric: host=algo-1, epoch=180, batch=0 train mse <loss>=0.9852950439453125\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:07 INFO 140434797135680] #quality_metric: host=algo-1, epoch=180, batch=0 train absolute_loss <loss>=0.8217506713867188\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:04:08.394] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 362, \"duration\": 559, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:08 INFO 140434797135680] #quality_metric: host=algo-1, epoch=180, train rmse <loss>=0.9299050731187669\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:08 INFO 140434797135680] #quality_metric: host=algo-1, epoch=180, train mse <loss>=0.8647234450120193\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:08 INFO 140434797135680] #quality_metric: host=algo-1, epoch=180, train absolute_loss <loss>=0.7387639891236693\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879447.8313649, \"EndTime\": 1630879448.395287, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 563.2922649383545, \"count\": 1, \"min\": 563.2922649383545, \"max\": 563.2922649383545}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:08 INFO 140434797135680] #progress_metric: host=algo-1, completed 90.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879447.8319669, \"EndTime\": 1630879448.3957293, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 180, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 16394170.0, \"count\": 1, \"min\": 16394170, \"max\": 16394170}, \"Total Batches Seen\": {\"sum\": 16472.0, \"count\": 1, \"min\": 16472, \"max\": 16472}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 182.0, \"count\": 1, \"min\": 182, \"max\": 182}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:08 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=160611.68430861543 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:08 INFO 140434797135680] #quality_metric: host=algo-1, epoch=181, batch=0 train rmse <loss>=0.9923335583931853\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:08 INFO 140434797135680] #quality_metric: host=algo-1, epoch=181, batch=0 train mse <loss>=0.9847258911132812\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:08 INFO 140434797135680] #quality_metric: host=algo-1, epoch=181, batch=0 train absolute_loss <loss>=0.8214778442382813\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:04:08.885] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 364, \"duration\": 486, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:08 INFO 140434797135680] #quality_metric: host=algo-1, epoch=181, train rmse <loss>=0.9295856837485196\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:08 INFO 140434797135680] #quality_metric: host=algo-1, epoch=181, train mse <loss>=0.8641295434302027\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:08 INFO 140434797135680] #quality_metric: host=algo-1, epoch=181, train absolute_loss <loss>=0.7384849323649982\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879448.3953705, \"EndTime\": 1630879448.8857427, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 489.0015125274658, \"count\": 1, \"min\": 489.0015125274658, \"max\": 489.0015125274658}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:08 INFO 140434797135680] #progress_metric: host=algo-1, completed 91.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879448.3967109, \"EndTime\": 1630879448.8860517, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 181, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 16484740.0, \"count\": 1, \"min\": 16484740, \"max\": 16484740}, \"Total Batches Seen\": {\"sum\": 16563.0, \"count\": 1, \"min\": 16563, \"max\": 16563}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 183.0, \"count\": 1, \"min\": 183, \"max\": 183}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:08 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=185024.34741187215 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:08 INFO 140434797135680] #quality_metric: host=algo-1, epoch=182, batch=0 train rmse <loss>=0.9920510179259778\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:08 INFO 140434797135680] #quality_metric: host=algo-1, epoch=182, batch=0 train mse <loss>=0.9841652221679688\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:08 INFO 140434797135680] #quality_metric: host=algo-1, epoch=182, batch=0 train absolute_loss <loss>=0.82121044921875\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:04:09.322] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 366, \"duration\": 434, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:09 INFO 140434797135680] #quality_metric: host=algo-1, epoch=182, train rmse <loss>=0.9292675736483441\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:09 INFO 140434797135680] #quality_metric: host=algo-1, epoch=182, train mse <loss>=0.8635382234342805\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:09 INFO 140434797135680] #quality_metric: host=algo-1, epoch=182, train absolute_loss <loss>=0.7382073129507212\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879448.8858376, \"EndTime\": 1630879449.3236024, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 436.8116855621338, \"count\": 1, \"min\": 436.8116855621338, \"max\": 436.8116855621338}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:09 INFO 140434797135680] #progress_metric: host=algo-1, completed 91.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879448.8867643, \"EndTime\": 1630879449.3238533, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 182, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 16575310.0, \"count\": 1, \"min\": 16575310, \"max\": 16575310}, \"Total Batches Seen\": {\"sum\": 16654.0, \"count\": 1, \"min\": 16654, \"max\": 16654}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 184.0, \"count\": 1, \"min\": 184, \"max\": 184}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:09 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=207151.59325058063 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:09 INFO 140434797135680] #quality_metric: host=algo-1, epoch=183, batch=0 train rmse <loss>=0.9917726741090294\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:09 INFO 140434797135680] #quality_metric: host=algo-1, epoch=183, batch=0 train mse <loss>=0.983613037109375\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:09 INFO 140434797135680] #quality_metric: host=algo-1, epoch=183, batch=0 train absolute_loss <loss>=0.8209509887695312\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:04:09.842] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 368, \"duration\": 516, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:09 INFO 140434797135680] #quality_metric: host=algo-1, epoch=183, train rmse <loss>=0.9289507578507383\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:09 INFO 140434797135680] #quality_metric: host=algo-1, epoch=183, train mse <loss>=0.8629495105114612\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:09 INFO 140434797135680] #quality_metric: host=algo-1, epoch=183, train absolute_loss <loss>=0.7379311121007899\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879449.3236787, \"EndTime\": 1630879449.8427794, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 518.2094573974609, \"count\": 1, \"min\": 518.2094573974609, \"max\": 518.2094573974609}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:09 INFO 140434797135680] #progress_metric: host=algo-1, completed 92.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879449.3245413, \"EndTime\": 1630879449.8431206, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 183, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 16665880.0, \"count\": 1, \"min\": 16665880, \"max\": 16665880}, \"Total Batches Seen\": {\"sum\": 16745.0, \"count\": 1, \"min\": 16745, \"max\": 16745}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 185.0, \"count\": 1, \"min\": 185, \"max\": 185}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:09 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=174601.45383044527 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:09 INFO 140434797135680] #quality_metric: host=algo-1, epoch=184, batch=0 train rmse <loss>=0.9914984381389772\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:09 INFO 140434797135680] #quality_metric: host=algo-1, epoch=184, batch=0 train mse <loss>=0.9830691528320312\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:09 INFO 140434797135680] #quality_metric: host=algo-1, epoch=184, batch=0 train absolute_loss <loss>=0.8206988525390625\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:04:10.282] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 370, \"duration\": 436, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:10 INFO 140434797135680] #quality_metric: host=algo-1, epoch=184, train rmse <loss>=0.9286351986783703\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:10 INFO 140434797135680] #quality_metric: host=algo-1, epoch=184, train mse <loss>=0.8623633322244162\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:10 INFO 140434797135680] #quality_metric: host=algo-1, epoch=184, train absolute_loss <loss>=0.737656247987852\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879449.842878, \"EndTime\": 1630879450.2828045, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 438.922643661499, \"count\": 1, \"min\": 438.922643661499, \"max\": 438.922643661499}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:10 INFO 140434797135680] #progress_metric: host=algo-1, completed 92.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879449.8438537, \"EndTime\": 1630879450.2831523, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 184, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 16756450.0, \"count\": 1, \"min\": 16756450, \"max\": 16756450}, \"Total Batches Seen\": {\"sum\": 16836.0, \"count\": 1, \"min\": 16836, \"max\": 16836}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 186.0, \"count\": 1, \"min\": 186, \"max\": 186}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:10 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=206099.30298722858 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:10 INFO 140434797135680] #quality_metric: host=algo-1, epoch=185, batch=0 train rmse <loss>=0.9912284673634624\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:10 INFO 140434797135680] #quality_metric: host=algo-1, epoch=185, batch=0 train mse <loss>=0.9825338745117187\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:10 INFO 140434797135680] #quality_metric: host=algo-1, epoch=185, batch=0 train absolute_loss <loss>=0.8204521484375\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:04:10.706] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 372, \"duration\": 421, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:10 INFO 140434797135680] #quality_metric: host=algo-1, epoch=185, train rmse <loss>=0.928320918365343\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:10 INFO 140434797135680] #quality_metric: host=algo-1, epoch=185, train mse <loss>=0.8617797274746738\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:10 INFO 140434797135680] #quality_metric: host=algo-1, epoch=185, train absolute_loss <loss>=0.737382803780692\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879450.2829258, \"EndTime\": 1630879450.7077546, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 423.9327907562256, \"count\": 1, \"min\": 423.9327907562256, \"max\": 423.9327907562256}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:10 INFO 140434797135680] #progress_metric: host=algo-1, completed 93.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879450.2837954, \"EndTime\": 1630879450.7080705, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 185, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 16847020.0, \"count\": 1, \"min\": 16847020, \"max\": 16847020}, \"Total Batches Seen\": {\"sum\": 16927.0, \"count\": 1, \"min\": 16927, \"max\": 16927}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 187.0, \"count\": 1, \"min\": 187, \"max\": 187}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:10 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=213378.70767848115 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:10 INFO 140434797135680] #quality_metric: host=algo-1, epoch=186, batch=0 train rmse <loss>=0.990962549697184\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:10 INFO 140434797135680] #quality_metric: host=algo-1, epoch=186, batch=0 train mse <loss>=0.9820067749023438\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:10 INFO 140434797135680] #quality_metric: host=algo-1, epoch=186, batch=0 train absolute_loss <loss>=0.8202112426757813\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:04:11.175] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 374, \"duration\": 465, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:11 INFO 140434797135680] #quality_metric: host=algo-1, epoch=186, train rmse <loss>=0.9280078697868297\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:11 INFO 140434797135680] #quality_metric: host=algo-1, epoch=186, train mse <loss>=0.8611986063862895\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:11 INFO 140434797135680] #quality_metric: host=algo-1, epoch=186, train absolute_loss <loss>=0.7371107077126975\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879450.707854, \"EndTime\": 1630879451.1769319, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 468.0938720703125, \"count\": 1, \"min\": 468.0938720703125, \"max\": 468.0938720703125}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:11 INFO 140434797135680] #progress_metric: host=algo-1, completed 93.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879450.7088108, \"EndTime\": 1630879451.1773143, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 186, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 16937590.0, \"count\": 1, \"min\": 16937590, \"max\": 16937590}, \"Total Batches Seen\": {\"sum\": 17018.0, \"count\": 1, \"min\": 17018, \"max\": 17018}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 188.0, \"count\": 1, \"min\": 188, \"max\": 188}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:11 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=193269.37792572717 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:11 INFO 140434797135680] #quality_metric: host=algo-1, epoch=187, batch=0 train rmse <loss>=0.9907008424240324\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:11 INFO 140434797135680] #quality_metric: host=algo-1, epoch=187, batch=0 train mse <loss>=0.9814881591796875\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:11 INFO 140434797135680] #quality_metric: host=algo-1, epoch=187, batch=0 train absolute_loss <loss>=0.8199769897460938\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:04:11.605] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 376, \"duration\": 425, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:11 INFO 140434797135680] #quality_metric: host=algo-1, epoch=187, train rmse <loss>=0.9276960820249246\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:11 INFO 140434797135680] #quality_metric: host=algo-1, epoch=187, train mse <loss>=0.8606200206043956\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:11 INFO 140434797135680] #quality_metric: host=algo-1, epoch=187, train absolute_loss <loss>=0.7368400181361607\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879451.1769972, \"EndTime\": 1630879451.6059425, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 427.8726577758789, \"count\": 1, \"min\": 427.8726577758789, \"max\": 427.8726577758789}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:11 INFO 140434797135680] #progress_metric: host=algo-1, completed 94.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879451.1780438, \"EndTime\": 1630879451.6061974, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 187, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 17028160.0, \"count\": 1, \"min\": 17028160, \"max\": 17028160}, \"Total Batches Seen\": {\"sum\": 17109.0, \"count\": 1, \"min\": 17109, \"max\": 17109}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 189.0, \"count\": 1, \"min\": 189, \"max\": 189}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:11 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=211445.1420365361 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:11 INFO 140434797135680] #quality_metric: host=algo-1, epoch=188, batch=0 train rmse <loss>=0.9904432872574974\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:11 INFO 140434797135680] #quality_metric: host=algo-1, epoch=188, batch=0 train mse <loss>=0.9809779052734375\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:11 INFO 140434797135680] #quality_metric: host=algo-1, epoch=188, batch=0 train absolute_loss <loss>=0.8197526245117187\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:04:12.044] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 378, \"duration\": 435, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:12 INFO 140434797135680] #quality_metric: host=algo-1, epoch=188, train rmse <loss>=0.9273855295916622\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:12 INFO 140434797135680] #quality_metric: host=algo-1, epoch=188, train mse <loss>=0.8600439204960079\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:12 INFO 140434797135680] #quality_metric: host=algo-1, epoch=188, train absolute_loss <loss>=0.7365707095638736\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879451.606017, \"EndTime\": 1630879452.0451212, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 438.16471099853516, \"count\": 1, \"min\": 438.16471099853516, \"max\": 438.16471099853516}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:12 INFO 140434797135680] #progress_metric: host=algo-1, completed 94.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879451.6069283, \"EndTime\": 1630879452.0454566, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 188, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 17118730.0, \"count\": 1, \"min\": 17118730, \"max\": 17118730}, \"Total Batches Seen\": {\"sum\": 17200.0, \"count\": 1, \"min\": 17200, \"max\": 17200}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 190.0, \"count\": 1, \"min\": 190, \"max\": 190}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:12 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=206453.58889618955 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:12 INFO 140434797135680] #quality_metric: host=algo-1, epoch=189, batch=0 train rmse <loss>=0.9901898257977009\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:12 INFO 140434797135680] #quality_metric: host=algo-1, epoch=189, batch=0 train mse <loss>=0.9804758911132813\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:12 INFO 140434797135680] #quality_metric: host=algo-1, epoch=189, batch=0 train absolute_loss <loss>=0.8195349731445313\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:04:12.471] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 380, \"duration\": 424, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:12 INFO 140434797135680] #quality_metric: host=algo-1, epoch=189, train rmse <loss>=0.9270761851512324\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:12 INFO 140434797135680] #quality_metric: host=algo-1, epoch=189, train mse <loss>=0.8594702530745622\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:12 INFO 140434797135680] #quality_metric: host=algo-1, epoch=189, train absolute_loss <loss>=0.7363027471186041\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879452.0452201, \"EndTime\": 1630879452.4725862, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 426.40209197998047, \"count\": 1, \"min\": 426.40209197998047, \"max\": 426.40209197998047}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:12 INFO 140434797135680] #progress_metric: host=algo-1, completed 95.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879452.0461564, \"EndTime\": 1630879452.472982, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 189, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 17209300.0, \"count\": 1, \"min\": 17209300, \"max\": 17209300}, \"Total Batches Seen\": {\"sum\": 17291.0, \"count\": 1, \"min\": 17291, \"max\": 17291}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:12 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=212126.8932983249 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:12 INFO 140434797135680] #quality_metric: host=algo-1, epoch=190, batch=0 train rmse <loss>=0.989940492016755\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:12 INFO 140434797135680] #quality_metric: host=algo-1, epoch=190, batch=0 train mse <loss>=0.979982177734375\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:12 INFO 140434797135680] #quality_metric: host=algo-1, epoch=190, batch=0 train absolute_loss <loss>=0.8193225708007813\u001b[0m\n",
      "\n",
      "2021-09-05 22:04:24 Uploading - Uploading generated training model\u001b[34m[2021-09-05 22:04:12.928] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 382, \"duration\": 452, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:12 INFO 140434797135680] #quality_metric: host=algo-1, epoch=190, train rmse <loss>=0.9267680748814465\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:12 INFO 140434797135680] #quality_metric: host=algo-1, epoch=190, train mse <loss>=0.8588990646194625\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:12 INFO 140434797135680] #quality_metric: host=algo-1, epoch=190, train absolute_loss <loss>=0.7360360362293956\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879452.4726994, \"EndTime\": 1630879452.9291537, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 455.40761947631836, \"count\": 1, \"min\": 455.40761947631836, \"max\": 455.40761947631836}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:12 INFO 140434797135680] #progress_metric: host=algo-1, completed 95.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879452.4737186, \"EndTime\": 1630879452.9295475, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 190, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 17299870.0, \"count\": 1, \"min\": 17299870, \"max\": 17299870}, \"Total Batches Seen\": {\"sum\": 17382.0, \"count\": 1, \"min\": 17382, \"max\": 17382}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 192.0, \"count\": 1, \"min\": 192, \"max\": 192}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:12 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=198643.1007051478 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:12 INFO 140434797135680] #quality_metric: host=algo-1, epoch=191, batch=0 train rmse <loss>=0.9896952890343163\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:12 INFO 140434797135680] #quality_metric: host=algo-1, epoch=191, batch=0 train mse <loss>=0.9794967651367188\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:12 INFO 140434797135680] #quality_metric: host=algo-1, epoch=191, batch=0 train absolute_loss <loss>=0.819115234375\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:04:13.357] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 384, \"duration\": 425, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:13 INFO 140434797135680] #quality_metric: host=algo-1, epoch=191, train rmse <loss>=0.9264611725033559\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:13 INFO 140434797135680] #quality_metric: host=algo-1, epoch=191, train mse <loss>=0.858330304156293\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:13 INFO 140434797135680] #quality_metric: host=algo-1, epoch=191, train absolute_loss <loss>=0.7357705943348644\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879452.9292228, \"EndTime\": 1630879453.3582203, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 427.89292335510254, \"count\": 1, \"min\": 427.89292335510254, \"max\": 427.89292335510254}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:13 INFO 140434797135680] #progress_metric: host=algo-1, completed 96.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879452.9303002, \"EndTime\": 1630879453.3586073, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 191, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 17390440.0, \"count\": 1, \"min\": 17390440, \"max\": 17390440}, \"Total Batches Seen\": {\"sum\": 17473.0, \"count\": 1, \"min\": 17473, \"max\": 17473}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 193.0, \"count\": 1, \"min\": 193, \"max\": 193}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:13 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=211393.7226414664 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:13 INFO 140434797135680] #quality_metric: host=algo-1, epoch=192, batch=0 train rmse <loss>=0.9894542199214234\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:13 INFO 140434797135680] #quality_metric: host=algo-1, epoch=192, batch=0 train mse <loss>=0.9790196533203125\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:13 INFO 140434797135680] #quality_metric: host=algo-1, epoch=192, batch=0 train absolute_loss <loss>=0.8189158935546875\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:04:13.799] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 386, \"duration\": 438, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:13 INFO 140434797135680] #quality_metric: host=algo-1, epoch=192, train rmse <loss>=0.9261554788556494\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:13 INFO 140434797135680] #quality_metric: host=algo-1, epoch=192, train mse <loss>=0.8577639710143372\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:13 INFO 140434797135680] #quality_metric: host=algo-1, epoch=192, train absolute_loss <loss>=0.7355064791165865\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879453.3583035, \"EndTime\": 1630879453.800389, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 441.0550594329834, \"count\": 1, \"min\": 441.0550594329834, \"max\": 441.0550594329834}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:13 INFO 140434797135680] #progress_metric: host=algo-1, completed 96.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879453.3593066, \"EndTime\": 1630879453.8007011, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 192, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 17481010.0, \"count\": 1, \"min\": 17481010, \"max\": 17481010}, \"Total Batches Seen\": {\"sum\": 17564.0, \"count\": 1, \"min\": 17564, \"max\": 17564}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 194.0, \"count\": 1, \"min\": 194, \"max\": 194}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:13 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=205126.74327548884 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:13 INFO 140434797135680] #quality_metric: host=algo-1, epoch=193, batch=0 train rmse <loss>=0.9892172568500814\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:13 INFO 140434797135680] #quality_metric: host=algo-1, epoch=193, batch=0 train mse <loss>=0.97855078125\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:13 INFO 140434797135680] #quality_metric: host=algo-1, epoch=193, batch=0 train absolute_loss <loss>=0.8187245483398438\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:04:14.245] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 388, \"duration\": 442, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:14 INFO 140434797135680] #quality_metric: host=algo-1, epoch=193, train rmse <loss>=0.9258509915134484\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:14 INFO 140434797135680] #quality_metric: host=algo-1, epoch=193, train mse <loss>=0.8572000584864354\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:14 INFO 140434797135680] #quality_metric: host=algo-1, epoch=193, train absolute_loss <loss>=0.7352435758821256\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879453.8004632, \"EndTime\": 1630879454.246096, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 444.7205066680908, \"count\": 1, \"min\": 444.7205066680908, \"max\": 444.7205066680908}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:14 INFO 140434797135680] #progress_metric: host=algo-1, completed 97.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879453.8013484, \"EndTime\": 1630879454.2463412, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 193, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 17571580.0, \"count\": 1, \"min\": 17571580, \"max\": 17571580}, \"Total Batches Seen\": {\"sum\": 17655.0, \"count\": 1, \"min\": 17655, \"max\": 17655}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 195.0, \"count\": 1, \"min\": 195, \"max\": 195}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:14 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=203474.15760380513 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:14 INFO 140434797135680] #quality_metric: host=algo-1, epoch=194, batch=0 train rmse <loss>=0.9889843410567575\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:14 INFO 140434797135680] #quality_metric: host=algo-1, epoch=194, batch=0 train mse <loss>=0.9780900268554688\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:14 INFO 140434797135680] #quality_metric: host=algo-1, epoch=194, batch=0 train absolute_loss <loss>=0.8185396118164062\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:04:14.762] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 390, \"duration\": 513, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:14 INFO 140434797135680] #quality_metric: host=algo-1, epoch=194, train rmse <loss>=0.9255476964492513\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:14 INFO 140434797135680] #quality_metric: host=algo-1, epoch=194, train mse <loss>=0.8566385384025155\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:14 INFO 140434797135680] #quality_metric: host=algo-1, epoch=194, train absolute_loss <loss>=0.734981936276614\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879454.2461705, \"EndTime\": 1630879454.7629783, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 515.9151554107666, \"count\": 1, \"min\": 515.9151554107666, \"max\": 515.9151554107666}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:14 INFO 140434797135680] #progress_metric: host=algo-1, completed 97.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879454.2470357, \"EndTime\": 1630879454.7633185, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 194, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 17662150.0, \"count\": 1, \"min\": 17662150, \"max\": 17662150}, \"Total Batches Seen\": {\"sum\": 17746.0, \"count\": 1, \"min\": 17746, \"max\": 17746}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 196.0, \"count\": 1, \"min\": 196, \"max\": 196}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:14 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=175368.72176119304 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:14 INFO 140434797135680] #quality_metric: host=algo-1, epoch=195, batch=0 train rmse <loss>=0.9887555062662736\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:14 INFO 140434797135680] #quality_metric: host=algo-1, epoch=195, batch=0 train mse <loss>=0.977637451171875\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:14 INFO 140434797135680] #quality_metric: host=algo-1, epoch=195, batch=0 train absolute_loss <loss>=0.8183601684570313\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:04:15.241] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 392, \"duration\": 475, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:15 INFO 140434797135680] #quality_metric: host=algo-1, epoch=195, train rmse <loss>=0.9252456024470548\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:15 INFO 140434797135680] #quality_metric: host=algo-1, epoch=195, train mse <loss>=0.8560794248476133\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:15 INFO 140434797135680] #quality_metric: host=algo-1, epoch=195, train absolute_loss <loss>=0.7347216253595038\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879454.7630923, \"EndTime\": 1630879455.2424734, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 478.23047637939453, \"count\": 1, \"min\": 478.23047637939453, \"max\": 478.23047637939453}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:15 INFO 140434797135680] #progress_metric: host=algo-1, completed 98.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879454.7642148, \"EndTime\": 1630879455.2428396, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 195, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 17752720.0, \"count\": 1, \"min\": 17752720, \"max\": 17752720}, \"Total Batches Seen\": {\"sum\": 17837.0, \"count\": 1, \"min\": 17837, \"max\": 17837}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 197.0, \"count\": 1, \"min\": 197, \"max\": 197}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:15 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=189172.2469370407 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:15 INFO 140434797135680] #quality_metric: host=algo-1, epoch=196, batch=0 train rmse <loss>=0.9885307244411083\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:15 INFO 140434797135680] #quality_metric: host=algo-1, epoch=196, batch=0 train mse <loss>=0.9771929931640625\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:15 INFO 140434797135680] #quality_metric: host=algo-1, epoch=196, batch=0 train absolute_loss <loss>=0.8181898193359375\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:04:15.667] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 394, \"duration\": 422, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:15 INFO 140434797135680] #quality_metric: host=algo-1, epoch=196, train rmse <loss>=0.9249446929177144\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:15 INFO 140434797135680] #quality_metric: host=algo-1, epoch=196, train mse <loss>=0.855522684956645\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:15 INFO 140434797135680] #quality_metric: host=algo-1, epoch=196, train absolute_loss <loss>=0.7344625867906508\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879455.242538, \"EndTime\": 1630879455.6685214, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 424.87287521362305, \"count\": 1, \"min\": 424.87287521362305, \"max\": 424.87287521362305}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:15 INFO 140434797135680] #progress_metric: host=algo-1, completed 98.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879455.243622, \"EndTime\": 1630879455.6687746, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 196, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 17843290.0, \"count\": 1, \"min\": 17843290, \"max\": 17843290}, \"Total Batches Seen\": {\"sum\": 17928.0, \"count\": 1, \"min\": 17928, \"max\": 17928}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 198.0, \"count\": 1, \"min\": 198, \"max\": 198}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:15 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=212963.49883477195 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:15 INFO 140434797135680] #quality_metric: host=algo-1, epoch=197, batch=0 train rmse <loss>=0.9883100292252364\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:15 INFO 140434797135680] #quality_metric: host=algo-1, epoch=197, batch=0 train mse <loss>=0.9767567138671875\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:15 INFO 140434797135680] #quality_metric: host=algo-1, epoch=197, batch=0 train absolute_loss <loss>=0.8180244140625\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:04:16.130] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 396, \"duration\": 459, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:16 INFO 140434797135680] #quality_metric: host=algo-1, epoch=197, train rmse <loss>=0.9246449701056931\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:16 INFO 140434797135680] #quality_metric: host=algo-1, epoch=197, train mse <loss>=0.8549683207417582\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:16 INFO 140434797135680] #quality_metric: host=algo-1, epoch=197, train absolute_loss <loss>=0.7342051022707761\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879455.6685965, \"EndTime\": 1630879456.132257, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 462.79001235961914, \"count\": 1, \"min\": 462.79001235961914, \"max\": 462.79001235961914}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:16 INFO 140434797135680] #progress_metric: host=algo-1, completed 99.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879455.66944, \"EndTime\": 1630879456.133011, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 197, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 17933860.0, \"count\": 1, \"min\": 17933860, \"max\": 17933860}, \"Total Batches Seen\": {\"sum\": 18019.0, \"count\": 1, \"min\": 18019, \"max\": 18019}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 199.0, \"count\": 1, \"min\": 199, \"max\": 199}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:16 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=195158.67292676272 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:16 INFO 140434797135680] #quality_metric: host=algo-1, epoch=198, batch=0 train rmse <loss>=0.9880933307009927\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:16 INFO 140434797135680] #quality_metric: host=algo-1, epoch=198, batch=0 train mse <loss>=0.9763284301757813\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:16 INFO 140434797135680] #quality_metric: host=algo-1, epoch=198, batch=0 train absolute_loss <loss>=0.8178638305664062\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:04:16.565] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 398, \"duration\": 429, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:16 INFO 140434797135680] #quality_metric: host=algo-1, epoch=198, train rmse <loss>=0.9243464337141618\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:16 INFO 140434797135680] #quality_metric: host=algo-1, epoch=198, train mse <loss>=0.8544163295200893\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:16 INFO 140434797135680] #quality_metric: host=algo-1, epoch=198, train absolute_loss <loss>=0.7339490329616672\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879456.132657, \"EndTime\": 1630879456.5664697, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 432.0566654205322, \"count\": 1, \"min\": 432.0566654205322, \"max\": 432.0566654205322}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:16 INFO 140434797135680] #progress_metric: host=algo-1, completed 99.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879456.1343408, \"EndTime\": 1630879456.5668561, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 198, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 18024430.0, \"count\": 1, \"min\": 18024430, \"max\": 18024430}, \"Total Batches Seen\": {\"sum\": 18110.0, \"count\": 1, \"min\": 18110, \"max\": 18110}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 200.0, \"count\": 1, \"min\": 200, \"max\": 200}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:16 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=209335.91300293937 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:16 INFO 140434797135680] #quality_metric: host=algo-1, epoch=199, batch=0 train rmse <loss>=0.9878806314984842\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:16 INFO 140434797135680] #quality_metric: host=algo-1, epoch=199, batch=0 train mse <loss>=0.9759081420898438\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:16 INFO 140434797135680] #quality_metric: host=algo-1, epoch=199, batch=0 train absolute_loss <loss>=0.8177079467773437\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:04:17.007] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 400, \"duration\": 438, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:17 INFO 140434797135680] #quality_metric: host=algo-1, epoch=199, train rmse <loss>=0.92404907763458\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:17 INFO 140434797135680] #quality_metric: host=algo-1, epoch=199, train mse <loss>=0.853866697877318\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:17 INFO 140434797135680] #quality_metric: host=algo-1, epoch=199, train absolute_loss <loss>=0.7336944586785284\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:17 INFO 140434797135680] #quality_metric: host=algo-1, train rmse <loss>=0.92404907763458\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:17 INFO 140434797135680] #quality_metric: host=algo-1, train mse <loss>=0.853866697877318\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:17 INFO 140434797135680] #quality_metric: host=algo-1, train absolute_loss <loss>=0.7336944586785284\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879456.5665452, \"EndTime\": 1630879457.0084488, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 440.8223628997803, \"count\": 1, \"min\": 440.8223628997803, \"max\": 440.8223628997803}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:17 INFO 140434797135680] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879456.5675874, \"EndTime\": 1630879457.008812, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 199, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 18115000.0, \"count\": 1, \"min\": 18115000, \"max\": 18115000}, \"Total Batches Seen\": {\"sum\": 18201.0, \"count\": 1, \"min\": 18201, \"max\": 18201}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 201.0, \"count\": 1, \"min\": 201, \"max\": 201}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:17 INFO 140434797135680] #throughput_metric: host=algo-1, train throughput=205202.86667473338 records/second\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:17 WARNING 140434797135680] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:17 INFO 140434797135680] Pulling entire model from kvstore to finalize\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879457.0085511, \"EndTime\": 1630879457.0115674, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 2.2881031036376953, \"count\": 1, \"min\": 2.2881031036376953, \"max\": 2.2881031036376953}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:17 INFO 140434797135680] Saved checkpoint to \"/tmp/tmp0qoskdr9/state-0001.params\"\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:04:17.016] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 0, \"duration\": 96259, \"num_examples\": 1, \"num_bytes\": 64000}\u001b[0m\n",
      "\u001b[34m[2021-09-05 22:04:17.043] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 1, \"duration\": 26, \"num_examples\": 10, \"num_bytes\": 603520}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879457.0166962, \"EndTime\": 1630879457.043329, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"test_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9430.0, \"count\": 1, \"min\": 9430, \"max\": 9430}, \"Total Batches Seen\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Max Records Seen Between Resets\": {\"sum\": 9430.0, \"count\": 1, \"min\": 9430, \"max\": 9430}, \"Max Batches Seen Between Resets\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 9430.0, \"count\": 1, \"min\": 9430, \"max\": 9430}, \"Number of Batches Since Last Reset\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:17 INFO 140434797135680] #test_score (algo-1) : ('rmse', 0.9751552825008076)\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:17 INFO 140434797135680] #test_score (algo-1) : ('mse', 0.9509278249892299)\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:17 INFO 140434797135680] #test_score (algo-1) : ('absolute_loss', 0.7906167799948635)\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:17 INFO 140434797135680] #quality_metric: host=algo-1, test rmse <loss>=0.9751552825008076\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:17 INFO 140434797135680] #quality_metric: host=algo-1, test mse <loss>=0.9509278249892299\u001b[0m\n",
      "\u001b[34m[09/05/2021 22:04:17 INFO 140434797135680] #quality_metric: host=algo-1, test absolute_loss <loss>=0.7906167799948635\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1630879457.0116262, \"EndTime\": 1630879457.044572, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 23.415088653564453, \"count\": 1, \"min\": 23.415088653564453, \"max\": 23.415088653564453}, \"totaltime\": {\"sum\": 96320.157289505, \"count\": 1, \"min\": 96320.157289505, \"max\": 96320.157289505}}}\n",
      "\u001b[0m\n",
      "\n",
      "2021-09-05 22:04:44 Completed - Training job completed\n",
      "ProfilerReport-1630879192: NoIssuesFound\n",
      "Training seconds: 158\n",
      "Billable seconds: 56\n",
      "Managed Spot Training savings: 64.6%\n"
     ]
    }
   ],
   "source": [
    "image_name= sagemaker.image_uris.retrieve(\"factorization-machines\", \"eu-central-1\")\n",
    "print(\"User image :\",image_name)\n",
    "\n",
    "fm = sagemaker.estimator.Estimator(image_name,\n",
    "                                   get_execution_role(),\n",
    "                                   instance_count = 1,  # Instance count\n",
    "                                   instance_type = 'ml.m5.large',\n",
    "                                   output_path = output_path,\n",
    "                                   sagemaker_session = sagemaker.Session(),\n",
    "                                   use_spot_instances=True, # We want to use spot instances to lower the bill\n",
    "                                   max_wait=1*3600,\n",
    "                                   max_run=1*3600\n",
    "                                  )\n",
    "\n",
    "fm.set_hyperparameters(feature_dim = training_data.shape[1],\n",
    "                       predictor_type = 'regressor', # We want to make regression to predict the rating\n",
    "                       mini_batch_size = 1000,\n",
    "                       num_factors = 10, # number of latent variable for user and product\n",
    "                       epochs = 200 \n",
    "                      )\n",
    "\n",
    "fm.fit({ 'train': training_data_location, 'test': testing_data_location })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------!"
     ]
    }
   ],
   "source": [
    "fm_predictor = fm.deploy(instance_type = 'ml.t2.medium', initial_instance_count = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactorizationMachineSerializer(SimpleBaseSerializer):\n",
    "    # SimpleBaseSerializer already uses \"application/json\" CONTENT_TYPE by default\n",
    "\n",
    "    def serialize(self, data):\n",
    "        js = {\"instances\": []}\n",
    "        for row in data:\n",
    "            js[\"instances\"].append({\"features\": row.tolist()})\n",
    "        return json.dumps(js)\n",
    "\n",
    "\n",
    "#fm_predictor.CONTENT_TYPE = 'application/json'\n",
    "fm_predictor.serializer = FactorizationMachineSerializer()\n",
    "fm_predictor.deserializer = JSONDeserializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: 2.8320682048797607\n",
      "Expected: 3.0\n"
     ]
    }
   ],
   "source": [
    "index=349\n",
    "\n",
    "\n",
    "result = fm_predictor.predict(testing_data[index].toarray())\n",
    "\n",
    "print(\"Actual:\",result[\"predictions\"][0][\"score\"])\n",
    "print(\"Expected:\",testing_labels[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run prediction with loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: 4.073488712310791\n",
      "Expected: 4.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "client = boto3.client('runtime.sagemaker')\n",
    "\n",
    "index=220\n",
    "\n",
    "testing_data[index].toarray()\n",
    "\n",
    "payload=FactorizationMachineSerializer().serialize(testing_data[index].toarray())\n",
    "\n",
    "\n",
    "result = client.invoke_endpoint(\n",
    "    EndpointName='factorization-machines-2021-09-05-21-01-55-437',\n",
    "    Body=payload,\n",
    "    ContentType='application/json',\n",
    "    Accept='Accept'\n",
    ")\n",
    "\n",
    "result=json.loads(result['Body'].read().decode())\n",
    "\n",
    "print(\"Actual:\",result[\"predictions\"][0][\"score\"])\n",
    "print(\"Expected:\",testing_labels[index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
